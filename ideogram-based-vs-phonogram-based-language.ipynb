{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0787b123",
   "metadata": {
    "papermill": {
     "duration": 0.046044,
     "end_time": "2023-09-25T12:48:36.495769",
     "exception": false,
     "start_time": "2023-09-25T12:48:36.449725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div id = \"top\"> </div>\n",
    "\n",
    "# 🀄 Ideogram-based vs. Phonogram-based Language\n",
    "#### Jason Heesang Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43acdb7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:36.687811Z",
     "iopub.status.busy": "2023-09-25T12:48:36.686717Z",
     "iopub.status.idle": "2023-09-25T12:48:50.578534Z",
     "shell.execute_reply": "2023-09-25T12:48:50.576650Z"
    },
    "papermill": {
     "duration": 14.040692,
     "end_time": "2023-09-25T12:48:50.581634",
     "exception": false,
     "start_time": "2023-09-25T12:48:36.540942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q whoosh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e6828",
   "metadata": {
    "papermill": {
     "duration": 0.051661,
     "end_time": "2023-09-25T12:48:50.690168",
     "exception": false,
     "start_time": "2023-09-25T12:48:50.638507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Disclaimer:* Initially, this project was just a quick review to fulfill my curiosity.<br>\n",
    "But as I was developing this notebook, somehow it became a large-sized project..<br>\n",
    "I will try to finish this notebook by ***October 2023***.<br>\n",
    "\n",
    "------------------------------------------------------------------\n",
    "<br>\n",
    "\n",
    "***There*** are more than **7.8 billion** people in the world and with more than **7,000 languages**.<br><br>\n",
    "In a greater perspective, there are two types of languages: Ideogram-Based Language and Phonogram-Based Language.<br>\n",
    "Phonogram-based Languages are languages that are developed on phonemes (speech sound) or a combination of phonemes.<br>\n",
    "Latin alphabets and Korean (Hangul) are examples.<br>\n",
    "<br>\n",
    "Ideogram Based Languages are the languages that are developed on symbols of writing systems.\n",
    "Chinese, Egyptian Hieroglyph and Sumero-Akkadian Cuneiform are examples.<br> [Source: Wikipedia](https://en.wikipedia.org/wiki/Ideogram)<br>\n",
    "<br>\n",
    "As I am fluent in Korean, English, and Chinese, I was suddenly curious about the possible differences in Natural Language Processing (NLP) techniques dealing with these two types of languages.<br> [Source: Wikipedia](https://en.wikipedia.org/wiki/Phonogram_(linguistics))<br>\n",
    "<br>\n",
    "In a brief thoughts, I believe it is easier to process Ideogram Based Languages than Phonogram Based Languages.<br>\n",
    "<br>\n",
    "It is due to the characteristics of the Ideogram Based Languages.\n",
    "<br>\n",
    "Taking Chinese (which I am familiar with) as an example, each character represents a certain definition. Each character (or an alphabet) in Phonogram Based Languages such as English and Hangul, often needs other characters to contain a definition.<br>\n",
    "<br>\n",
    "**`Hypothesis`** : Ideogram-based Languages might not need special Tokenizations or Embeddings for Natural Language Processing.<br>\n",
    "<br>\n",
    "I tried to ask and discuss with the lecturers here at Year-Dream School (Data Science Bootcamp) regarding this topic.<br>\n",
    "I only had a meaningful discussion with [@Yongdam Kim](https://www.kaggle.com/emphymachine) as he and some of his friend has some (not a lot, as per he claims) experience in this field.<br>\n",
    "He mentioned that Natural Language Processing can be easier for Ideogram-based languages, as each character in this language contains meaning, which already could be similar to embedding.<br>\n",
    "<br>\n",
    "As I want to further research into this topic, I had to first ask ChatGPT and Google Bard to fulfill my curiosity.<br>\n",
    "<br>\n",
    "***My query was as below.***<br>\n",
    "\n",
    "> *I was recently wondering that NLP process could be different between Phonogram based languages like English, and Ideogram based language like Chinese.<br>\n",
    "Like Tokenization, Embedding, Vectorization, Lemmatization, Stemming, etc.<br>\n",
    "Could you tell me the main differences in process of Natural Language Processing?*\n",
    ">\n",
    "\n",
    "Below are the responses from the LLMs (redirected to my Notion page)<br><br>\n",
    "**`ChatGPT`**<br>\n",
    "[GPT - NLP Phonogram Ideogram.pdf](https://www.notion.so/jason-heesang-lee/Ideogram-Based-Language-vs-Phonogram-Based-Language-6ba064e320e2413aaba60f6aba5e6e19?pvs=4#b378a20a10ca4580b4442a5a4486b87f)<br>\n",
    "<br>\n",
    "**`Google Bard`**<br>\n",
    "[Bard - NLP Phonogram Ideogram.pdf](https://www.notion.so/jason-heesang-lee/Ideogram-Based-Language-vs-Phonogram-Based-Language-6ba064e320e2413aaba60f6aba5e6e19?pvs=4#11e5c642f4394e1c82311677d4ea1268)<br>\n",
    "<br>\n",
    "There were some points that were interesting.<br>\n",
    "<br>\n",
    "First, both GPT and Bard told me that the Tokenization process might be harder on Ideogram-based Languages.<br>\n",
    "Tokenization is the process of decomposing a sentence into words.<br>\n",
    "As each word is represented in a way as a sequence of characters, it would be easier for the tokenizing process.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08430dd",
   "metadata": {
    "papermill": {
     "duration": 0.044352,
     "end_time": "2023-09-25T12:48:50.778626",
     "exception": false,
     "start_time": "2023-09-25T12:48:50.734274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "My plan is to open up each key modules and figure out how they work.<br>\n",
    "For Jieba, I will try to understand how this module is able to perform such segmentation.<br>\n",
    "Also for DeBERTa Tokenizer or AutoTokenizer (I need to find out which module makes the difference), I want to know the inner logic that processes English and Chinese with the same lines of code.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a08457",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:50.870002Z",
     "iopub.status.busy": "2023-09-25T12:48:50.868833Z",
     "iopub.status.idle": "2023-09-25T12:48:56.048393Z",
     "shell.execute_reply": "2023-09-25T12:48:56.047132Z"
    },
    "papermill": {
     "duration": 5.228583,
     "end_time": "2023-09-25T12:48:56.051372",
     "exception": false,
     "start_time": "2023-09-25T12:48:50.822789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/sentencepiece-pb2/\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import re\n",
    "import nltk\n",
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sentencepiece_pb2\n",
    "import sentencepiece as spm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a470293",
   "metadata": {
    "papermill": {
     "duration": 0.045324,
     "end_time": "2023-09-25T12:48:56.141543",
     "exception": false,
     "start_time": "2023-09-25T12:48:56.096219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>\n",
    "<strong><a href=\"#jieba\"> 🔻 Jieba</a></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d949fc9",
   "metadata": {
    "papermill": {
     "duration": 0.043455,
     "end_time": "2023-09-25T12:48:56.228488",
     "exception": false,
     "start_time": "2023-09-25T12:48:56.185033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset\n",
    "I have brought [Chinese Daily News](https://www.kaggle.com/datasets/noxmoon/chinese-official-daily-news-since-2016) by [@noxmoon](https://www.kaggle.com/noxmoon) & True news from [Fake and Real News](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset) by [@clmentbisaillon](https://www.kaggle.com/clmentbisaillon) to compare the process.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57f9e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:56.322045Z",
     "iopub.status.busy": "2023-09-25T12:48:56.321409Z",
     "iopub.status.idle": "2023-09-25T12:48:58.124320Z",
     "shell.execute_reply": "2023-09-25T12:48:58.122895Z"
    },
    "papermill": {
     "duration": 1.853445,
     "end_time": "2023-09-25T12:48:58.127467",
     "exception": false,
     "start_time": "2023-09-25T12:48:56.274022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tag</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队...</td>\n",
       "      <td>中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>中央军委印发《关于深化国防和军队改革的意见》</td>\n",
       "      <td>经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>《习近平关于严明党的纪律和规矩论述摘编》出版发行</td>\n",
       "      <td>由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>以实际行动向党中央看齐 向高标准努力</td>\n",
       "      <td>广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>详细全文</td>\n",
       "      <td>【年终特稿】关键之年 改革挺进深水区</td>\n",
       "      <td>刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tag                                           headline  \\\n",
       "0  2016-01-01  详细全文  陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队...   \n",
       "1  2016-01-01  详细全文                             中央军委印发《关于深化国防和军队改革的意见》   \n",
       "2  2016-01-01  详细全文                           《习近平关于严明党的纪律和规矩论述摘编》出版发行   \n",
       "3  2016-01-01  详细全文                                 以实际行动向党中央看齐 向高标准努力   \n",
       "4  2016-01-01  详细全文                                 【年终特稿】关键之年 改革挺进深水区   \n",
       "\n",
       "                                             content  \n",
       "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...  \n",
       "1  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...  \n",
       "2  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...  \n",
       "3  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...  \n",
       "4  刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cn_df = pd.read_csv('/kaggle/input/chinese-official-daily-news-since-2016/chinese_news.csv', encoding='utf-8')\n",
    "display(cn_df.head(5))\n",
    "print()\n",
    "en_df = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\n",
    "display(en_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41475e13",
   "metadata": {
    "papermill": {
     "duration": 0.04507,
     "end_time": "2023-09-25T12:48:58.217571",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.172501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Checking DataFrame Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e78444",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:58.309294Z",
     "iopub.status.busy": "2023-09-25T12:48:58.308818Z",
     "iopub.status.idle": "2023-09-25T12:48:58.344379Z",
     "shell.execute_reply": "2023-09-25T12:48:58.343141Z"
    },
    "papermill": {
     "duration": 0.085414,
     "end_time": "2023-09-25T12:48:58.347408",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.261994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20738 entries, 0 to 20737\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   date      20738 non-null  object\n",
      " 1   tag       20738 non-null  object\n",
      " 2   headline  20738 non-null  object\n",
      " 3   content   20631 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 648.2+ KB\n",
      "cn_df.info() :\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"cn_df.info() :\\n{cn_df.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b261a8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:58.441463Z",
     "iopub.status.busy": "2023-09-25T12:48:58.440963Z",
     "iopub.status.idle": "2023-09-25T12:48:58.459979Z",
     "shell.execute_reply": "2023-09-25T12:48:58.458829Z"
    },
    "papermill": {
     "duration": 0.068954,
     "end_time": "2023-09-25T12:48:58.462538",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.393584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21417 entries, 0 to 21416\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    21417 non-null  object\n",
      " 1   text     21417 non-null  object\n",
      " 2   subject  21417 non-null  object\n",
      " 3   date     21417 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 669.4+ KB\n",
      "en_df.info() :\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"en_df.info() :\\n{en_df.info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fee161",
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 0.048894,
     "end_time": "2023-09-25T12:48:58.559105",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.510211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dropping unnecessary columns\n",
    "I will drop date & tag columns from each DataFrame.<br>\n",
    "And matched the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fa5204",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:58.653279Z",
     "iopub.status.busy": "2023-09-25T12:48:58.652498Z",
     "iopub.status.idle": "2023-09-25T12:48:58.666540Z",
     "shell.execute_reply": "2023-09-25T12:48:58.665105Z"
    },
    "papermill": {
     "duration": 0.06477,
     "end_time": "2023-09-25T12:48:58.669484",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.604714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cn_df = cn_df.drop(columns=['date', 'tag'])\n",
    "en_df = en_df.drop(columns=['date', 'subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb19ea34",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:58.764578Z",
     "iopub.status.busy": "2023-09-25T12:48:58.764122Z",
     "iopub.status.idle": "2023-09-25T12:48:58.769350Z",
     "shell.execute_reply": "2023-09-25T12:48:58.768401Z"
    },
    "papermill": {
     "duration": 0.05446,
     "end_time": "2023-09-25T12:48:58.772238",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.717778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(cn_df.columns) :\n",
      "['headline', 'content']\n"
     ]
    }
   ],
   "source": [
    "print(f\"list(cn_df.columns) :\\n{list(cn_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c6f0b2",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:58.868764Z",
     "iopub.status.busy": "2023-09-25T12:48:58.867656Z",
     "iopub.status.idle": "2023-09-25T12:48:58.880845Z",
     "shell.execute_reply": "2023-09-25T12:48:58.879462Z"
    },
    "papermill": {
     "duration": 0.062026,
     "end_time": "2023-09-25T12:48:58.883148",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.821122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(en_df.columns) :\n",
      "['headline', 'content']\n"
     ]
    }
   ],
   "source": [
    "en_df = en_df.rename(columns={'title':'headline', 'text':'content'})\n",
    "print(f\"list(en_df.columns) :\\n{list(en_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59116981",
   "metadata": {
    "papermill": {
     "duration": 0.04481,
     "end_time": "2023-09-25T12:48:58.973286",
     "exception": false,
     "start_time": "2023-09-25T12:48:58.928476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Most of NLP Technique retrieved from [@jhoward](https://www.kaggle.com/jhoward)'s notebook\n",
    "***[Getting started with NLP for absolute beginners](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d02362c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:59.066113Z",
     "iopub.status.busy": "2023-09-25T12:48:59.065674Z",
     "iopub.status.idle": "2023-09-25T12:48:59.073186Z",
     "shell.execute_reply": "2023-09-25T12:48:59.072086Z"
    },
    "papermill": {
     "duration": 0.057988,
     "end_time": "2023-09-25T12:48:59.076499",
     "exception": false,
     "start_time": "2023-09-25T12:48:59.018511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn_example :\n",
      "                                            headline  \\\n",
      "0  陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队...   \n",
      "\n",
      "                                             content  \n",
      "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...  \n"
     ]
    }
   ],
   "source": [
    "cn_example = pd.DataFrame(cn_df.iloc[0]).T\n",
    "print(f\"cn_example :\\n{cn_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607ca584",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:59.167939Z",
     "iopub.status.busy": "2023-09-25T12:48:59.167547Z",
     "iopub.status.idle": "2023-09-25T12:48:59.175348Z",
     "shell.execute_reply": "2023-09-25T12:48:59.174203Z"
    },
    "papermill": {
     "duration": 0.056588,
     "end_time": "2023-09-25T12:48:59.177743",
     "exception": false,
     "start_time": "2023-09-25T12:48:59.121155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_example :\n",
      "                                            headline  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "\n",
      "                                             content  \n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  \n"
     ]
    }
   ],
   "source": [
    "en_example = pd.DataFrame(en_df.iloc[0]).T\n",
    "print(f\"en_example :\\n{en_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ea1db",
   "metadata": {
    "papermill": {
     "duration": 0.045579,
     "end_time": "2023-09-25T12:48:59.269464",
     "exception": false,
     "start_time": "2023-09-25T12:48:59.223885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CN Text Preprocessing\n",
    "##### CN Definition retrieved from [Baidu Wenku](https://wenku.baidu.com/view/039d6d4e551252d380eb6294dd88d0d233d43cc8.html?_wkts_=1693548615550&bdQuery=%E4%B8%AD%E6%96%87+%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80+%E5%89%8D%E5%A4%84%E7%90%86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5870414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:59.362465Z",
     "iopub.status.busy": "2023-09-25T12:48:59.362002Z",
     "iopub.status.idle": "2023-09-25T12:48:59.367996Z",
     "shell.execute_reply": "2023-09-25T12:48:59.367194Z"
    },
    "papermill": {
     "duration": 0.054435,
     "end_time": "2023-09-25T12:48:59.369965",
     "exception": false,
     "start_time": "2023-09-25T12:48:59.315530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stopwords = [k.strip() for k in open('/kaggle/input/english-and-chinese-stopwords/stopwords.txt', encoding='utf8').readlines() if k.strip() != '']\n",
    "\n",
    "def find_chinese(text):\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    chinese_txt = re.sub(pattern,'',text)\n",
    "    return str(chinese_txt)\n",
    "\n",
    "def cut_words(text):\n",
    "    jieba_txt = ' '.join(jieba.cut(find_chinese(text), cut_all=False))\n",
    "    return jieba_txt\n",
    "\n",
    "# def seg_sentence(text_list):\n",
    "#     seg_text = [word for word in text_list if word not in stopwords]\n",
    "#     return seg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce102c6",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:59.462597Z",
     "iopub.status.busy": "2023-09-25T12:48:59.462161Z",
     "iopub.status.idle": "2023-09-25T12:48:59.469728Z",
     "shell.execute_reply": "2023-09-25T12:48:59.468378Z"
    },
    "papermill": {
     "duration": 0.056991,
     "end_time": "2023-09-25T12:48:59.472229",
     "exception": false,
     "start_time": "2023-09-25T12:48:59.415238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cn_text.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile cn_text.txt\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4bcdfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:48:59.565420Z",
     "iopub.status.busy": "2023-09-25T12:48:59.564954Z",
     "iopub.status.idle": "2023-09-25T12:49:00.636367Z",
     "shell.execute_reply": "2023-09-25T12:49:00.635239Z"
    },
    "papermill": {
     "duration": 1.125593,
     "end_time": "2023-09-25T12:49:00.643031",
     "exception": false,
     "start_time": "2023-09-25T12:48:59.517438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.029 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>陆军 领导 机构 火箭 军 战略 支援 部队 成立 大会 在京举行 习近平 向 中国人民解放...</td>\n",
       "      <td>中国人民解放军 陆军 领导 机构 中国人民解放军 火箭 军 中国人民解放军 战略 支援 部队...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  陆军 领导 机构 火箭 军 战略 支援 部队 成立 大会 在京举行 习近平 向 中国人民解放...   \n",
       "\n",
       "                                             content  \n",
       "0  中国人民解放军 陆军 领导 机构 中国人民解放军 火箭 军 中国人民解放军 战略 支援 部队...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cn_text_file = open('/kaggle/working/cn_text.txt', 'w')\n",
    "cn_text = ''\n",
    "for column in cn_example.columns:\n",
    "    temp = []\n",
    "    for row in tqdm(range(cn_example.shape[0])):\n",
    "        text = cn_example.iloc[row][column]\n",
    "        text = cut_words(text)\n",
    "        \n",
    "        temp.append(text)\n",
    "        cn_text = cn_text + '; ' + text\n",
    "#     text = seg_sentence(temp)\n",
    "    cn_example[column] = pd.Series(temp)\n",
    "\n",
    "#     cn_example[column] = pd.Series(seg_sentence(temp))\n",
    "cn_text_file.write(cn_text)\n",
    "display(cn_example.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636b600",
   "metadata": {
    "papermill": {
     "duration": 0.047901,
     "end_time": "2023-09-25T12:49:00.765847",
     "exception": false,
     "start_time": "2023-09-25T12:49:00.717946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EN Text Preproecessing\n",
    "I will drop the names of the news companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4421fd",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:00.863813Z",
     "iopub.status.busy": "2023-09-25T12:49:00.863328Z",
     "iopub.status.idle": "2023-09-25T12:49:00.870690Z",
     "shell.execute_reply": "2023-09-25T12:49:00.869236Z"
    },
    "papermill": {
     "duration": 0.060045,
     "end_time": "2023-09-25T12:49:00.873187",
     "exception": false,
     "start_time": "2023-09-25T12:49:00.813142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing en_text.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile en_text.txt\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7805160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:00.970843Z",
     "iopub.status.busy": "2023-09-25T12:49:00.969388Z",
     "iopub.status.idle": "2023-09-25T12:49:00.987635Z",
     "shell.execute_reply": "2023-09-25T12:49:00.986577Z"
    },
    "papermill": {
     "duration": 0.06948,
     "end_time": "2023-09-25T12:49:00.989836",
     "exception": false,
     "start_time": "2023-09-25T12:49:00.920356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1231.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>The head of a conservative Republican faction ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "\n",
       "                                             content  \n",
       "0  The head of a conservative Republican faction ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = []\n",
    "en_text_file = open('/kaggle/working/en_text.txt', 'w')\n",
    "\n",
    "en_text = ''\n",
    "for row in tqdm(range(en_example.shape[0])):\n",
    "    text_h = en_df.headline[row]\n",
    "    text = \" \".join(en_example.content[row].split(' - ')[1:])\n",
    "    en_text = en_text + '; ' + text_h\n",
    "    en_text = en_text + \"; \" + text\n",
    "    temp.append(text)\n",
    "\n",
    "en_text_file.write(en_text)\n",
    "en_example.content = pd.Series(temp)\n",
    "display(en_example.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eefee9b",
   "metadata": {
    "papermill": {
     "duration": 0.049564,
     "end_time": "2023-09-25T12:49:01.087193",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.037629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Checking text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885d4b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:01.187670Z",
     "iopub.status.busy": "2023-09-25T12:49:01.186105Z",
     "iopub.status.idle": "2023-09-25T12:49:01.194536Z",
     "shell.execute_reply": "2023-09-25T12:49:01.192601Z"
    },
    "papermill": {
     "duration": 0.063002,
     "end_time": "2023-09-25T12:49:01.197407",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.134405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "; 陆军 领导 机构 火箭 军 战略 支援 部队 成立 大会 在京举行 习近平 向 中国人民解放军 陆军 火箭 军 战略 支援 部队 授予 军旗 并致 训词; 中国人民解放军 陆军 领导 机构 中国人民解放军 火箭 军 中国人民解放军 战略 支援 部队 成立 大会 年月日 在 八一 大楼 隆重举行 中共中央 总书记 国家 主席 中央军委 主席 习近平 向 陆军 火箭 军 战略 支援 部队 授予 军旗 并致 训词 代表 党中央 和 中央军委 向 同志 们 向 全军 部队 致以 热烈祝贺 强调 要 坚持 以党 在 新形势下 的 强军 目标 为 引领 深入 贯彻 新形势下 军事 战略方针 全面实施 改革 强军 战略 坚定不移 走 中国 特色 强军 之 路 时刻 听从 党和人民 召唤 忠实 履行 党和人民 赋予 的 神圣 使命 为 实现 中国 梦 强军 梦 作出 新 的 更 大 的 贡献 下午 时 成立 大会 开始 全场 高 唱国歌 仪仗 礼兵 护卫 着 鲜艳 军旗 正 步行 进 到 主席台 前 习近平 将军 旗 郑重 授予 陆军 司令员 李 作成 政治委员 刘雷 火箭 军 司令员 魏凤 和 政治委员 王家 胜 战略 支援 部队 司令员 高津 政治委员 刘福 连 陆军 火箭 军 战略 支援 部队 主要 领导 军容严整 精神抖擞 向 习近平 敬礼 从 习近平 手中 接过 军旗 全场 官兵 向 军旗 敬礼 授旗仪式 后 习近平 致 训词 他 指出 成立 陆军 领导 机构 火箭 军 战略 支援 部队 是 党中央 和 中央军委 着眼 实现 中国 梦 强军 梦 作出 的 重大 决策 是 构建 中国 特色 现代 军事力量 体系 的 战略 举措 必将 成为 我军 现代化 建设 的 一个 重要 里程碑 载入 人民军队 史册 习近平 强调 陆军 是 党 最早 建立 和 领导 的 武装力量 历史悠久 敢 打 善战 战功卓著 为 党和人民 建立 了 不朽 功勋 陆军 对 维护 国家主权 安全 和 发展 利益 具有 不可 替代 的 作用 陆军 全体官兵 要 弘扬 陆军 光荣传统 和 优良作风 适应 信息化 时代 陆军 建设 模式 和 运用 方式 的 深刻 变化 探索 陆军 发展 特点 和 规律 按照 机动 作战 立体 攻防 的 战略 要求 加强 顶层 设计 和 领导 管理 优化 力量 结构 和 部队 编成 加快 实现 区域 防卫 型 向 全域 作战 型 转变 努力 建设 一支 强大 的 现代化 新型 陆军 习近平 强调 火箭 军是 我国 战略 威慑 的 核心 力量 是 我国 大国 地位 的 战略 支撑 是 维护 国家 安全 的 重要 基石 火箭 军 全体官兵 要 把握 火箭 军 的 职能 定位 和 使命 任务 按照 核常 兼备 全域 慑战 的 战略 要求 增强 可信 可靠 的 核威慑 和 核反击 能力 加强 中 远程 精确 打击 力量 建设 增强 战略 制衡 能力 努力 建设 一支 强大 的 现代化 火箭 军 习近平 强调 战略 支援 部队 是 维护 国家 安全 的 新型 作战 力量 是 我军 新质 作战 能力 的 重要 增长点 战略 支援 部队 全体官兵 要 坚持 体系 融合 军民 融合 努力 在 关键 领域 实现 跨越 发展 高标准 高起点 推进 新型 作战 力量 加速 发展 一体 发展 努力 建设 一支 强大 的 现代化 战略 支援 部队 习近平 强调 你们 要 坚持 以党 在 新形势下 的 强军 目标 为 引领 深入 贯彻 新形势下 军事 战略方针 全面实施 改革 强军 战略 坚定不移 走 中国 特色 强军 之 路 时刻 听从 党和人民 的 召唤 忠诚 履行 党和人民 赋予 的 神圣 使命 为 实现 中国 梦 强军 梦 作出 新 的 更 大 的 贡献 刘雷 王家 胜 刘福 连 分别 代表 陆军 火箭 军 战略 支援 部队 发言 一致 表示 坚决贯彻 习 主席 训词 任何 时候 任何 情况 下 都 坚决 听从 党中央 中央军委 和习 主席 指挥 牢记 职责 使命 忠诚 履职 尽责 带领 部队 圆满完成 各项任务 成立 大会 上 中共中央政治局 委员 中央军委 副 主席 范 长龙 宣读 了 习近平 主席 签发 的 中央军委 关于 组建 陆军 领导 机构 火箭 军 战略 支援 部队 及其 领导班子 成员 任职 命令 和 决定 中共中央政治局 委员 中央军委 副 主席 许其亮 主持 大会 大会 在 嘹亮 的 军 歌声 中 结束 之后 习近平 亲切 接见 了 陆军 火箭 军 战略 支援 部队 领导班子 成员 并 同 大家 合影留念 中央军委 委员 常万全 房峰辉 张阳 赵克石 张 又 侠 吴 胜利 马晓天 出席 大会 四 总部 驻京 各大 单位 和 军委办公厅 领导 参加 大会\n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/working/cn_text.txt') as cn_text_file:\n",
    "    print(cn_text_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2b5316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:01.294894Z",
     "iopub.status.busy": "2023-09-25T12:49:01.294024Z",
     "iopub.status.idle": "2023-09-25T12:49:01.299522Z",
     "shell.execute_reply": "2023-09-25T12:49:01.298769Z"
    },
    "papermill": {
     "duration": 0.056092,
     "end_time": "2023-09-25T12:49:01.301578",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.245486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "; As U.S. budget fight looms, Republicans flip their fiscal script; The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. \n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/working/en_text.txt') as en_text_file:\n",
    "    print(en_text_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6c94b",
   "metadata": {
    "papermill": {
     "duration": 0.04673,
     "end_time": "2023-09-25T12:49:01.396020",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.349290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eecf65e",
   "metadata": {
    "papermill": {
     "duration": 0.046299,
     "end_time": "2023-09-25T12:49:01.491527",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.445228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div id = \"jieba\"> </div>\n",
    "\n",
    "# Jieba\n",
    "***I guess this is where I have to examine the [Jieba Github](https://github.com/fxsjy/jieba)...!***\n",
    "\n",
    "**This is how the repository looks like.**<br>\n",
    "<img src=\"https://github.com/jasonheesanglee/Ideogram_Phonogram/blob/main/IDEOPHONO/jieba_main.png?raw=true\" height=\"100\" /><br>\n",
    "There are 3 different directories - extra_dict, jieba, test, and some config files.<br>\n",
    "Let's first look into README.md to grasp the concept of what this module is in the end.<br>\n",
    "I brought English version of README.<br>\n",
    "(The content is identical with the Chinese version.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a400e22",
   "metadata": {
    "papermill": {
     "duration": 0.048485,
     "end_time": "2023-09-25T12:49:01.587293",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.538808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br><br>\n",
    "<strong><a href=\"#jieba_read_me\"> 🔻 Jieba Read Me</a></strong><br>\n",
    "<strong><a href=\"#jieba_main_function\"> 🔻 Jieba Main Function </a></strong><br>\n",
    "<strong><a href=\"#jieba_cut\"> 🔻 Jieba Cut Method </a></strong><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0abd0",
   "metadata": {
    "papermill": {
     "duration": 0.046096,
     "end_time": "2023-09-25T12:49:01.679687",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.633591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div id = \"jieba_read_me\"> </div>\n",
    "\n",
    "## jieba\n",
    "-----------------------------------\n",
    "\n",
    "*Jieba (Chinese for \"to stutter\") Chinese text segmentation: built to be the best Python Chinese word segmentation module.*<br>\n",
    "***This is the explanation of what jieba is***<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3aeeb",
   "metadata": {
    "papermill": {
     "duration": 0.046362,
     "end_time": "2023-09-25T12:49:01.772942",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.726580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Features\n",
    "-----------------------------------\n",
    "- Support three types of segmentation mode:\n",
    "1. Accurate Mode attempts to cut the sentence into the most accurate segmentations, which is suitable for text analysis.\n",
    "2. Full Mode gets all the possible words from the sentence. Fast but not accurate.\n",
    "3. Search Engine Mode, based on the Accurate Mode, attempts to cut long words into several short words, which can raise the recall rate. Suitable for search engines.\n",
    "- Supports Traditional Chinese\n",
    "- Supports customized dictionaries\n",
    "- MIT License\n",
    "\n",
    "***There are 3 different segmentation modes, and the usage of each mode differs from the purpose of the usage.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31090c",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.045989,
     "end_time": "2023-09-25T12:49:01.865649",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.819660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Online demo \n",
    "-----------------------------------\n",
    "\n",
    "[http://jiebademo.ap01.aws.af.cm/](http://jiebademo.ap01.aws.af.cm/)<br>\n",
    "***This online demo is not working anymore (404 Error)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdc883",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.046059,
     "end_time": "2023-09-25T12:49:01.958096",
     "exception": false,
     "start_time": "2023-09-25T12:49:01.912037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Usage\n",
    "-----------------------------------\n",
    "\n",
    "- Fully automatic installation: `easy_install jieba` or `pip install jieba`<br>\n",
    "- Semi-automatic installation: Download [http://pypi.python.org/pypi/jieba/](https://pypi.org/project/jieba/) , run `python setup.py install` after extracting.<br>\n",
    "- Manual installation: place the `jieba` directory in the current directory or python `site-packages` directory.<br>\n",
    "- `import jieba`.<br>\n",
    "\n",
    "***This section explains how to import the module***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a038c0",
   "metadata": {
    "papermill": {
     "duration": 0.046491,
     "end_time": "2023-09-25T12:49:02.051055",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.004564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Algorithm\n",
    "-----------------------------------\n",
    "\n",
    "- Based on a prefix dictionary structure to achieve efficient word graph scanning. Build a directed acyclic graph (DAG) for all possible word combinations.\n",
    "- Use dynamic programming to find the most probable combination based on the word frequency.\n",
    "- For unknown words, a HMM-based model is used with the Viterbi algorithm.\n",
    "\n",
    "***Wait, there are so many terms I have no clue about.<br>What is Directed Acyclic Graph? <br>What is HMM-based model? <br>What is Viterbi algorithm?***\n",
    "\n",
    "#### Directed Acyclic Graph (DAG)\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Tred-G.svg/1920px-Tred-G.svg.png\" width=200 />\n",
    "\n",
    "Based on [Wikipedia](https://en.wikipedia.org/wiki/Directed_acyclic_graph), Directed Acyclic Graph is a \n",
    ">*Directed graph with no directed cycles. A directed graph is a DAG if and only if it can be [topologically ordered](https://en.wikipedia.org/wiki/Topological_order), by arranging the vertices as a linear ordering that is consistent with all edge directions.* <br>\n",
    "\n",
    "What? still no clue yet, let's move on to the definitions.<br>\n",
    "\n",
    "> *A graph is formed by vertices and by edges connecting pairs of vertices, where the vertices can be any kind of object that is connected in pairs by edges. In the case of a directed graph, each edge has an orientation, from one vertex to another vertex. A path in a directed graph is a sequence of edges having the property that the ending vertex of each edge in the sequence is the same as the starting vertex of the next edge in the sequence; a path forms a cycle if the starting vertex of its first edge equals the ending vertex of its last edge. A directed acyclic graph is a directed graph that has no cycles.*<br><br>\n",
    "\n",
    "**TL;DR** (I shouldn't though)\n",
    "\n",
    "Instead of learning it from Wikipedia, I searched Google a bit more and completely understood the concept from [StackExchange](https://math.stackexchange.com/questions/3782987/difference-between-oriented-graph-and-directed-acyclic-graphs-dag#:~:text=Basically%20directed%20graphs%20can%20have,two%20vertices%20A%20and%20B.&text=In%20mathematics%2C%20particularly%20graph%20theory,graph%20with%20no%20directed%20cycles.)<br>\n",
    "Please correct me if I am wrong;<br>\n",
    "Basically DAG is a graph of number of vertices connected by edges (with direction), and this edge doesn't go back but only go forth.<br> Which makes this graph a graph with direction, but not circulating.<br>\n",
    "***OH*** That is why its name is **Directed** **A**cyclic Graph!!\n",
    "\n",
    "#### HMM-based model\n",
    "Based on this [article](https://medium.com/data-science-in-your-pocket/pos-tagging-using-hidden-markov-models-hmm-viterbi-algorithm-in-nlp-mathematics-explained-d43ca89347c4) by [Mehul Gupta](https://medium.com/@mehulgupta_7991), to understand the conecept of Hidden Markov Model (HMM)-based model, we need to understand what ***Markov Chain*** is.<br>\n",
    "It gave a simple definition of Markov chain and I completely got it!\n",
    "> *A Markov chain is a model that tells us something about the probabilities of sequences of random states/variables. A Markov chain makes a very strong assumption that if we want to predict the future in the sequence, all that matters is the current state. All the states before the current state have no impact on the future except via the current state.*\n",
    "\n",
    "Below is an example the writer gave, and I believe this is just a perfect example.\n",
    "> *A Markov Chain model based on Weather might have Hot, Cool, and Rainy as its states & to predict tomorrow’s weather you could examine today’s weather but yesterday’s weather isn’t significant in the prediction.*<br>\n",
    "\n",
    "Below are specified all the components of Markov Chains.\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1104/format:webp/1*tI5HGo_cFTxgcxiEDHQMOw.png\" height=100 />\n",
    "\n",
    "Moving on to ***HMM-based model***.<br>\n",
    "> *Sometimes, what we want to predict is a sequence of states that aren’t directly observable in the environment. Though we are given another sequence of states that are observable in the environment, these hidden states have some dependence on the observable states.*\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EXjrDa28pUnGmI0ehjhR8A.png\" height=100 /><br>\n",
    "> *In the above HMM, we are given Walk, Shop & Clean as observable states. But we are more interested in tracing the sequence of the hidden states that will be followed which are Rainy & Sunny.*<br>\n",
    "\n",
    "***As per my understanding, simply saying, this is an advanced step after Markov Chain.<br>\n",
    "According to the provided image, actions are the subjects that we are predicting, and the original factors of Markov Chain example (weather conditions), are the hidden layer (state) that influences the prediction of the action.***<br>\n",
    "\n",
    "Hidden Markov Model is needed for Part of Speech Tagging (Categories of words; verbs, nouns, actions, expresssions and so on).<br>\n",
    "> If you notice closely, we can have the words in a sentence as Observable States (given to us in the data) but their POS Tags as Hidden states and hence we use HMM for estimating POS tags. It must be noted that we call Observable states ‘Observation’ & Hidden states ‘States’.\n",
    "\n",
    "Below are the specified all the components of HMM<br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1240/format:webp/1*ARltONawvqjzKeZOMvD-tg.png\" height=100 /><br>\n",
    "> *$Q$: Set of possible Tags<br><br>\n",
    "$A$: The A matrix contains the tag transition probabilities<br><br>\n",
    "$P$($ti$|$ti−1$) which represent the probability of a tag occurring given the previous tag. Example: Calculating A[Verb][Noun]:\n",
    "$P$ (Noun|Verb): Count(Noun & Verb)/Count(Verb)<br><br>\n",
    "$O$: Sequence of observation (words in the sentence)<br><br>\n",
    "$B$: The $B$ emission probabilities, $P(wi|ti)$, represent the probability, given a tag (say Verb), that it will be associated with a given word (say Playing). The emission probability $B$[Verb][Playing] is calculated using:<br><br>\n",
    "$P$(Playing | Verb): Count (Playing & Verb)/ Count (Verb)<br><br>\n",
    "It must be noted that we get all these Count() from the corpus itself used for training.<br><br>\n",
    "A sample HMM with both ‘A’ & ‘B’ matrices will look like this :*\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1026/format:webp/1*TY_h8WgfRH7iJy1PZKN5UQ.png\" height=100 />\n",
    "\n",
    "> *Here, the black, straight arrows represent values of Transition matrix ‘A’ while the dotted black arrow represents Emission Matrix ‘B’ for a system with Q: {MD, VB, NN}.*<br>\n",
    "\n",
    "The writer has also explained about Decoding using HMMs.<br>\n",
    "While skimming through the upcoming content (Viterbi Algorithm) of the same writer, I thought it was necessary to go through this part as well.<br>\n",
    "> Given an input as HMM (Transition Matrix, Emission Matrix) and a sequence of observations $O = o1, o2, …, oT$ (Words in sentences of a corpus), find the most probable sequence of states $Q = q1q2q3…, qT$ (POS Tags in our case)<br>\n",
    "The two major assumptions followed while decoding tag sequence using HMMs:\n",
    "> - The probability of a word appearing depends only on its **own tag** and is independent of neighboring words and tags.\n",
    "> - The probability of a tag depends only on ***the previous tag(bigram HMM)*** that occured rather than the entire previous tag sequence i.e. shows Markov Property. Though we can be flexible with this.\n",
    "\n",
    "Which, I believe, means unlikely to Markov Chain, it references on the previous tag, but surely, not the entire previous tags.<br>\n",
    "Let's move on to Viterbi Algorithm\n",
    "\n",
    "### Viterbi Algorithm\n",
    "[Mehul Gupta](https://medium.com/@mehulgupta_7991) has also well explained about Viterbi Algorithm from the same [article](https://medium.com/data-science-in-your-pocket/pos-tagging-using-hidden-markov-models-hmm-viterbi-algorithm-in-nlp-mathematics-explained-d43ca89347c4).<br><br>\n",
    "Viterbi Algorithm is a decoding algorithm used for HMMs.<br>\n",
    "The writer mentioned that setting up Lattice, the probability matrix, is necessary.<br>\n",
    "In prior to proceed further, being familiar with the tags of Part of Speech would be necessary.<br><br>\n",
    "\n",
    "<img src=\"https://m-clark.github.io/text-analysis-with-R/img/POS-Tags.png\" height=200 /> <br>\n",
    "[***Source: Text Analysis in R by Michael Clark***](https://m-clark.github.io/text-analysis-with-R/part-of-speech-tagging.html)<br>\n",
    "\n",
    "    \n",
    "With a sample sentence ***Janet will back the bill***, it will look like this on Lattice:<br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1080/format:webp/1*8-5KZVj-_jZOWN83gGhD5A.png\" height=100 />\n",
    "\n",
    "As all the words in this sentence are commonly used words, there are no word with an \"Unknown\" tag.<br><br>\n",
    "\n",
    "Each cell of the lattice is represented by $V_t(j)$, $V$ for Viterbi, $t$ for column, $j$ for row.<br>\n",
    "This represents probability that the HMM is in $state j(present POS Tag)$ after seeing the $first t observations (past words for which lattice values has been calculated)$.<br>\n",
    "This passes through the most **probable state sequence (Previous POS Tag)** $q_1, q_2, ... q_t-1$.<br>\n",
    "Which means, if we have the word **back**, we most probably will have **Janet** and **will** in previous order.<br>\n",
    "\n",
    "$V_t(j)$ is calculated as :\n",
    "$$V_t(j) = max: V_t-1*a(i,j)* b_j(O_t)$$\n",
    "where we got ‘a’(transition matrix) & ‘b’(emission matrix) from the HMM part calculations discussed above.:<br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1014/format:webp/1*1UylhpDw7suhH9WpnPYFaw.png\" height=20 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9997c79",
   "metadata": {
    "papermill": {
     "duration": 0.047945,
     "end_time": "2023-09-25T12:49:02.146134",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.098189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>\n",
    "<strong><a href=\"#jieba\"> 🔺 Top of Jieba</a></strong><br>\n",
    "<strong><a href=\"#jieba_read_me\"> 🔺 Jieba Read Me</a></strong><br><br>\n",
    "<strong><a href=\"#jieba_cut\"> 🔻 Jieba Cut Method </a></strong><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f20423",
   "metadata": {
    "papermill": {
     "duration": 0.047832,
     "end_time": "2023-09-25T12:49:02.242135",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.194303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div id = \"jieba_main_function\"> </div>\n",
    "\n",
    "### Main Functions\n",
    "-----------------------------------\n",
    "\n",
    "### 1. Cut\n",
    "-----------------------------------\n",
    "***This section shows how to use jieba.cut method.***<br>\n",
    "- The `jieba.cut` function accepts three input parameters: the first parameter is the string to be cut; the second parameter is `cut_all`, controlling the cut mode; the third parameter is to control whether to use the Hidden Markov Model.\n",
    "- `jieba.cut_for_search` accepts two parameter: the string to be cut; whether to use the Hidden Markov Model. This will cut the sentence into short words suitable for search engines.\n",
    "- The input string can be an unicode/str object, or a str/bytes object which is encoded in UTF-8 or GBK. Note that using GBK encoding is not recommended because it may be unexpectly decoded as UTF-8.\n",
    "- `jieba.cut` and `jieba.cut_for_search` returns an generator, from which you can use a `for` loop to get the segmentation result (in unicode).\n",
    "- `jieba.lcut` and `jieba.lcut_for_search` returns a list.\n",
    "- `jieba.Tokenizer(dictionary=DEFAULT_DICT)` creates a new customized Tokenizer, which enables you to use different dictionaries at the same time. `jieba.dt` is the default Tokenizer, to which almost all global functions are mapped.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc1e7d7e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:02.339653Z",
     "iopub.status.busy": "2023-09-25T12:49:02.338924Z",
     "iopub.status.idle": "2023-09-25T12:49:02.346557Z",
     "shell.execute_reply": "2023-09-25T12:49:02.345747Z"
    },
    "papermill": {
     "duration": 0.059578,
     "end_time": "2023-09-25T12:49:02.349011",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.289433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code example: Segmentation\n",
      "\n",
      "Output: \n",
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "print(\"Code example: Segmentation\\n\\nOutput: \")\n",
    "\n",
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "print()\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 默认模式\n",
    "print()\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")\n",
    "print(\", \".join(seg_list))\n",
    "print()\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6156ca",
   "metadata": {
    "papermill": {
     "duration": 0.049439,
     "end_time": "2023-09-25T12:49:02.446253",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.396814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Add a custom dictionary\n",
    "-----------------------------------\n",
    "***This section explains about how to load & modifying the dictionary***<br>\n",
    "#### Load dictionary\n",
    "- Developers can specify their own custom dictionary to be included in the jieba default dictionary. Jieba is able to identify new words, but you can add your own new words can ensure a higher accuracy.\n",
    "- Usage: `jieba.load_userdict(file_name)` # file_name is a file-like object or the path of the custom dictionary\n",
    "- The dictionary format is the same as that of `dict.txt`: one word per line; each line is divided into three parts separated by a space: word, word frequency, POS tag. If `file_name` is a path or a file opened in binary mode, the dictionary must be UTF-8 encoded.\n",
    "- The word frequency and POS tag can be omitted respectively. The word frequency will be filled with a suitable value if omitted.\n",
    "\n",
    "**Example:** <br>\n",
    "*创新办 3 i*<br>\n",
    "*云计算 5<br>\n",
    "凱特琳 nz<br>\n",
    "台中<br>*\n",
    "\n",
    "- Change a Tokenizer's `tmp_dir` and `cache_file` to specify the path of the cache file, for using on a restricted file system.\n",
    "\n",
    "**Example:** <br>\n",
    "*云计算 5<br>\n",
    "  李小福 2<br>\n",
    "  创新办 3<br>\n",
    "  [Before]： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /<br>\n",
    "  [After]：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /*<br>\n",
    "  \n",
    "#### Modify dictionary\n",
    "- Use add_word(word, freq=None, tag=None) and del_word(word) to modify the dictionary dynamically in programs.\n",
    "- Use suggest_freq(segment, tune=True) to adjust the frequency of a single word so that it can (or cannot) be segmented.\n",
    "- Note that HMM may affect the final result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142dcae4",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:02.544771Z",
     "iopub.status.busy": "2023-09-25T12:49:02.543799Z",
     "iopub.status.idle": "2023-09-25T12:49:02.551025Z",
     "shell.execute_reply": "2023-09-25T12:49:02.550290Z"
    },
    "papermill": {
     "duration": 0.05906,
     "end_time": "2023-09-25T12:49:02.553357",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.494297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example :\n",
      "\n",
      "如果/放到/post/中将/出错/。\n",
      "如果/放到/post/中/将/出错/。\n",
      "「/台/中/」/正确/应该/不会/被/切开\n",
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print(\"Example :\\n\")\n",
    ">>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "# 如果/放到/post/中将/出错/。\n",
    ">>> jieba.suggest_freq(('中', '将'), True)\n",
    "# 494\n",
    ">>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "# 如果/放到/post/中/将/出错/。\n",
    ">>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "# 「/台/中/」/正确/应该/不会/被/切开\n",
    ">>> jieba.suggest_freq('台中', True)\n",
    "# 69\n",
    ">>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "# 「/台中/」/正确/应该/不会/被/切开\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edbaca",
   "metadata": {
    "papermill": {
     "duration": 0.04641,
     "end_time": "2023-09-25T12:49:02.647264",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.600854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Keyword Extraction\n",
    "-----------------------------------\n",
    "***This section explains how to extract keywords***<br>\n",
    "\n",
    "`import jieba.analyse`\n",
    "\n",
    "- `jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())`<br>\n",
    "    - `sentence`: the text to be extracted<br>\n",
    "    - `topK`: return how many keywords with the highest TF/IDF weights. The default value is 20<br>\n",
    "`withWeight`: whether return TF/IDF weights with the keywords. The default value is False<br>\n",
    "    - `allowPOS`: filter words with which POSs are included. Empty for no filtering.<br>\n",
    "- `jieba.analyse.TFIDF(idf_path=None)` creates a new TF/IDF instance, `idf_path` specifies IDF file path.<br><br>\n",
    "\n",
    "**Example (keyword extraction)**<br>\n",
    "https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py<br>\n",
    "Developers can specify their own custom IDF corpus in jieba keyword extraction<br>\n",
    "- Usage: `jieba.analyse.set_idf_path(file_name)`<br>\n",
    "`file_name` is the path for the custom corpus<br>\n",
    "- Custom Corpus Sample: (not working)<br>\n",
    "https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big\n",
    "- Sample Code:<br>\n",
    "https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py<br>\n",
    "Developers can specify their own custom stop words corpus in jieba keyword extraction\n",
    "\n",
    "- Usage: `jieba.analyse.set_stop_words(file_name)`<br>\n",
    "`file_name` is the path for the custom corpus\n",
    "- Custom Corpus Sample:<br>\n",
    "https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt\n",
    "- Sample Code:<br>\n",
    "https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py<br>\n",
    "\n",
    "There's also a [TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf) implementation available.\n",
    "\n",
    "- Use: `jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))`\n",
    "\n",
    "Note that it filters POS by default.<br>\n",
    "`jieba.analyse.TextRank()` creates a new TextRank instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9acec",
   "metadata": {
    "papermill": {
     "duration": 0.046226,
     "end_time": "2023-09-25T12:49:02.739981",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.693755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4. Part of Speech Tagging\n",
    "-----------------------------------\n",
    "***This section explains how to tag Part of Words***<br>\n",
    "\n",
    "- `jieba.posseg.POSTokenizer(tokenizer=None)` creates a new customized Tokenizer.<br>\n",
    "`tokenizer` specifies the `jieba.Tokenizer` to internally use. jieba.posseg.dt is the default POSTokenizer.\n",
    "- Tags the POS of each word after segmentation, using labels compatible with ictclas.<br>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0924b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:02.835413Z",
     "iopub.status.busy": "2023-09-25T12:49:02.834972Z",
     "iopub.status.idle": "2023-09-25T12:49:03.304289Z",
     "shell.execute_reply": "2023-09-25T12:49:03.303032Z"
    },
    "papermill": {
     "duration": 0.5201,
     "end_time": "2023-09-25T12:49:03.306623",
     "exception": false,
     "start_time": "2023-09-25T12:49:02.786523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京国安 ns\n"
     ]
    }
   ],
   "source": [
    ">>> import jieba.posseg as pseg\n",
    ">>> words = pseg.cut(\"我爱北京国安\")\n",
    ">>> for w in words:\n",
    "...    print('%s %s' % (w.word, w.flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173d5dc",
   "metadata": {
    "papermill": {
     "duration": 0.046035,
     "end_time": "2023-09-25T12:49:03.398782",
     "exception": false,
     "start_time": "2023-09-25T12:49:03.352747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5. Parallel Processing\n",
    "-----------------------------------\n",
    "***This section explains about parallel processing.***<br><br>\n",
    "I believe this would be helpful on large dataset, but I will not implement this module on this notebook.<br>\n",
    "\n",
    "- Principle: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.\n",
    "\n",
    "- Based on the multiprocessing module of Python.\n",
    "\n",
    "- Usage:\n",
    "\n",
    "    - `jieba.enable_parallel(4)`<br>\n",
    "    Enable parallel processing. The parameter is the number of processes.\n",
    "    - `jieba.disable_parallel()`<br>\n",
    "    Disable parallel processing.\n",
    "    \n",
    "- **Example:** https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py\n",
    "\n",
    "- Result: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version.\n",
    "\n",
    "- Note that parallel processing supports only default tokenizers, `jieba.dt` and `jieba.posseg.dt`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c044f",
   "metadata": {
    "papermill": {
     "duration": 0.047199,
     "end_time": "2023-09-25T12:49:03.492334",
     "exception": false,
     "start_time": "2023-09-25T12:49:03.445135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6. Tokenize: return words with position\n",
    "-----------------------------------\n",
    "***This section explains about tokenizing words.***\n",
    "- The input must be unicode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e13f0643",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:03.589662Z",
     "iopub.status.busy": "2023-09-25T12:49:03.589227Z",
     "iopub.status.idle": "2023-09-25T12:49:03.595800Z",
     "shell.execute_reply": "2023-09-25T12:49:03.594743Z"
    },
    "papermill": {
     "duration": 0.059357,
     "end_time": "2023-09-25T12:49:03.598405",
     "exception": false,
     "start_time": "2023-09-25T12:49:03.539048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode\n",
      "\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "print('Default Mode\\n')\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "052674d3",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:03.693938Z",
     "iopub.status.busy": "2023-09-25T12:49:03.693527Z",
     "iopub.status.idle": "2023-09-25T12:49:03.700055Z",
     "shell.execute_reply": "2023-09-25T12:49:03.699017Z"
    },
    "papermill": {
     "duration": 0.057437,
     "end_time": "2023-09-25T12:49:03.702462",
     "exception": false,
     "start_time": "2023-09-25T12:49:03.645025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Mode\n",
      "\n",
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "print(\"Search Mode\\n\")\n",
    "result = jieba.tokenize(u'永和服装饰品有限公司',mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5490407",
   "metadata": {
    "papermill": {
     "duration": 0.04847,
     "end_time": "2023-09-25T12:49:03.799793",
     "exception": false,
     "start_time": "2023-09-25T12:49:03.751323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 7. ChineseAnalyzer for Whoosh\n",
    "-----------------------------------\n",
    "***This section explains about tokenizing words.***\n",
    "\n",
    "`from jieba.analyse import ChineseAnalyzer`<br>\n",
    "**Example:** (Copy & Pasted below to see the result)<br> https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d2aa9b0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:03.895597Z",
     "iopub.status.busy": "2023-09-25T12:49:03.895169Z",
     "iopub.status.idle": "2023-09-25T12:49:04.367435Z",
     "shell.execute_reply": "2023-09-25T12:49:04.365851Z"
    },
    "papermill": {
     "duration": 0.522997,
     "end_time": "2023-09-25T12:49:04.369822",
     "exception": false,
     "start_time": "2023-09-25T12:49:03.846825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of  水果世博园\n",
      "买<b class=\"match term0\">水果</b>然后来<b class=\"match term1\">世博园</b>\n",
      "==========\n",
      "result of  你\n",
      "second one <b class=\"match term0\">你</b> 中文测试中文 is even more interesting\n",
      "==========\n",
      "result of  first\n",
      "<b class=\"match term0\">first</b> document we’ve added\n",
      "==========\n",
      "result of  中文\n",
      "second one 你 <b class=\"match term0\">中文</b>测试<b class=\"match term0\">中文</b> is even more interesting\n",
      "==========\n",
      "result of  交换机\n",
      "干事每月经过下属科室都要亲口交代24口<b class=\"match term0\">交换机</b>等技术性器件的安装工作\n",
      "==========\n",
      "result of  交换\n",
      "咱俩<b class=\"match term0\">交换</b>一下吧\n",
      "干事每月经过下属科室都要亲口交代24口<b class=\"match term0\">交换</b>机等技术性器件的安装工作\n",
      "==========\n",
      "我\n",
      "好\n",
      "朋友\n",
      "是\n",
      "李明\n",
      "我\n",
      "爱\n",
      "北京\n",
      "国安\n",
      "北京国安\n",
      "ibm\n",
      "microsoft\n",
      "dream\n",
      "intetest\n",
      "interest\n",
      "me\n",
      "lot\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "import sys,os\n",
    "sys.path.append(\"../\")\n",
    "from whoosh.index import create_in,open_dir\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "from jieba.analyse.analyzer import ChineseAnalyzer\n",
    "\n",
    "analyzer = ChineseAnalyzer()\n",
    "\n",
    "schema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT(stored=True, analyzer=analyzer))\n",
    "if not os.path.exists(\"tmp\"):\n",
    "    os.mkdir(\"tmp\")\n",
    "\n",
    "ix = create_in(\"tmp\", schema) # for create new index\n",
    "#ix = open_dir(\"tmp\") # for read only\n",
    "writer = ix.writer()\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document1\",\n",
    "    path=\"/a\",\n",
    "    content=\"This is the first document we’ve added!\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document2\",\n",
    "    path=\"/b\",\n",
    "    content=\"The second one 你 中文测试中文 is even more interesting! 吃水果\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document3\",\n",
    "    path=\"/c\",\n",
    "    content=\"买水果然后来世博园。\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document4\",\n",
    "    path=\"/c\",\n",
    "    content=\"工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document4\",\n",
    "    path=\"/c\",\n",
    "    content=\"咱俩交换一下吧。\"\n",
    ")\n",
    "\n",
    "writer.commit()\n",
    "searcher = ix.searcher()\n",
    "parser = QueryParser(\"content\", schema=ix.schema)\n",
    "\n",
    "for keyword in (\"水果世博园\",\"你\",\"first\",\"中文\",\"交换机\",\"交换\"):\n",
    "    print(\"result of \",keyword)\n",
    "    q = parser.parse(keyword)\n",
    "    results = searcher.search(q)\n",
    "    for hit in results:\n",
    "        print(hit.highlights(\"content\"))\n",
    "    print(\"=\"*10)\n",
    "\n",
    "for t in analyzer(\"我的好朋友是李明;我爱北京国安;IBM和Microsoft; I have a dream. this is intetesting and interested me a lot\"):\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6be112",
   "metadata": {
    "papermill": {
     "duration": 0.047225,
     "end_time": "2023-09-25T12:49:04.464222",
     "exception": false,
     "start_time": "2023-09-25T12:49:04.416997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8. Command Line Interface\n",
    "-----------------------------------\n",
    "```\n",
    "$> python -m jieba --help\n",
    "Jieba command line interface.\n",
    "\n",
    "positional arguments:\n",
    "  filename              input file\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -d [DELIM], --delimiter [DELIM]\n",
    "                        use DELIM instead of ' / ' for word delimiter; or a\n",
    "                        space if it is used without DELIM\n",
    "  -p [DELIM], --pos [DELIM]\n",
    "                        enable POS tagging; if DELIM is specified, use DELIM\n",
    "                        instead of '_' for POS delimiter\n",
    "  -D DICT, --dict DICT  use DICT as dictionary\n",
    "  -u USER_DICT, --user-dict USER_DICT\n",
    "                        use USER_DICT together with the default dictionary or\n",
    "                        DICT (if specified)\n",
    "  -a, --cut-all         full pattern cutting (ignored with POS tagging)\n",
    "  -n, --no-hmm          don't use the Hidden Markov Model\n",
    "  -q, --quiet           don't print loading messages to stderr\n",
    "  -V, --version         show program's version number and exit\n",
    "\n",
    "If no filename specified, use STDIN instead.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea0734",
   "metadata": {
    "papermill": {
     "duration": 0.046797,
     "end_time": "2023-09-25T12:49:04.558901",
     "exception": false,
     "start_time": "2023-09-25T12:49:04.512104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialization\n",
    "-----------------------------------\n",
    "\n",
    "By default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again.<br>\n",
    "If you want to initialize Jieba manually, you can call:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14060ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:04.658055Z",
     "iopub.status.busy": "2023-09-25T12:49:04.656708Z",
     "iopub.status.idle": "2023-09-25T12:49:04.662565Z",
     "shell.execute_reply": "2023-09-25T12:49:04.661439Z"
    },
    "papermill": {
     "duration": 0.056466,
     "end_time": "2023-09-25T12:49:04.664785",
     "exception": false,
     "start_time": "2023-09-25T12:49:04.608319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.initialize()  # (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42347e",
   "metadata": {
    "papermill": {
     "duration": 0.046617,
     "end_time": "2023-09-25T12:49:04.758924",
     "exception": false,
     "start_time": "2023-09-25T12:49:04.712307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can also specify the dictionary (not supported before version 0.28) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e3d33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:04.856938Z",
     "iopub.status.busy": "2023-09-25T12:49:04.856486Z",
     "iopub.status.idle": "2023-09-25T12:49:04.866442Z",
     "shell.execute_reply": "2023-09-25T12:49:04.865165Z"
    },
    "papermill": {
     "duration": 0.061994,
     "end_time": "2023-09-25T12:49:04.869609",
     "exception": false,
     "start_time": "2023-09-25T12:49:04.807615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jieba.set_dictionary('/kaggle/input/ideogram-phonogram-dataset/dict.txt.big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac41d94",
   "metadata": {
    "papermill": {
     "duration": 0.04818,
     "end_time": "2023-09-25T12:49:04.967298",
     "exception": false,
     "start_time": "2023-09-25T12:49:04.919118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using Other Dictionaries\n",
    "-----------------------------------\n",
    "It is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:<br>\n",
    "1. A smaller dictionary for a smaller memory footprint: <br>\n",
    "https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small<br>\n",
    "\n",
    "2. There is also a bigger dictionary that has better support for traditional Chinese (繁體):<br>\n",
    "https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big<br>\n",
    "***You can find both files from [here](https://www.kaggle.com/datasets/jasonheesanglee/ideogram-phonogram-dataset)***<br><br>\n",
    "\n",
    "By default, an in-between dictionary is used, called `dict.txt` and included in the distribution.<br>\n",
    "\n",
    "In either case, download the file you want, and then call `jieba.set_dictionary('data/dict.txt.big')` or just replace the existing `dict.txt`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739a0a0",
   "metadata": {
    "papermill": {
     "duration": 0.047759,
     "end_time": "2023-09-25T12:49:05.064276",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.016517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>\n",
    "<strong><a href=\"#jieba\"> 🔺 Jieba</a></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432697b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048576,
     "end_time": "2023-09-25T12:49:05.161150",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.112574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## jieba/jieba\n",
    "-----------------------------------\n",
    "As I have finished going through README.md, I will start on the original plan.<br>\n",
    "Below is how jieba/jieba directory looks like.<br><br>\n",
    "Code explanation done with the help of ChatGPT & BARD\n",
    "<img src=\"https://github.com/jasonheesanglee/Ideogram_Phonogram/blob/main/IDEOPHONO/jieba_jieba.png?raw=true\" height=\"100\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb32b1",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049821,
     "end_time": "2023-09-25T12:49:05.258774",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.208953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### dict.txt\n",
    "-----------------------------------\n",
    "Let's take a look at dict.txt<br>\n",
    "From the code output below, we can see that this txt file is composed in a format of `[word]` | `[word frequency]` | `[POS]` as explained in [2.Add a custom dictionary](https://www.kaggle.com/code/jasonheesanglee/ideogram-based-vs-phonogram-based-language?scriptVersionId=142722802&cellId=36)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "616f5cc7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:05.357194Z",
     "iopub.status.busy": "2023-09-25T12:49:05.356749Z",
     "iopub.status.idle": "2023-09-25T12:49:05.482417Z",
     "shell.execute_reply": "2023-09-25T12:49:05.481171Z"
    },
    "papermill": {
     "duration": 0.176844,
     "end_time": "2023-09-25T12:49:05.485168",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.308324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AT&T 3 nz\\n',\n",
       " 'B超 3 n\\n',\n",
       " 'c# 3 nz\\n',\n",
       " 'C# 3 nz\\n',\n",
       " 'c++ 3 nz\\n',\n",
       " 'C++ 3 nz\\n',\n",
       " 'T恤 4 n\\n',\n",
       " 'A座 3 n\\n',\n",
       " 'A股 3 n\\n',\n",
       " 'A型 3 n\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(r'/kaggle/input/ideogram-phonogram-dataset/dict.txt') as dict_txt:\n",
    "    display(dict_txt.readlines()[0:10])\n",
    "#     display(dict_txt.read()[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d3307",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.053185,
     "end_time": "2023-09-25T12:49:05.585733",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.532548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### _compat.py\n",
    "-----------------------------------\n",
    "I will start with _compat.py as both `main.py` and `init.py` starts by importing this module.<br>\n",
    "(Sorry for not including \"___\" in the file name... Hate markdown syntax..)<br>\n",
    "\n",
    "I will break the module down per `def`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc0efc",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047114,
     "end_time": "2023-09-25T12:49:05.681389",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.634275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing Modules\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd044209",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:05.779449Z",
     "iopub.status.busy": "2023-09-25T12:49:05.778431Z",
     "iopub.status.idle": "2023-09-25T12:49:05.783744Z",
     "shell.execute_reply": "2023-09-25T12:49:05.782890Z"
    },
    "papermill": {
     "duration": 0.056829,
     "end_time": "2023-09-25T12:49:05.786035",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.729206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import logging\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a2104",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.046923,
     "end_time": "2023-09-25T12:49:05.882439",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.835516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Logging Configurations\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db8344fd",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:05.980132Z",
     "iopub.status.busy": "2023-09-25T12:49:05.979404Z",
     "iopub.status.idle": "2023-09-25T12:49:05.983967Z",
     "shell.execute_reply": "2023-09-25T12:49:05.983157Z"
    },
    "papermill": {
     "duration": 0.056278,
     "end_time": "2023-09-25T12:49:05.986229",
     "exception": false,
     "start_time": "2023-09-25T12:49:05.929951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log_console = logging.StreamHandler(sys.stderr)\n",
    "# default_logger = logging.getLogger(__name__)\n",
    "# default_logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae64113",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047041,
     "end_time": "2023-09-25T12:49:06.081365",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.034324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `log_console` is created as a Stream Handler that directs log messages to the standard error ('sys.stderr')<br>\n",
    "- `default_loger` is a logger object created for the current module.<br>\n",
    "- \\_\\_name__ refers to the current module (`_compat.py`)<br>\n",
    "It is configured to log messages with a minimum level of \"DEBUG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2580e10",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.144821,
     "end_time": "2023-09-25T12:49:06.274483",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.129662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `setLogLevel`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dffa51a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:06.376405Z",
     "iopub.status.busy": "2023-09-25T12:49:06.375476Z",
     "iopub.status.idle": "2023-09-25T12:49:06.380139Z",
     "shell.execute_reply": "2023-09-25T12:49:06.379336Z"
    },
    "papermill": {
     "duration": 0.056497,
     "end_time": "2023-09-25T12:49:06.382333",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.325836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def setLogLevel(log_level):\n",
    "#     default_logger.setLevel(log_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fe95b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047478,
     "end_time": "2023-09-25T12:49:06.476802",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.429324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function is defined to allow changing the log level of the \"default_logger\".<br>\n",
    "By calling this function with a log level. the logger's level will be set.<br>\n",
    "For example, if the log level is set to `logging.INFO`, the log level will be changed to `INFO`, and the logger will only display messages of INFO level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a99797d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:06.574015Z",
     "iopub.status.busy": "2023-09-25T12:49:06.573145Z",
     "iopub.status.idle": "2023-09-25T12:49:06.578211Z",
     "shell.execute_reply": "2023-09-25T12:49:06.577348Z"
    },
    "papermill": {
     "duration": 0.05617,
     "end_time": "2023-09-25T12:49:06.580501",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.524331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check_paddle_install = {'is_paddle_installed': False}\n",
    "\n",
    "# try:\n",
    "#     import pkg_resources\n",
    "\n",
    "#     get_module_res = lambda *res: pkg_resources.resource_stream(__name__,\n",
    "#                                                                 os.path.join(*res))\n",
    "# except ImportError:\n",
    "#     get_module_res = lambda *res: open(os.path.normpath(os.path.join(\n",
    "#         os.getcwd(), os.path.dirname(__file__), *res)), 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ff16f",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047985,
     "end_time": "2023-09-25T12:49:06.678971",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.630986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This part is to check whether the PaddlePaddle library is installed.<br>\n",
    "- If `pkg_resources` can be imported, it sets `is_paddle_installed` to True.<br>\n",
    "- It uses pkg_resources.resource_stream if available, and if not, it constructs the resource path using os.getcwd() and os.path.dirname(__file__) and opens the resource as a binary file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a20665",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04782,
     "end_time": "2023-09-25T12:49:06.774861",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.727041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `enable_paddle`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea848a1",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:06.873482Z",
     "iopub.status.busy": "2023-09-25T12:49:06.873015Z",
     "iopub.status.idle": "2023-09-25T12:49:06.878681Z",
     "shell.execute_reply": "2023-09-25T12:49:06.877173Z"
    },
    "papermill": {
     "duration": 0.058413,
     "end_time": "2023-09-25T12:49:06.881040",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.822627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def enable_paddle():\n",
    "#     try:\n",
    "#         import paddle\n",
    "#     except ImportError:\n",
    "#         default_logger.debug(\"Installing paddle-tiny, please wait a minute......\")\n",
    "#         os.system(\"pip install paddlepaddle-tiny\")\n",
    "#         try:\n",
    "#             import paddle\n",
    "#         except ImportError:\n",
    "#             default_logger.debug(\n",
    "#                 \"Import paddle error, please use command to install: pip install paddlepaddle-tiny==1.6.1.\"\n",
    "#                 \"Now, back to jieba basic cut......\")\n",
    "#     if paddle.__version__ < '1.6.1':\n",
    "#         default_logger.debug(\"Find your own paddle version doesn't satisfy the minimum requirement (1.6.1), \"\n",
    "#                              \"please install paddle tiny by 'pip install --upgrade paddlepaddle-tiny', \"\n",
    "#                              \"or upgrade paddle full version by \"\n",
    "#                              \"'pip install --upgrade paddlepaddle (-gpu for GPU version)' \")\n",
    "#     else:\n",
    "#         try:\n",
    "#             import jieba.lac_small.predict as predict\n",
    "#             default_logger.debug(\"Paddle enabled successfully......\")\n",
    "#             check_paddle_install['is_paddle_installed'] = True\n",
    "#         except ImportError:\n",
    "#             default_logger.debug(\"Import error, cannot find paddle.fluid and jieba.lac_small.predict module. \"\n",
    "#                                  \"Now, back to jieba basic cut......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29645c",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047062,
     "end_time": "2023-09-25T12:49:06.975337",
     "exception": false,
     "start_time": "2023-09-25T12:49:06.928275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This function begins by importing `paddle`.<br>\n",
    "- If the nested import raises an ImportError again, it logs another message to the default logger, indicating that PaddlePaddle couldn't be imported even after the installation and suggests a specific command to install a particular version of PaddlePaddle.\n",
    "- The function does not return any values but effectively determines whether PaddlePaddle is available for use in the Jieba library and logs relevant messages.\n",
    "- This function handles the installation and availability of the PaddlePaddle library, which may be used by Jieba for certain tasks.<br> If PaddlePaddle is available and of the correct version, it sets the is_paddle_installed flag to True, indicating that PaddlePaddle support is enabled.<br> Otherwise, it falls back to the basic Jieba functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2cea3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047069,
     "end_time": "2023-09-25T12:49:07.069582",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.022513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `PaddlePaddle`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "178c6d61",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:07.167623Z",
     "iopub.status.busy": "2023-09-25T12:49:07.167197Z",
     "iopub.status.idle": "2023-09-25T12:49:07.172361Z",
     "shell.execute_reply": "2023-09-25T12:49:07.171141Z"
    },
    "papermill": {
     "duration": 0.058028,
     "end_time": "2023-09-25T12:49:07.174847",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.116819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PY2 = sys.version_info[0] == 2\n",
    "\n",
    "# default_encoding = sys.getfilesystemencoding()\n",
    "\n",
    "# if PY2:\n",
    "#     text_type = unicode\n",
    "#     string_types = (str, unicode)\n",
    "\n",
    "#     iterkeys = lambda d: d.iterkeys()\n",
    "#     itervalues = lambda d: d.itervalues()\n",
    "#     iteritems = lambda d: d.iteritems()\n",
    "\n",
    "# else:\n",
    "#     text_type = str\n",
    "#     string_types = (str,)\n",
    "#     xrange = range\n",
    "\n",
    "#     iterkeys = lambda d: iter(d.keys())\n",
    "#     itervalues = lambda d: iter(d.values())\n",
    "#     iteritems = lambda d: iter(d.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ec9aa",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048907,
     "end_time": "2023-09-25T12:49:07.272670",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.223763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This section deals with defining variables and functions based on Python version compatibility (Python 2 and Python 3).\n",
    "\n",
    "- `PY2 = sys.version_info[0] == 2`:<br>This line determines whether the Python version being used is Python 2.<br>It checks if the major version number (`sys.version_info[0]`) is equal to 2 and assigns the result to the variable PY2.\n",
    "- `default_encoding = sys.getfilesystemencoding()`:This line obtains the default encoding used by the file system and assigns it to the variable `default_encoding`.<br>This is often used for encoding and decoding file paths.\n",
    "\n",
    "***I will pass the first `if` statement as we are using Python 3***\n",
    "\n",
    "- `text_type = str`: In Python 3, str is used for representing both byte strings and Unicode strings, so it assigns the name text_type to str.\n",
    "- `string_types = (str,)`: It defines string_types as a tuple containing only str since there's no need for unicode in Python 3.\n",
    "- `xrange = range`: In Python 2, there was a separate xrange function for creating efficient iterators over a range of numbers.<br>In Python 3, the range function provides the same functionality, so it assigns range to xrange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea310a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.0482,
     "end_time": "2023-09-25T12:49:07.370414",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.322214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `strdecode`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "472de6f8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:07.473378Z",
     "iopub.status.busy": "2023-09-25T12:49:07.472521Z",
     "iopub.status.idle": "2023-09-25T12:49:07.477698Z",
     "shell.execute_reply": "2023-09-25T12:49:07.476687Z"
    },
    "papermill": {
     "duration": 0.059377,
     "end_time": "2023-09-25T12:49:07.480008",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.420631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def strdecode(sentence):\n",
    "#     if not isinstance(sentence, text_type):\n",
    "#         try:\n",
    "#             sentence = sentence.decode('utf-8')\n",
    "#         except UnicodeDecodeError:\n",
    "#             sentence = sentence.decode('gbk', 'ignore')\n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7486c60",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047729,
     "end_time": "2023-09-25T12:49:07.576185",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.528456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `strdecode` function decodes string to ensure they are in utf-8 format.\n",
    "- If it is not utf-8 format, it decodes the sentence with `gbk` encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae03f1",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047579,
     "end_time": "2023-09-25T12:49:07.672983",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.625404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `resolve_filename`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82bc0045",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:07.771256Z",
     "iopub.status.busy": "2023-09-25T12:49:07.770305Z",
     "iopub.status.idle": "2023-09-25T12:49:07.776064Z",
     "shell.execute_reply": "2023-09-25T12:49:07.775045Z"
    },
    "papermill": {
     "duration": 0.057696,
     "end_time": "2023-09-25T12:49:07.778661",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.720965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def resolve_filename(f):\n",
    "#     try:\n",
    "#         return f.name\n",
    "#     except AttributeError:\n",
    "#         return repr(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487cecc4",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.046716,
     "end_time": "2023-09-25T12:49:07.873951",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.827235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `resolve_filename` defines a function named resolve_filename that takes one argument called f, which is expected to be a file object.\n",
    "- If the name attribute is not available, it returns a string representation of the file object f using the repr() function.<br>This representation includes information about the object, which can be helpful for debugging or providing more context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdead15",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047364,
     "end_time": "2023-09-25T12:49:07.968779",
     "exception": false,
     "start_time": "2023-09-25T12:49:07.921415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>\n",
    "<strong><a href=\"#jieba\"> 🔺 Jieba</a></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bb0ec",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047906,
     "end_time": "2023-09-25T12:49:08.064675",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.016769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### __main__.py\n",
    "-----------------------------------\n",
    "I have hid this part of analysis as it is mostly configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c9030",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048334,
     "end_time": "2023-09-25T12:49:08.160767",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.112433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing modules\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5685143",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:08.258985Z",
     "iopub.status.busy": "2023-09-25T12:49:08.258127Z",
     "iopub.status.idle": "2023-09-25T12:49:08.266045Z",
     "shell.execute_reply": "2023-09-25T12:49:08.264560Z"
    },
    "papermill": {
     "duration": 0.059934,
     "end_time": "2023-09-25T12:49:08.268676",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.208742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jieba command line interface.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Jieba command line interface.\"\"\"\n",
    "\n",
    "# import sys\n",
    "# import jieba\n",
    "# from argparse import ArgumentParser\n",
    "# from ._compat import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40b66f",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.0482,
     "end_time": "2023-09-25T12:49:08.366026",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.317826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Argument Parsing\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad0972c1",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:08.466046Z",
     "iopub.status.busy": "2023-09-25T12:49:08.465153Z",
     "iopub.status.idle": "2023-09-25T12:49:08.470521Z",
     "shell.execute_reply": "2023-09-25T12:49:08.469559Z"
    },
    "papermill": {
     "duration": 0.058234,
     "end_time": "2023-09-25T12:49:08.473047",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.414813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parser = ArgumentParser(usage=\"%s -m jieba [options] filename\" % sys.executable, description=\"Jieba command line interface.\", epilog=\"If no filename specified, use STDIN instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8dee6",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047037,
     "end_time": "2023-09-25T12:49:08.569706",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.522669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This section sets up the argument parser for the command-line interface of `jieba`.<br>\n",
    "It defines various command-line options that can be used when running the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735de9c",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047255,
     "end_time": "2023-09-25T12:49:08.667105",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.619850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Argument Definitions\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "917b440d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:08.766443Z",
     "iopub.status.busy": "2023-09-25T12:49:08.765965Z",
     "iopub.status.idle": "2023-09-25T12:49:08.771481Z",
     "shell.execute_reply": "2023-09-25T12:49:08.770169Z"
    },
    "papermill": {
     "duration": 0.058359,
     "end_time": "2023-09-25T12:49:08.773829",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.715470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parser.add_argument(\"-d\", \"--delimiter\", metavar=\"DELIM\", default=' / ',\n",
    "#                     nargs='?', const=' ',\n",
    "#                     help=\"use DELIM instead of ' / ' for word delimiter; or a space if it is used without DELIM\")\n",
    "# parser.add_argument(\"-p\", \"--pos\", metavar=\"DELIM\", nargs='?', const='_',\n",
    "#                     help=\"enable POS tagging; if DELIM is specified, use DELIM instead of '_' for POS delimiter\")\n",
    "# parser.add_argument(\"-D\", \"--dict\", help=\"use DICT as dictionary\")\n",
    "# parser.add_argument(\"-u\", \"--user-dict\",\n",
    "#                     help=\"use USER_DICT together with the default dictionary or DICT (if specified)\")\n",
    "# parser.add_argument(\"-a\", \"--cut-all\",\n",
    "#                     action=\"store_true\", dest=\"cutall\", default=False,\n",
    "#                     help=\"full pattern cutting (ignored with POS tagging)\")\n",
    "# parser.add_argument(\"-n\", \"--no-hmm\", dest=\"hmm\", action=\"store_false\",\n",
    "#                     default=True, help=\"don't use the Hidden Markov Model\")\n",
    "# parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\", default=False,\n",
    "#                     help=\"don't print loading messages to stderr\")\n",
    "# parser.add_argument(\"-V\", '--version', action='version',\n",
    "#                     version=\"Jieba \" + jieba.__version__)\n",
    "# parser.add_argument(\"filename\", nargs='?', help=\"input file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35c35e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04874,
     "end_time": "2023-09-25T12:49:08.871729",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.822989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This section add arguments to the parser.\n",
    "- `-d` is used to specify a delimiter for word.\n",
    "- `-p` is used to enable part of speech tagging.\n",
    "- `-D` allows specifying a custom dictionary.\n",
    "- `-u` is for a user-defined dictionary.\n",
    "- `-a` enables full pattern cutting.\n",
    "- `-n` disables the Hidden Markov Model.\n",
    "- `-q` makes the script run quietly without loading messages.\n",
    "\n",
    "***I guess these are the similar terms and functions to*** `!pip install -q ...`.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf47277",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04766,
     "end_time": "2023-09-25T12:49:08.968055",
     "exception": false,
     "start_time": "2023-09-25T12:49:08.920395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Parsing Command-Line Arguments\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9689f568",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:09.068560Z",
     "iopub.status.busy": "2023-09-25T12:49:09.068128Z",
     "iopub.status.idle": "2023-09-25T12:49:09.072127Z",
     "shell.execute_reply": "2023-09-25T12:49:09.071168Z"
    },
    "papermill": {
     "duration": 0.056617,
     "end_time": "2023-09-25T12:49:09.074217",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.017600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25ade8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047963,
     "end_time": "2023-09-25T12:49:09.170728",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.122765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section parses the command-line arguments using the previously defined argument parser.<br>\n",
    "- The parsed arguments are stored in the `args` variable, which is an object with attributes corresponding to the defined arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de824e6",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049449,
     "end_time": "2023-09-25T12:49:09.268655",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.219206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration based on Command-Line Arguments.\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b50f0eb4",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:09.369933Z",
     "iopub.status.busy": "2023-09-25T12:49:09.368912Z",
     "iopub.status.idle": "2023-09-25T12:49:09.373627Z",
     "shell.execute_reply": "2023-09-25T12:49:09.372516Z"
    },
    "papermill": {
     "duration": 0.057752,
     "end_time": "2023-09-25T12:49:09.376536",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.318784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if args.quiet:\n",
    "#     jieba.setLogLevel(60)\n",
    "\n",
    "# if args.pos:\n",
    "#     import jieba.posseg\n",
    "#     posdelim = args.pos\n",
    "#     def cutfunc(sentence, _, HMM=True):\n",
    "#         for w, f in jieba.posseg.cut(sentence, HMM):\n",
    "#             yield w + posdelim + f\n",
    "# else:\n",
    "#     cutfunc = jieba.cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b63be",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04792,
     "end_time": "2023-09-25T12:49:09.474256",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.426336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- If the `-q` flag is provided in the command line, it sets the logging level of the jieba library to 60 (which corresponds to the `CRITICAL` log level.<br>\n",
    "- This means that loading messages will not be printed to the standard error (stderr)<br>\n",
    "\n",
    "- If the `-p` flag is provided in the command line, it imports the `jieba.posseg` module and sets up a custom word segmentation function (`cutfunc`) that incorporates POS tags based on the specified delimiter.\n",
    "- If the `-p` flag is not provided, it sets `cutfunc` to the default word segmentation function (`jieba.cut`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d8d57",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2023-09-12T12:30:44.322142Z",
     "iopub.status.idle": "2023-09-12T12:30:44.322653Z",
     "shell.execute_reply": "2023-09-12T12:30:44.322412Z",
     "shell.execute_reply.started": "2023-09-12T12:30:44.322387Z"
    },
    "papermill": {
     "duration": 0.048579,
     "end_time": "2023-09-25T12:49:09.574456",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.525877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Variable Assignments\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5868ce9b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:09.675528Z",
     "iopub.status.busy": "2023-09-25T12:49:09.675049Z",
     "iopub.status.idle": "2023-09-25T12:49:09.679929Z",
     "shell.execute_reply": "2023-09-25T12:49:09.678704Z"
    },
    "papermill": {
     "duration": 0.057311,
     "end_time": "2023-09-25T12:49:09.682414",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.625103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delim = text_type(args.delimiter)\n",
    "# cutall = args.cutall\n",
    "# hmm = args.hmm\n",
    "# fp = open(args.filename, 'r') if args.filename else sys.stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28056a4d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047394,
     "end_time": "2023-09-25T12:49:09.778536",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.731142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `delim` converts the specified delimiter into appropriate text type. (Either Unicode or byte string)\n",
    "- `cutall` stores whether the `-a` flag was provided.\n",
    "- `hmm` stores whether `-n` flag was provided.\n",
    "- `fp` opens the input file specified in the command line `arg.filename` or `sys.stdin` if filename is not provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0ecef",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047069,
     "end_time": "2023-09-25T12:49:09.873463",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.826394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `jieba` Configuration\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3d47efa",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:09.971859Z",
     "iopub.status.busy": "2023-09-25T12:49:09.971192Z",
     "iopub.status.idle": "2023-09-25T12:49:09.976273Z",
     "shell.execute_reply": "2023-09-25T12:49:09.975176Z"
    },
    "papermill": {
     "duration": 0.057544,
     "end_time": "2023-09-25T12:49:09.978770",
     "exception": false,
     "start_time": "2023-09-25T12:49:09.921226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if args.dict:\n",
    "#     jieba.initialize(args.dict)\n",
    "# else:\n",
    "#     jieba.initialize()\n",
    "# if args.user_dict:\n",
    "#     jieba.load_userdict(args.user_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf7d24",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04809,
     "end_time": "2023-09-25T12:49:10.075528",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.027438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- If the `-D` flag is provided, it initializes jieba with the specified dictionary.<br>Otherwise, it uses the default dictionary.\n",
    "- If the `-u` flag is provided, it loads the specified user dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c129c",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047663,
     "end_time": "2023-09-25T12:49:10.170952",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.123289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Processing and Output\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69adb42c",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:10.270122Z",
     "iopub.status.busy": "2023-09-25T12:49:10.268845Z",
     "iopub.status.idle": "2023-09-25T12:49:10.274039Z",
     "shell.execute_reply": "2023-09-25T12:49:10.272917Z"
    },
    "papermill": {
     "duration": 0.057771,
     "end_time": "2023-09-25T12:49:10.276708",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.218937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ln = fp.readline()\n",
    "# while ln:\n",
    "#     l = ln.rstrip('\\r\\n')\n",
    "#     result = delim.join(cutfunc(ln.rstrip('\\r\\n'), cutall, hmm))\n",
    "#     if PY2:\n",
    "#         result = result.encode(default_encoding)\n",
    "#     print(result)\n",
    "#     ln = fp.readline()\n",
    "\n",
    "# fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e7ca1",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047586,
     "end_time": "2023-09-25T12:49:10.373117",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.325531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section reads lines from the input file (or stdin if no filename is provided) using fp.readline().\n",
    "- It applies the word segmentation function (cutfunc) to each line, joining the resulting tokens with the specified delimiter.\n",
    "- If the Python version is 2.x (PY2 is True), it encodes the result using the default encoding.\n",
    "- It prints the segmented and possibly encoded text to the standard output.\n",
    "- This process continues until there are no more lines to read.\n",
    "- Finally, it closes the input file (if opened)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1cdbb",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047571,
     "end_time": "2023-09-25T12:49:10.475772",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.428201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>\n",
    "<strong><a href=\"#jieba\"> 🔺 Jieba</a></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83206d62",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.051212,
     "end_time": "2023-09-25T12:49:10.576382",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.525170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### __init__.py\n",
    "-----------------------------------\n",
    "\n",
    "### Importing Libraries\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "062cc488",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:10.692618Z",
     "iopub.status.busy": "2023-09-25T12:49:10.692054Z",
     "iopub.status.idle": "2023-09-25T12:49:10.698584Z",
     "shell.execute_reply": "2023-09-25T12:49:10.697851Z"
    },
    "papermill": {
     "duration": 0.065945,
     "end_time": "2023-09-25T12:49:10.700536",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.634591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from __future__ import absolute_import, unicode_literals\n",
    "1\n",
    "# import marshal\n",
    "# import re\n",
    "# import tempfile\n",
    "# import threading\n",
    "# import time\n",
    "# from hashlib import md5\n",
    "# from math import log\n",
    "\n",
    "# from . import finalseg\n",
    "# from ._compat import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5e0c7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047935,
     "end_time": "2023-09-25T12:49:10.796700",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.748765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section imports various modules and packages needed for the functionality of `jieba`, including `marshal`, `re`, `tempfile`, `threading`, `time`, `md5`, `log`, and modules from within the `jieba` package itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7383ea",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048183,
     "end_time": "2023-09-25T12:49:10.892699",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.844516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Version & Licence\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d67bd515",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:10.991983Z",
     "iopub.status.busy": "2023-09-25T12:49:10.991124Z",
     "iopub.status.idle": "2023-09-25T12:49:10.995462Z",
     "shell.execute_reply": "2023-09-25T12:49:10.994427Z"
    },
    "papermill": {
     "duration": 0.056924,
     "end_time": "2023-09-25T12:49:10.997890",
     "exception": false,
     "start_time": "2023-09-25T12:49:10.940966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# __version__ = '0.42.1'\n",
    "# __license__ = 'MIT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309251b1",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048827,
     "end_time": "2023-09-25T12:49:11.095301",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.046474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section specifies the Version & License of `jieba`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd61bd0",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.050176,
     "end_time": "2023-09-25T12:49:11.193631",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.143455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Conditional Import\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "220c1d37",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:11.294028Z",
     "iopub.status.busy": "2023-09-25T12:49:11.293537Z",
     "iopub.status.idle": "2023-09-25T12:49:11.298872Z",
     "shell.execute_reply": "2023-09-25T12:49:11.297517Z"
    },
    "papermill": {
     "duration": 0.059538,
     "end_time": "2023-09-25T12:49:11.302173",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.242635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if os.name == 'nt':\n",
    "#     from shutil import move as _replace_file\n",
    "# else:\n",
    "#     _replace_file = os.rename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58afc7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047802,
     "end_time": "2023-09-25T12:49:11.401656",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.353854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section imports `move` from `shutil` and place in variable `_replace_file` if this code runs on Windows NT.\n",
    "- This section place `os.rename` in variable `_replace_file`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba4420",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047592,
     "end_time": "2023-09-25T12:49:11.497788",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.450196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Path Normalization Function\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67410a0e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:11.597529Z",
     "iopub.status.busy": "2023-09-25T12:49:11.597060Z",
     "iopub.status.idle": "2023-09-25T12:49:11.601979Z",
     "shell.execute_reply": "2023-09-25T12:49:11.600759Z"
    },
    "papermill": {
     "duration": 0.057452,
     "end_time": "2023-09-25T12:49:11.604498",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.547046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _get_abs_path = lambda path: os.path.normpath(os.path.join(os.getcwd(), path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8afdd",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.050357,
     "end_time": "2023-09-25T12:49:11.708570",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.658213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section normalizes the path of the destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371094d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048409,
     "end_time": "2023-09-25T12:49:11.805688",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.757279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Constants\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e63f2586",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:11.905613Z",
     "iopub.status.busy": "2023-09-25T12:49:11.905189Z",
     "iopub.status.idle": "2023-09-25T12:49:11.909581Z",
     "shell.execute_reply": "2023-09-25T12:49:11.908653Z"
    },
    "papermill": {
     "duration": 0.056902,
     "end_time": "2023-09-25T12:49:11.911583",
     "exception": false,
     "start_time": "2023-09-25T12:49:11.854681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEFAULT_DICT = None\n",
    "# DEFAULT_DICT_NAME = \"dict.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757e757",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049112,
     "end_time": "2023-09-25T12:49:12.108961",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.059849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`DEFAULT_DICT` set as `None`<br>\n",
    "`DEFAULT_DICT_NAME` set as dict.txt which is in `jieba/jieba/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339688ff",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048454,
     "end_time": "2023-09-25T12:49:12.206870",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.158416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Logger Setup\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a0692f0",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:12.311275Z",
     "iopub.status.busy": "2023-09-25T12:49:12.310386Z",
     "iopub.status.idle": "2023-09-25T12:49:12.314708Z",
     "shell.execute_reply": "2023-09-25T12:49:12.313842Z"
    },
    "papermill": {
     "duration": 0.058799,
     "end_time": "2023-09-25T12:49:12.317005",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.258206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log_console = logging.StreamHandler(sys.stderr)\n",
    "# default_logger = logging.getLogger(__name__)\n",
    "# default_logger.setLevel(logging.DEBUG)\n",
    "# default_logger.addHandler(log_console)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a493a1a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.050914,
     "end_time": "2023-09-25T12:49:12.416436",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.365522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- These lines set up a logger (`default_logger`) to log messages with a log level of `DEBUG` to the standard error stream (`sys.stderr`).<br>This logger is used for debugging and logging informational messages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5860f2e7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049467,
     "end_time": "2023-09-25T12:49:12.514382",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.464915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dict, Parallel Processing, Regular Expression\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c61f55a3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:12.618733Z",
     "iopub.status.busy": "2023-09-25T12:49:12.617828Z",
     "iopub.status.idle": "2023-09-25T12:49:12.624155Z",
     "shell.execute_reply": "2023-09-25T12:49:12.621710Z"
    },
    "papermill": {
     "duration": 0.063007,
     "end_time": "2023-09-25T12:49:12.628915",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.565908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DICT_WRITING = {}\n",
    "\n",
    "# pool = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f9312a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048787,
     "end_time": "2023-09-25T12:49:12.729483",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.680696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `DICT_WRITING` is used to keep track of whether a dictionary file is currently being written. <br>It's an empty dictionary initially.<br><br>\n",
    "- `pool` variable is used later in the code for parallel processing with multiprocessing.<br>Here, it's set to None to indicate that no multiprocessing pool has been created yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b83cde",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.05205,
     "end_time": "2023-09-25T12:49:12.832801",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.780751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Regular Expression\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e53ceefa",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:12.935226Z",
     "iopub.status.busy": "2023-09-25T12:49:12.934287Z",
     "iopub.status.idle": "2023-09-25T12:49:12.939612Z",
     "shell.execute_reply": "2023-09-25T12:49:12.938444Z"
    },
    "papermill": {
     "duration": 0.059466,
     "end_time": "2023-09-25T12:49:12.942111",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.882645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re_userdict = re.compile('^(.+?)( [0-9]+)?( [a-z]+)?$', re.U)\n",
    "# re_eng = re.compile('[a-zA-Z0-9]', re.U)\n",
    "\n",
    "# # \\u4E00-\\u9FD5a-zA-Z0-9+#&\\._ : All non-space characters. Will be handled with re_han\n",
    "# # \\r\\n|\\s : whitespace characters. Will not be handled.\n",
    "# # re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%]+)\", re.U)\n",
    "# # Adding \"-\" symbol in re_han_default\n",
    "\n",
    "# re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
    "# re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e4c13",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048706,
     "end_time": "2023-09-25T12:49:13.040202",
     "exception": false,
     "start_time": "2023-09-25T12:49:12.991496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `re_userdict`: This line defines `re_userdict`, a regular expression.<br>\n",
    "    - `^`: Matches the start of a line.\n",
    "    - `(.+?)`: Matches one or more characters (non-greedy) and captures them. <br>This is used to capture the word.\n",
    "    - `( [0-9]+)?`: Matches an optional space followed by one or more digits (captures them). <br>This is used to capture the frequency of the word (if present).\n",
    "    - `( [a-z]+)?`: Matches an optional space followed by one or more lowercase letters (captures them). <br>This is used to capture the part of speech tag (if present).\n",
    "    - `re.U`: This is a flag that specifies Unicode matching, enabling the regular expression to work with Unicode characters.<br><br>\n",
    "- `re_eng`: It's used to match English alphanumeric characters.<br>\n",
    "    - `[a-zA-Z0-9]`: Matches any single English alphabet (lowercase or uppercase) or digit.\n",
    "    - `re.U`: This is the Unicode matching flag, enabling the regular expression to work with Unicode characters.<br><br>\n",
    "    \n",
    "- `re_han_default` : It uses re.compile to create a regular expression pattern object.<br>\n",
    "    - `([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%]+)`: This part of the regular expression defines a character group that matches one or more non-space characters.<br>It includes Chinese characters `(\\u4E00-\\u9FD5)` (from , alphanumeric characters (a-zA-Z0-9), and specific symbols (+#&\\._%).\n",
    "    - re.U: This is a flag that specifies Unicode matching, enabling the regular expression to work with Unicode characters.<br><br>\n",
    "- `re_skip_default` : It is used for matching whitespace characters and line breaks `(\\r\\n)`.<br>These characters are not considered part of words during word segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097136",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048417,
     "end_time": "2023-09-25T12:49:13.137205",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.088788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `setLogLevel`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38fb1d4b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:13.236888Z",
     "iopub.status.busy": "2023-09-25T12:49:13.236414Z",
     "iopub.status.idle": "2023-09-25T12:49:13.240879Z",
     "shell.execute_reply": "2023-09-25T12:49:13.239781Z"
    },
    "papermill": {
     "duration": 0.057757,
     "end_time": "2023-09-25T12:49:13.243297",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.185540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def setLogLevel(log_level):\n",
    "#     default_logger.setLevel(log_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1096cc4",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049665,
     "end_time": "2023-09-25T12:49:13.343483",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.293818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section is to allow changing the log level of the default_logger.\n",
    "- Calling this function with a log level, and it will set the logger's level accordingly.\n",
    "- For example, if the function is called as setLogLevel(logging.INFO), it will change the log level to INFO, and the logger will only display messages of INFO level and above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35925eb2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049738,
     "end_time": "2023-09-25T12:49:13.442751",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.393013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tokenizer\n",
    "-----------------------------------\n",
    "I have splitted the Tokenizer class into per definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6662982d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:13.544803Z",
     "iopub.status.busy": "2023-09-25T12:49:13.543804Z",
     "iopub.status.idle": "2023-09-25T12:49:13.549255Z",
     "shell.execute_reply": "2023-09-25T12:49:13.548280Z"
    },
    "papermill": {
     "duration": 0.059028,
     "end_time": "2023-09-25T12:49:13.551770",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.492742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Tokenizer(object):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec8302",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049716,
     "end_time": "2023-09-25T12:49:13.650454",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.600738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def __init__`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e137c4c0",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:13.749568Z",
     "iopub.status.busy": "2023-09-25T12:49:13.749035Z",
     "iopub.status.idle": "2023-09-25T12:49:13.754097Z",
     "shell.execute_reply": "2023-09-25T12:49:13.753183Z"
    },
    "papermill": {
     "duration": 0.057356,
     "end_time": "2023-09-25T12:49:13.756145",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.698789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def __init__(self, dictionary=DEFAULT_DICT):\n",
    "#         self.lock = threading.RLock()\n",
    "#         if dictionary == DEFAULT_DICT:\n",
    "#             self.dictionary = dictionary\n",
    "#         else:\n",
    "#             self.dictionary = _get_abs_path(dictionary)\n",
    "#         self.FREQ = {}\n",
    "#         self.total = 0\n",
    "#         self.user_word_tag_tab = {}\n",
    "#         self.initialized = False\n",
    "#         self.tmp_dir = None\n",
    "#         self.cache_file = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882ff73",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048258,
     "end_time": "2023-09-25T12:49:13.852976",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.804718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- When calling this `Tokenizer` class, it takes dictionary as an optional parameter.\n",
    "- `self.lock` initializes a threading reentrant lock.\n",
    "    - It is used for thread synchronization to ensure that certain operations are thread-safe.\n",
    "- `DEFAULT_DICT` is set as a default dictionary, and if another dictionary is given as an input, `self.dicitonary` will return the path to the new dictionary.\n",
    "- `self.initialized` is set to False.\n",
    "    - This is used to keep track of whether the tokenizer has been initialized.\n",
    "- `self.tmp_dir` is set to `None`.\n",
    "    - It will later take a path to temporary directory.\n",
    "- `self.cache_file` is set to `None`.\n",
    "    - This as well will later take a path to cache file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8562907",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048544,
     "end_time": "2023-09-25T12:49:13.950845",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.902301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def __repr__`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6c4cff5",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:14.050157Z",
     "iopub.status.busy": "2023-09-25T12:49:14.048962Z",
     "iopub.status.idle": "2023-09-25T12:49:14.053575Z",
     "shell.execute_reply": "2023-09-25T12:49:14.052526Z"
    },
    "papermill": {
     "duration": 0.056765,
     "end_time": "2023-09-25T12:49:14.055943",
     "exception": false,
     "start_time": "2023-09-25T12:49:13.999178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def __repr__(self):\n",
    "#         return '<Tokenizer dictionary=%r>' % self.dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8221a056",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048603,
     "end_time": "2023-09-25T12:49:14.153754",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.105151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This definition returns a string that includes information about the dictionary being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345ffbb",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049585,
     "end_time": "2023-09-25T12:49:14.252775",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.203190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def gen_pfdict`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab68d709",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:14.354130Z",
     "iopub.status.busy": "2023-09-25T12:49:14.353412Z",
     "iopub.status.idle": "2023-09-25T12:49:14.358421Z",
     "shell.execute_reply": "2023-09-25T12:49:14.357320Z"
    },
    "papermill": {
     "duration": 0.05939,
     "end_time": "2023-09-25T12:49:14.361055",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.301665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     @staticmethod\n",
    "#     def gen_pfdict(f):\n",
    "#         lfreq = {}\n",
    "#         ltotal = 0\n",
    "#         f_name = resolve_filename(f)\n",
    "#         for lineno, line in enumerate(f, 1):\n",
    "#             try:\n",
    "#                 line = line.strip().decode('utf-8')\n",
    "#                 word, freq = line.split(' ')[:2]\n",
    "#                 freq = int(freq)\n",
    "#                 lfreq[word] = freq\n",
    "#                 ltotal += freq\n",
    "#                 for ch in xrange(len(word)):\n",
    "#                     wfrag = word[:ch + 1]\n",
    "#                     if wfrag not in lfreq:\n",
    "#                         lfreq[wfrag] = 0\n",
    "#             except ValueError:\n",
    "#                 raise ValueError(\n",
    "#                     'invalid dictionary entry in %s at Line %s: %s' % (f_name, lineno, line))\n",
    "#         f.close()\n",
    "#         return lfreq, ltotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a652e8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049676,
     "end_time": "2023-09-25T12:49:14.461580",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.411904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `@staticmethod` defines a static method within a class.\n",
    "    - Static method is a method that belongs to the class itself rather than to an instance of the class.\n",
    "    - Static method can be called on the class itself without needing to create an instance of the class.\n",
    "    - Static methods do not have access to the instance state and do not modify it.\n",
    "    - They are often used for utility functions that are related to the class but don't require access to instance-specific data.\n",
    "- In this case, `gen_pfdict` is defined as a static method.<br><br>\n",
    "- `gen_pfdict` is responsible for generating a dictionary of word frequencies from a given dictionary file.<br><br>\n",
    "\n",
    "- `f_name = resolve_filename(f)`: `f_name` is set to the resolved filename of the input file using `resolve_filename` function.\n",
    "    - This is done to ensure that the file path is correctly resolved, especially when handling custom dictionaries.<br><br>\n",
    "\n",
    "- Outer `for` loop iterates over the file, starting from line 1.\n",
    "    - `line` is stripped and decoded into UTF-8.\n",
    "    - `lfreq` dict stores word and its frequency.\n",
    "    - `ltotal` stores frequency value.<br><br>\n",
    "    \n",
    "- Inner `for` loop iterates over each character.\n",
    "    - It creates sub-word fragments for each character and check if they are in the `lfreq` dictionary.\n",
    "    - If not, it adds them with a frequency of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd8f6f",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049722,
     "end_time": "2023-09-25T12:49:14.561061",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.511339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def initialize`\n",
    "-----------------------------------\n",
    "I will divide this definition into parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f771147",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:14.666397Z",
     "iopub.status.busy": "2023-09-25T12:49:14.665494Z",
     "iopub.status.idle": "2023-09-25T12:49:14.671003Z",
     "shell.execute_reply": "2023-09-25T12:49:14.670124Z"
    },
    "papermill": {
     "duration": 0.061159,
     "end_time": "2023-09-25T12:49:14.673555",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.612396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def initialize(self, dictionary=None):\n",
    "#         if dictionary:\n",
    "#             abs_path = _get_abs_path(dictionary)\n",
    "#             if self.dictionary == abs_path and self.initialized:\n",
    "#                 return\n",
    "#             else:\n",
    "#                 self.dictionary = abs_path\n",
    "#                 self.initialized = False\n",
    "#         else:\n",
    "#             abs_path = self.dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d15e65",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048766,
     "end_time": "2023-09-25T12:49:14.772020",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.723254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, it specifies the path to the dictionary.<br>\n",
    "If using a new dictionary, it gets the path by using `_get_abs_path` function which was defined in [`__init__.py`](https://www.kaggle.com/code/jasonheesanglee/ideogram-based-vs-phonogram-based-language?scriptVersionId=143053397&cellId=114)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82fa65d2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:14.873175Z",
     "iopub.status.busy": "2023-09-25T12:49:14.872309Z",
     "iopub.status.idle": "2023-09-25T12:49:14.877510Z",
     "shell.execute_reply": "2023-09-25T12:49:14.876422Z"
    },
    "papermill": {
     "duration": 0.05863,
     "end_time": "2023-09-25T12:49:14.879945",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.821315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#         with self.lock:\n",
    "#             try:\n",
    "#                 with DICT_WRITING[abs_path]:\n",
    "#                     pass\n",
    "#             except KeyError:\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefbaec",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.052954,
     "end_time": "2023-09-25T12:49:14.982868",
     "exception": false,
     "start_time": "2023-09-25T12:49:14.929914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This section ensures that multiple threads do not attempt to initialize the same dictionary file concurrently.<br>\n",
    "It attempts to acquire a lock from the `DICT_WRITING` dictionary using the absolute path of the dictionary file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e1d2c3a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:15.087220Z",
     "iopub.status.busy": "2023-09-25T12:49:15.086503Z",
     "iopub.status.idle": "2023-09-25T12:49:15.090998Z",
     "shell.execute_reply": "2023-09-25T12:49:15.090183Z"
    },
    "papermill": {
     "duration": 0.059466,
     "end_time": "2023-09-25T12:49:15.093793",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.034327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             if self.initialized:\n",
    "#                 return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808169c3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049388,
     "end_time": "2023-09-25T12:49:15.195094",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.145706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If the dictionary is already initialized, it returns without reinitializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac75b338",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:15.297967Z",
     "iopub.status.busy": "2023-09-25T12:49:15.297263Z",
     "iopub.status.idle": "2023-09-25T12:49:15.301589Z",
     "shell.execute_reply": "2023-09-25T12:49:15.300605Z"
    },
    "papermill": {
     "duration": 0.058008,
     "end_time": "2023-09-25T12:49:15.303828",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.245820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             default_logger.debug(\"Building prefix dict from %s ...\" % (abs_path or 'the default dictionary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ba56e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.05044,
     "end_time": "2023-09-25T12:49:15.403930",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.353490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It logs a message to indicate that it is building the prefix dictionary from the specified dictionary file (`abs_path`).<br>\n",
    "If `abs_path` is not provided, it indicates that it's using the default dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c4eebdb",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:15.506324Z",
     "iopub.status.busy": "2023-09-25T12:49:15.505598Z",
     "iopub.status.idle": "2023-09-25T12:49:15.509479Z",
     "shell.execute_reply": "2023-09-25T12:49:15.508698Z"
    },
    "papermill": {
     "duration": 0.058048,
     "end_time": "2023-09-25T12:49:15.511646",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.453598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698a374",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049301,
     "end_time": "2023-09-25T12:49:15.610354",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.561053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Recording starting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "007d7b70",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:15.713256Z",
     "iopub.status.busy": "2023-09-25T12:49:15.712757Z",
     "iopub.status.idle": "2023-09-25T12:49:15.718296Z",
     "shell.execute_reply": "2023-09-25T12:49:15.717131Z"
    },
    "papermill": {
     "duration": 0.058355,
     "end_time": "2023-09-25T12:49:15.720712",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.662357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             if self.cache_file:\n",
    "#                 cache_file = self.cache_file\n",
    "#             # default dictionary\n",
    "#             elif abs_path == DEFAULT_DICT:\n",
    "#                 cache_file = \"jieba.cache\"\n",
    "#             # custom dictionary\n",
    "#             else:\n",
    "#                 cache_file = \"jieba.u%s.cache\" % md5(\n",
    "#                     abs_path.encode('utf-8', 'replace')).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba913d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048817,
     "end_time": "2023-09-25T12:49:15.819606",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.770789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`If` `cache_file` path exists, it uses the `cache_file` path.<br>\n",
    "`Else if` abs_path is `DEFAULT_DICT`, it creates `jieba.cache` as a name of the cache file.<br>\n",
    "`Else`, when using a custom dictionary, it calculates a cache file name based on the MD5 hash of the dictionary file's absolute path to ensure uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd865e43",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:15.920642Z",
     "iopub.status.busy": "2023-09-25T12:49:15.919804Z",
     "iopub.status.idle": "2023-09-25T12:49:15.924401Z",
     "shell.execute_reply": "2023-09-25T12:49:15.923402Z"
    },
    "papermill": {
     "duration": 0.057788,
     "end_time": "2023-09-25T12:49:15.926562",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.868774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             cache_file = os.path.join(\n",
    "#                 self.tmp_dir or tempfile.gettempdir(), cache_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291fb5b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048498,
     "end_time": "2023-09-25T12:49:16.024366",
     "exception": false,
     "start_time": "2023-09-25T12:49:15.975868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It constructs the full path of the cache file by combining the cache file name and the temporary directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0630693e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:16.127386Z",
     "iopub.status.busy": "2023-09-25T12:49:16.126270Z",
     "iopub.status.idle": "2023-09-25T12:49:16.131294Z",
     "shell.execute_reply": "2023-09-25T12:49:16.130317Z"
    },
    "papermill": {
     "duration": 0.060323,
     "end_time": "2023-09-25T12:49:16.133637",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.073314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             tmpdir = os.path.dirname(cache_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e57ae",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048901,
     "end_time": "2023-09-25T12:49:16.234159",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.185258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prevent absolute path in self.cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3db07e88",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:16.337917Z",
     "iopub.status.busy": "2023-09-25T12:49:16.337509Z",
     "iopub.status.idle": "2023-09-25T12:49:16.341633Z",
     "shell.execute_reply": "2023-09-25T12:49:16.340856Z"
    },
    "papermill": {
     "duration": 0.060143,
     "end_time": "2023-09-25T12:49:16.344351",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.284208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             load_from_cache_fail = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b856bb",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048591,
     "end_time": "2023-09-25T12:49:16.444677",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.396086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initializes a boolean variable load_from_cache_fail to True to track whether loading from the cache file fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f6f52e2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:16.545355Z",
     "iopub.status.busy": "2023-09-25T12:49:16.544685Z",
     "iopub.status.idle": "2023-09-25T12:49:16.549206Z",
     "shell.execute_reply": "2023-09-25T12:49:16.548446Z"
    },
    "papermill": {
     "duration": 0.056676,
     "end_time": "2023-09-25T12:49:16.551088",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.494412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             if os.path.isfile(cache_file) and (abs_path == DEFAULT_DICT or\n",
    "#                                                os.path.getmtime(cache_file) > os.path.getmtime(abs_path)):\n",
    "#                 default_logger.debug(\n",
    "#                     \"Loading model from cache %s\" % cache_file)\n",
    "#                 try:\n",
    "#                     with open(cache_file, 'rb') as cf:\n",
    "#                         self.FREQ, self.total = marshal.load(cf)\n",
    "#                     load_from_cache_fail = False\n",
    "#                 except Exception:\n",
    "#                     load_from_cache_fail = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5da8d6",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048946,
     "end_time": "2023-09-25T12:49:16.649510",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.600564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It checks if the cache file already exists and whether it's up-to-date.<br>If the dictionary is the default dictionary (`abs_path == DEFAULT_DICT`) or if the cache file's modification time is later than the dictionary file's modification time, it indicates that the cache file is valid.<br><br>\n",
    "\n",
    "If the cache file is valid, it logs a message indicating that it's loading the model from the cache file.<br>Then, it attempts to load the precomputed word frequencies (`self.FREQ`) and the total frequency count (`self.total`) from the cache file using the `marshal.load` method.<br><br>\n",
    "If loading from the cache file fails (due to an exception), it sets `load_from_cache_fail` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d524573",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:16.749739Z",
     "iopub.status.busy": "2023-09-25T12:49:16.748848Z",
     "iopub.status.idle": "2023-09-25T12:49:16.754106Z",
     "shell.execute_reply": "2023-09-25T12:49:16.753173Z"
    },
    "papermill": {
     "duration": 0.057992,
     "end_time": "2023-09-25T12:49:16.756379",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.698387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             if load_from_cache_fail:\n",
    "#                 wlock = DICT_WRITING.get(abs_path, threading.RLock())\n",
    "#                 DICT_WRITING[abs_path] = wlock\n",
    "#                 with wlock:\n",
    "#                     self.FREQ, self.total = self.gen_pfdict(self.get_dict_file())\n",
    "#                     default_logger.debug(\n",
    "#                         \"Dumping model to file cache %s\" % cache_file)\n",
    "#                     try:\n",
    "#                         # prevent moving across different filesystems\n",
    "#                         fd, fpath = tempfile.mkstemp(dir=tmpdir)\n",
    "#                         with os.fdopen(fd, 'wb') as temp_cache_file:\n",
    "#                             marshal.dump(\n",
    "#                                 (self.FREQ, self.total), temp_cache_file)\n",
    "#                         _replace_file(fpath, cache_file)\n",
    "#                     except Exception:\n",
    "#                         default_logger.exception(\"Dump cache file failed.\")\n",
    "\n",
    "#                 try:\n",
    "#                     del DICT_WRITING[abs_path]\n",
    "#                 except KeyError:\n",
    "#                     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73167b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049681,
     "end_time": "2023-09-25T12:49:16.856177",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.806496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If loading from the cache file failed or the cache file is not valid, it proceeds with generating the dictionary data.<br><br>\n",
    "`wlock = DICT_WRITING.get` acquires a lock from the `DICT_WRITING` dictionary (or creates one if it doesn't exist) to ensure exclusive access to the dictionary file during initialization.<br><br>\n",
    "`with wlock` calls the `gen_pfdict` method to generate the word frequencies (`self.FREQ`) and the total frequency count (`self.total`) by parsing the dictionary file obtained from `self.get_dict_file()`.<br><br>\n",
    "`default_logger.debug` logs a message indicating that it's dumping the generated model data to the cache file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d954e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048412,
     "end_time": "2023-09-25T12:49:16.953761",
     "exception": false,
     "start_time": "2023-09-25T12:49:16.905349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inner `try` attempts to create a temporary cache file (`temp_cache_file`) and dumps the generated word frequencies (`self.FREQ`) and the total frequency count (`self.total`) to it using `marshal.dump`.<br><br>\n",
    "After successfully dumping the data, it uses `_replace_file` to atomically replace the existing cache file with the newly created cache file. This prevents issues when moving files across different filesystems.<br><br>\n",
    "If any exception occurs during this process, it logs an exception message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03bc2b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048965,
     "end_time": "2023-09-25T12:49:17.051708",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.002743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, outer `try` releases the lock by removing the entry from the `DICT_WRITING` dictionary to allow other threads to access the dictionary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "583220e2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:17.150906Z",
     "iopub.status.busy": "2023-09-25T12:49:17.150497Z",
     "iopub.status.idle": "2023-09-25T12:49:17.154762Z",
     "shell.execute_reply": "2023-09-25T12:49:17.153556Z"
    },
    "papermill": {
     "duration": 0.056036,
     "end_time": "2023-09-25T12:49:17.156868",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.100832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#             self.initialized = True\n",
    "#             default_logger.debug(\n",
    "#                 \"Loading model cost %.3f seconds.\" % (time.time() - t1))\n",
    "#             default_logger.debug(\"Prefix dict has been built successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221433f",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048818,
     "end_time": "2023-09-25T12:49:17.255002",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.206184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After successfully initializing the dictionary data, it sets `self.initialized` to `True` to indicate that the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6d1a3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049315,
     "end_time": "2023-09-25T12:49:17.353885",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.304570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def check_initialized`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfe75864",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:17.454685Z",
     "iopub.status.busy": "2023-09-25T12:49:17.454248Z",
     "iopub.status.idle": "2023-09-25T12:49:17.458492Z",
     "shell.execute_reply": "2023-09-25T12:49:17.457369Z"
    },
    "papermill": {
     "duration": 0.058151,
     "end_time": "2023-09-25T12:49:17.461031",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.402880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def check_initialized(self):\n",
    "#         if not self.initialized:\n",
    "#             self.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f21a46",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.0516,
     "end_time": "2023-09-25T12:49:17.564765",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.513165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It initializes if not initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb4a16",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.05214,
     "end_time": "2023-09-25T12:49:17.668413",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.616273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def calc`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "271de13b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:17.769337Z",
     "iopub.status.busy": "2023-09-25T12:49:17.768818Z",
     "iopub.status.idle": "2023-09-25T12:49:17.773933Z",
     "shell.execute_reply": "2023-09-25T12:49:17.772578Z"
    },
    "papermill": {
     "duration": 0.058553,
     "end_time": "2023-09-25T12:49:17.776303",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.717750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def calc(self, sentence, DAG, route):\n",
    "#         N = len(sentence)\n",
    "#         route[N] = (0, 0)\n",
    "#         logtotal = log(self.total)\n",
    "#         for idx in xrange(N - 1, -1, -1):\n",
    "#             route[idx] = max((log(self.FREQ.get(sentence[idx:x + 1]) or 1) -\n",
    "#                               logtotal + route[x + 1][0], x) for x in DAG[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80717e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.146774,
     "end_time": "2023-09-25T12:49:17.973736",
     "exception": false,
     "start_time": "2023-09-25T12:49:17.826962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Calculates the route with the maximum probability through the Directed Acyclic Graph (DAG) for word segmentation.\n",
    "    - `N` variable stores the length of the sentence.<br> \n",
    "    - `route[N]` initializes the route dictionary with an entry for N, which corresponds to the end of the sentence. The entry is a tuple (0, 0), where the first element represents the maximum log probability, and the second element represents the position.<br>\n",
    "    - `logtotal` cacluates the logarithm of the total frequency count (`self.total`).<br>\n",
    "    This will be used in probability calculations.\n",
    "    - `for` loop iterates over the characters in the input sentence in reverse order.<br>\n",
    "    Starting from the last character (index `N-1`) and moving backward.\n",
    "        - `route[idx]` caculates the log probability of the word from `idx` to `x` , using the formula `log(self.FREQ.get(sentence[idx:x+1]) or 1) - logtotal + route[x+1][0]`.\n",
    "        - `self.FREQ.get(sentence[idx:x+1])` retrieves the frequency count of the word from idx to x from the dictionary.<br>If the word is not found (`None`), it defaults to `1`.\n",
    "        - It subtracts `logtotal` to normalize the log probabilites.\n",
    "        - It adds the log probability of the path to `x+1`, which represents the best path from character `x+1` to the end of the sentence.\n",
    "    - The formula uses `max` to find the maximum log probability among all possible paths from `idx` to the end of the sentence.<br>The result of this calculation is a tuple `(max_log_prob, best_position)`.\n",
    "    - It stores this tuple in `route` dictionary at index `idx`, representing the best path and maximum probability to reach the end of the sentence starting from character `idx`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e91ef",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049493,
     "end_time": "2023-09-25T12:49:18.073203",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.023710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def get_DAG`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1606b92",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:18.174371Z",
     "iopub.status.busy": "2023-09-25T12:49:18.173893Z",
     "iopub.status.idle": "2023-09-25T12:49:18.179475Z",
     "shell.execute_reply": "2023-09-25T12:49:18.178390Z"
    },
    "papermill": {
     "duration": 0.058701,
     "end_time": "2023-09-25T12:49:18.181790",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.123089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def get_DAG(self, sentence):\n",
    "#         self.check_initialized()\n",
    "#         DAG = {}\n",
    "#         N = len(sentence)\n",
    "#         for k in xrange(N):\n",
    "#             tmplist = []\n",
    "#             i = k\n",
    "#             frag = sentence[k]\n",
    "#             while i < N and frag in self.FREQ:\n",
    "#                 if self.FREQ[frag]:\n",
    "#                     tmplist.append(i)\n",
    "#                 i += 1\n",
    "#                 frag = sentence[k:i + 1]\n",
    "#             if not tmplist:\n",
    "#                 tmplist.append(k)\n",
    "#             DAG[k] = tmplist\n",
    "#         return DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb014ec6",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.050814,
     "end_time": "2023-09-25T12:49:18.283675",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.232861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section constructs a Directed Acyclic Graph (DAG) that represents the possible word combinations in the input sentence.\n",
    "- `self.check_initialized()` checks if it is initialized.<br>If not, it initializes it.\n",
    "- `for` loop iterates over characters in the input sentence from right to left.\n",
    "- `while` loop continues until `i` is less than `N` and `frag` is in `self.FREQ`.\n",
    "- `If self.FREQ[frag]` checks if the frequency count of the current `frag` is not zero. <br>If it's not zero, it means that `frag` is a valid word.\n",
    "- `i` increases by 1 when each loop finishes, than it repositions to the next word with `sentence[k:i + 1]`.\n",
    "- `if not tmplist` checks if `tmplist` is empty.<br>If it is empty, it means that no valid words were found starting from character `k`.\n",
    "- `tmplist` is added to `DAG` dictionary with key k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da3b49",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049075,
     "end_time": "2023-09-25T12:49:18.381758",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.332683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def __cut_all`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50a812df",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:18.483904Z",
     "iopub.status.busy": "2023-09-25T12:49:18.482786Z",
     "iopub.status.idle": "2023-09-25T12:49:18.488139Z",
     "shell.execute_reply": "2023-09-25T12:49:18.487272Z"
    },
    "papermill": {
     "duration": 0.059379,
     "end_time": "2023-09-25T12:49:18.490393",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.431014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def __cut_all(self, sentence):\n",
    "#         dag = self.get_DAG(sentence)\n",
    "#         old_j = -1\n",
    "#         eng_scan = 0\n",
    "#         eng_buf = u''\n",
    "#         for k, L in iteritems(dag):\n",
    "#             if eng_scan == 1 and not re_eng.match(sentence[k]):\n",
    "#                 eng_scan = 0\n",
    "#                 yield eng_buf\n",
    "#             if len(L) == 1 and k > old_j:\n",
    "#                 word = sentence[k:L[0] + 1]\n",
    "#                 if re_eng.match(word):\n",
    "#                     if eng_scan == 0:\n",
    "#                         eng_scan = 1\n",
    "#                         eng_buf = word\n",
    "#                     else:\n",
    "#                         eng_buf += word\n",
    "#                 if eng_scan == 0:\n",
    "#                     yield word\n",
    "#                 old_j = L[0]\n",
    "#             else:\n",
    "#                 for j in L:\n",
    "#                     if j > k:\n",
    "#                         yield sentence[k:j + 1]\n",
    "#                         old_j = j\n",
    "#         if eng_scan == 1:\n",
    "#             yield eng_buf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6057c2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.05027,
     "end_time": "2023-09-25T12:49:18.590697",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.540427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section is used for word segmentation when the `cut_all` method is enabled.\n",
    "    - The tokenizer attempts to split the sentence into all possible combinations of words.\n",
    "\n",
    "- `dag` stores the constructed Directed Acyclic Graph (DAG) that represents the possible word combinations in the input sentence.\n",
    "\n",
    "- `eng_buf` is an empty unicode string.\n",
    "\n",
    "- `for` loop iterates through the nodes in the DAG. \n",
    "    - `if eng_scan == 1 and not re_eng.match(sentence[K])` checks if the word scan is in progress and the character at index `k` is not part of an English word.\n",
    "        - If all the conditions match, it means that the current English word has ended, so it sets `eng_scan` to 0 and yields the English word stored in `eng_buf`.\n",
    "    \n",
    "    - `if len(L) == 1 and k > old_j` checks if there is only one possible word ending in the current list `L`, and if the current character index `k` is greater than the previous word's ending index `old_j`.\n",
    "        - This condition indicates a potential single-character word.\n",
    "        - `word = sentence[K:L[0] + 1]` constructs the potential single-character word by taking a swlice of the sentence from character `k` to `L[0] + 1` if the condition is met.\n",
    "        - `if re_eng.match(word)` checks if the potential word `word` is an English word by matching it against the `re_eng` regular expression.\n",
    "            - `if eng_scan == 0` checks if an English word scan is in progress.<br>If not, it starts a new English word scan by setting `eng_scan` to `1` and stores `word` in `eng_buf`.<br>If English wordscan is already in progress, it appends `word` to the current English word stored in `eng_buf`\n",
    "        - It yields word if `eng_scan == 0`, which means the potential word is not an English word, and there was no previous English word scan in progress.\n",
    "        - Then set `old_j = L[0]`.<br><br>\n",
    " \n",
    "    - If `len(L) == 1 and k > old_j` is `False`, it means that there are multiple possible word endings in the list `L`, or the current character is part of a longer word.\n",
    "        - `for` loop (`for j in L`) iterates through the possible word endings in `L`.\n",
    "            - `if j > k` checks if the ending index `j` is greater than the current character index `k`.<br>If yes, it indicates that there is a valid word ending in this segment of the sentence and yield the word by taking a slice of the sentence from character `k` to `j + 1`, which represents the word.\n",
    "            - Then, it updates `old_j` with `j` to store the ending index of the curernt word.\n",
    "- After processing the entire DAG, `if eng_scan == 1` checks if an English word scan is still in progress.\n",
    "    - If yes, it yields the remaining English word stored in `eng_buf`.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91698818",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.051271,
     "end_time": "2023-09-25T12:49:18.691597",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.640326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def __cut_DAG_NO_HMM`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b0b64df",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:18.793227Z",
     "iopub.status.busy": "2023-09-25T12:49:18.792777Z",
     "iopub.status.idle": "2023-09-25T12:49:18.797864Z",
     "shell.execute_reply": "2023-09-25T12:49:18.796648Z"
    },
    "papermill": {
     "duration": 0.058973,
     "end_time": "2023-09-25T12:49:18.800157",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.741184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def __cut_DAG_NO_HMM(self, sentence):\n",
    "#         DAG = self.get_DAG(sentence)\n",
    "#         route = {}\n",
    "#         self.calc(sentence, DAG, route)\n",
    "#         x = 0\n",
    "#         N = len(sentence)\n",
    "#         buf = ''\n",
    "#         while x < N:\n",
    "#             y = route[x][1] + 1\n",
    "#             l_word = sentence[x:y]\n",
    "#             if re_eng.match(l_word) and len(l_word) == 1:\n",
    "#                 buf += l_word\n",
    "#                 x = y\n",
    "#             else:\n",
    "#                 if buf:\n",
    "#                     yield buf\n",
    "#                     buf = ''\n",
    "#                 yield l_word\n",
    "#                 x = y\n",
    "#         if buf:\n",
    "#             yield buf\n",
    "#             buf = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9cb41",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048368,
     "end_time": "2023-09-25T12:49:18.897306",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.848938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section is used for word segmentation when Hidden Markov Model is disabled.\n",
    "    - `self.calc(sentence, DAG, route)` calculates the best word segmentation path based on the `DAG`.<br>This step populates the route dictionary with information about the optimal word segmentation.\n",
    "    - `while` loop iterates through the characters in the `sentence` until `x` is less than the length of the sentence.\n",
    "        - `y = route[x][1] + 1` represents the ending index of the current word.\n",
    "        - `l_word` represents the current word (from the character at index x to y).\n",
    "        - `if re_eng.match(l_word) and len(l_word) == 1` checks if the current word matches an English word by using regular expression, and also verifies that the length of the word is exactly 1.<br>This condition identifies single characters within the text.\n",
    "            - If the above condition matches, `l_word` is added to an empty string `buf`.\n",
    "            - Then `x` is updated as `y` to proceed to the next sequence.\n",
    "        - if the condition above doesn't match, it checks if there are characters stored in the buf variable (indicating an English word in progress).<br>If there are, it yields the English word stored in `buf` and resets buf to an empty string.\n",
    "    \n",
    "        - `yield l_word` yields the current word, which is either a Chinese word or a non-English character.\n",
    "        \n",
    "    - `if buf` checks if there are any characters remaining in the `buf` variable.\n",
    "        - `yield buf` yields the remaining English word stored in `buf`.\n",
    "        - Then it resets the `buf` variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b7f3d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048103,
     "end_time": "2023-09-25T12:49:18.993764",
     "exception": false,
     "start_time": "2023-09-25T12:49:18.945661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def __cut_DAG`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bcc48086",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:19.095384Z",
     "iopub.status.busy": "2023-09-25T12:49:19.094474Z",
     "iopub.status.idle": "2023-09-25T12:49:19.100396Z",
     "shell.execute_reply": "2023-09-25T12:49:19.099522Z"
    },
    "papermill": {
     "duration": 0.060274,
     "end_time": "2023-09-25T12:49:19.102692",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.042418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def __cut_DAG(self, sentence):\n",
    "#         DAG = self.get_DAG(sentence)\n",
    "#         route = {}\n",
    "#         self.calc(sentence, DAG, route)\n",
    "#         x = 0\n",
    "#         buf = ''\n",
    "#         N = len(sentence)\n",
    "#         while x < N:\n",
    "#             y = route[x][1] + 1\n",
    "#             l_word = sentence[x:y]\n",
    "#             if y - x == 1:\n",
    "#                 buf += l_word\n",
    "#             else:\n",
    "#                 if buf:\n",
    "#                     if len(buf) == 1:\n",
    "#                         yield buf\n",
    "#                         buf = ''\n",
    "#                     else:\n",
    "#                         if not self.FREQ.get(buf):\n",
    "#                             recognized = finalseg.cut(buf)\n",
    "#                             for t in recognized:\n",
    "#                                 yield t\n",
    "#                         else:\n",
    "#                             for elem in buf:\n",
    "#                                 yield elem\n",
    "#                         buf = ''\n",
    "#                 yield l_word\n",
    "#             x = y\n",
    "\n",
    "#         if buf:\n",
    "#             if len(buf) == 1:\n",
    "#                 yield buf\n",
    "#             elif not self.FREQ.get(buf):\n",
    "#                 recognized = finalseg.cut(buf)\n",
    "#                 for t in recognized:\n",
    "#                     yield t\n",
    "#             else:\n",
    "#                 for elem in buf:\n",
    "#                     yield elem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1971a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047946,
     "end_time": "2023-09-25T12:49:19.200161",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.152215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This section is used for word segmentation when `HMM` is enabled.<br>This method is responsible for segmenting Chinese into words using `HMM`.\n",
    "    - `if y - x == 1` checks if the current word `l_word` consists of a single character.<br>If it is a single character, it means it's a Chinese character.\n",
    "    - `if len(buf) == 1` checks if there was a single Chinese character in `buf`.<br>If yes, it yields the single character as standalone word.\n",
    "    - When `else` (== `if len(buf) != 1`), it yields the segmented components (segmented by `finalseg.cut(buf)` method) of the unknown word (`if not self.FREQ.get(buf)`).<br>Otherwise, it yields each character in `buf`.\n",
    "    - After processing the known words, resets `buf`.<br>Next, it yields `l_word`, which can be multi-character Chinese word or a non-Chinese word.<br>Then, x is updated as y to proceed to the next character position.\n",
    "    <br><br>\n",
    "    - After the loop is over, `if buf` checks if there is remaining Chinese words in `buf`.\n",
    "        - `if len(buf) == 1`, it yields `buf`.\n",
    "        - Else if the word in `buf` is not in the frequent list (`elif not self.FREQ,get(buf)`), it yields the segmented components of these unknown words.\n",
    "        - `else`, it yields each element in `buf`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d952d2b",
   "metadata": {
    "papermill": {
     "duration": 0.049414,
     "end_time": "2023-09-25T12:49:19.297704",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.248290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div id = \"jieba_cut\"> </div>\n",
    "\n",
    "### `def cut`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71221320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:19.399484Z",
     "iopub.status.busy": "2023-09-25T12:49:19.398643Z",
     "iopub.status.idle": "2023-09-25T12:49:19.409096Z",
     "shell.execute_reply": "2023-09-25T12:49:19.407749Z"
    },
    "papermill": {
     "duration": 0.063502,
     "end_time": "2023-09-25T12:49:19.411689",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.348187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut(self, sentence, cut_all=False, HMM=True, use_paddle=False):\n",
    "    \"\"\"\n",
    "    The main function that segments an entire sentence that contains\n",
    "    Chinese characters into separated words.\n",
    "\n",
    "    Parameter:\n",
    "        - sentence: The str(unicode) to be segmented.\n",
    "        - cut_all: Model type. True for full pattern, False for accurate pattern.\n",
    "        - HMM: Whether to use the Hidden Markov Model.\n",
    "    \"\"\"\n",
    "    is_paddle_installed = check_paddle_install['is_paddle_installed']\n",
    "    sentence = strdecode(sentence)\n",
    "    if use_paddle and is_paddle_installed:\n",
    "        # if sentence is null, it will raise core exception in paddle.\n",
    "        if sentence is None or len(sentence) == 0:\n",
    "            return\n",
    "        import jieba.lac_small.predict as predict\n",
    "        results = predict.get_sent(sentence)\n",
    "        for sent in results:\n",
    "            if sent is None:\n",
    "                continue\n",
    "            yield sent\n",
    "        return\n",
    "    re_han = re_han_default\n",
    "    re_skip = re_skip_default\n",
    "    if cut_all:\n",
    "        cut_block = self.__cut_all\n",
    "    elif HMM:\n",
    "        cut_block = self.__cut_DAG\n",
    "    else:\n",
    "        cut_block = self.__cut_DAG_NO_HMM\n",
    "    blocks = re_han.split(sentence)\n",
    "    for blk in blocks:\n",
    "        if not blk:\n",
    "            continue\n",
    "        if re_han.match(blk):\n",
    "            for word in cut_block(blk):\n",
    "                yield word\n",
    "        else:\n",
    "            tmp = re_skip.split(blk)\n",
    "            for x in tmp:\n",
    "                if re_skip.match(x):\n",
    "                    yield x\n",
    "                elif not cut_all:\n",
    "                    for xx in x:\n",
    "                        yield xx\n",
    "                else:\n",
    "                    yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9068681",
   "metadata": {
    "papermill": {
     "duration": 0.053078,
     "end_time": "2023-09-25T12:49:19.513863",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.460785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the main section that I was looking for!<br>\n",
    "This method takes several parameters:\n",
    "- `self`: The instance of the Jieba class.\n",
    "- `sentence`: The input text (a string containing Chinese characters) to be segmented.\n",
    "- `cut_all`: A boolean flag that determines the segmentation mode.<br>When True, it uses full pattern matching for segmentation.<br>When False, it uses accurate pattern matching.\n",
    "- `HMM`: A boolean flag that specifies whether to use the Hidden Markov Model (HMM) for segmentation.<br>When True, HMM is used;<br>when False, it's not used.\n",
    "- `use_paddle`: A boolean flag indicating whether to use PaddlePaddle for segmentation, if `PaddlePaddle` is installed.\n",
    "<br><br>\n",
    "- `is_paddle_installed = check_paddle_install['is_paddle_installed']`\n",
    "    - This line of code checks whether PaddlePaddle is installed by accessing the `check_paddle_install` dictionary and retrieving the `is_paddle_installed` key.\n",
    "- `sentence = strdecode(sentence)`\n",
    "    - This line of code decodes the input sentence to ensure it's in a suitable format for processing.<br><br>\n",
    "- It runs the code below if `use_paddle` is True and if `PaddlePaddle` is installed.\n",
    "```\n",
    "if use_paddle and is_paddle_installed:\n",
    "   # if sentence is null, it will raise core exception in paddle.\n",
    "    if sentence is None or len(sentence) == 0:\n",
    "     return\n",
    "    import jieba.lac_small.predict as predict\n",
    "    results = predict.get_sent(sentence)\n",
    "    for sent in results:\n",
    "     if sent is None:\n",
    "         continue\n",
    "     yield sent\n",
    "    return\n",
    "```\n",
    "- If the conditions are met, it skips when the `sentence` is `None` or when the length of the `sentence` is 0.<br>\n",
    "- Otherwise, it imports `predict` module from `jieba.lac_small` to segment the sentence.\n",
    "- `for` loop iterates over the results and yields each segmented word or phrase.\n",
    "- `re_han = re_han_default` and `re_skip = re_skip_default` initializes regular expressions for Chinese characters and characters to be skipped during segmentation.\n",
    "- `if`, `elif`, `else` statements calls the corresponding methods to `cut_block`.\n",
    "- `blocks = re_han.split(sentence)` splits the input sentence into blocks of text using regular expression `re_han`.<br>These blocks will consist of either Chinese characters or non-Chinese characters.\n",
    "- `for` loop iterates over blocks.<br>It skips the empty blocks, and yield word if the block matches the regular expression `re_han`.\n",
    "    - If the block does not match the regular expression `re_han`, which is not Chinese character, it splits the block by using regular expression `re_skip`.\n",
    "        - Then, for this non Chinese block, if a sub-block `x` matches the regular expression `re_skip`, it yields `x`.\n",
    "    - Else if `cut_all` is set to False, it splits the sub-block `x` into `xx` and yields `xx` separately.\n",
    "    - Otherwise, it yields `x`.\n",
    "    \n",
    "    \n",
    "#### It intelligently selects the appropriate segmentation strategy based on the provided parameters.<br>It yields segmented words or characters based on whether it encounters Chinese characters, non-Chinese characters, and the segmentation mode specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9f388",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.05017,
     "end_time": "2023-09-25T12:49:19.612655",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.562485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def cut_for_search`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b832cb1f",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:19.716916Z",
     "iopub.status.busy": "2023-09-25T12:49:19.715772Z",
     "iopub.status.idle": "2023-09-25T12:49:19.721275Z",
     "shell.execute_reply": "2023-09-25T12:49:19.720041Z"
    },
    "papermill": {
     "duration": 0.06101,
     "end_time": "2023-09-25T12:49:19.723185",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.662175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def cut_for_search(self, sentence, HMM=True):\n",
    "#         \"\"\"\n",
    "#         Finer segmentation for search engines.\n",
    "#         \"\"\"\n",
    "#         words = self.cut(sentence, HMM=HMM)\n",
    "#         for w in words:\n",
    "#             if len(w) > 2:\n",
    "#                 for i in xrange(len(w) - 1):\n",
    "#                     gram2 = w[i:i + 2]\n",
    "#                     if self.FREQ.get(gram2):\n",
    "#                         yield gram2\n",
    "#             if len(w) > 3:\n",
    "#                 for i in xrange(len(w) - 2):\n",
    "#                     gram3 = w[i:i + 3]\n",
    "#                     if self.FREQ.get(gram3):\n",
    "#                         yield gram3\n",
    "#             yield w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b45cc3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.047794,
     "end_time": "2023-09-25T12:49:19.819363",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.771569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method is designed for finer segmentation, particularly useful for search engines.\n",
    "    - This first `cut` the sentence into words.\n",
    "    - `for` loop iterates over each words in word.\n",
    "        - if a word is longer than 2 characters, it iterates over each character except for the last characeter.\n",
    "            - Then it extracts a 2-character substring and yield these characters.\n",
    "        - if a word is longer than 3 characters, it iterates over each character except for last two characters.\n",
    "            - Then it extracts a 3-character substring and yield these characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a4f51",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04766,
     "end_time": "2023-09-25T12:49:19.915213",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.867553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def lcut`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4b4932a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:20.014936Z",
     "iopub.status.busy": "2023-09-25T12:49:20.013735Z",
     "iopub.status.idle": "2023-09-25T12:49:20.018649Z",
     "shell.execute_reply": "2023-09-25T12:49:20.017829Z"
    },
    "papermill": {
     "duration": 0.057301,
     "end_time": "2023-09-25T12:49:20.020912",
     "exception": false,
     "start_time": "2023-09-25T12:49:19.963611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def lcut(self, *args, **kwargs):\n",
    "#         return list(self.cut(*args, **kwargs))\n",
    "\n",
    "#     def lcut_for_search(self, *args, **kwargs):\n",
    "#         return list(self.cut_for_search(*args, **kwargs))\n",
    "\n",
    "#     _lcut = lcut\n",
    "#     _lcut_for_search = lcut_for_search\n",
    "\n",
    "#     def _lcut_no_hmm(self, sentence):\n",
    "#         return self.lcut(sentence, False, False)\n",
    "\n",
    "#     def _lcut_all(self, sentence):\n",
    "#         return self.lcut(sentence, True)\n",
    "\n",
    "#     def _lcut_for_search_no_hmm(self, sentence):\n",
    "#         return self.lcut_for_search(sentence, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348f573",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048801,
     "end_time": "2023-09-25T12:49:20.118585",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.069784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Above methods of `lcut` perform similar jobs as the ones with `cut` method, but the only difference is that they returns the lists, instead of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3042a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04815,
     "end_time": "2023-09-25T12:49:20.215460",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.167310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def get_dict_file`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e26b0ac9",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:20.315260Z",
     "iopub.status.busy": "2023-09-25T12:49:20.314808Z",
     "iopub.status.idle": "2023-09-25T12:49:20.319567Z",
     "shell.execute_reply": "2023-09-25T12:49:20.318454Z"
    },
    "papermill": {
     "duration": 0.057944,
     "end_time": "2023-09-25T12:49:20.321635",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.263691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def get_dict_file(self):\n",
    "#         if self.dictionary == DEFAULT_DICT:\n",
    "#             return get_module_res(DEFAULT_DICT_NAME)\n",
    "#         else:\n",
    "#             return open(self.dictionary, 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778d085",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.051467,
     "end_time": "2023-09-25T12:49:20.422357",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.370890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method retrieves the dictionary file associated with `jieba`.\n",
    "- This method returns a custom dictionary when a given dictionary is not same with the default dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2bed5a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049013,
     "end_time": "2023-09-25T12:49:20.520834",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.471821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def load_userdict`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58c7fc33",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:20.639037Z",
     "iopub.status.busy": "2023-09-25T12:49:20.638200Z",
     "iopub.status.idle": "2023-09-25T12:49:20.645814Z",
     "shell.execute_reply": "2023-09-25T12:49:20.642578Z"
    },
    "papermill": {
     "duration": 0.075583,
     "end_time": "2023-09-25T12:49:20.648335",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.572752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def load_userdict(self, f):\n",
    "#         '''\n",
    "#         Load personalized dict to improve detect rate.\n",
    "\n",
    "#         Parameter:\n",
    "#             - f : A plain text file contains words and their ocurrences.\n",
    "#                   Can be a file-like object, or the path of the dictionary file,\n",
    "#                   whose encoding must be utf-8.\n",
    "\n",
    "#         Structure of dict file:\n",
    "#         word1 freq1 word_type1\n",
    "#         word2 freq2 word_type2\n",
    "#         ...\n",
    "#         Word type may be ignored\n",
    "#         '''\n",
    "#         self.check_initialized()\n",
    "#         if isinstance(f, string_types):\n",
    "#             f_name = f\n",
    "#             f = open(f, 'rb')\n",
    "#         else:\n",
    "#             f_name = resolve_filename(f)\n",
    "#         for lineno, ln in enumerate(f, 1):\n",
    "#             line = ln.strip()\n",
    "#             if not isinstance(line, text_type):\n",
    "#                 try:\n",
    "#                     line = line.decode('utf-8').lstrip('\\ufeff')\n",
    "#                 except UnicodeDecodeError:\n",
    "#                     raise ValueError('dictionary file %s must be utf-8' % f_name)\n",
    "#             if not line:\n",
    "#                 continue\n",
    "#             # match won't be None because there's at least one character\n",
    "#             word, freq, tag = re_userdict.match(line).groups()\n",
    "#             if freq is not None:\n",
    "#                 freq = freq.strip()\n",
    "#             if tag is not None:\n",
    "#                 tag = tag.strip()\n",
    "#             self.add_word(word, freq, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ab04a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049039,
     "end_time": "2023-09-25T12:49:20.748134",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.699095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method loads a personalized dictionary into `jieba` instance.\n",
    "- This allows to add custom words with optional frequency and POS tags to improve word segmentation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8db81",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049665,
     "end_time": "2023-09-25T12:49:20.846687",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.797022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def add_word`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90f92aa5",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:20.947015Z",
     "iopub.status.busy": "2023-09-25T12:49:20.946204Z",
     "iopub.status.idle": "2023-09-25T12:49:20.950746Z",
     "shell.execute_reply": "2023-09-25T12:49:20.949940Z"
    },
    "papermill": {
     "duration": 0.057152,
     "end_time": "2023-09-25T12:49:20.952685",
     "exception": false,
     "start_time": "2023-09-25T12:49:20.895533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def add_word(self, word, freq=None, tag=None):\n",
    "#         \"\"\"\n",
    "#         Add a word to dictionary.\n",
    "\n",
    "#         freq and tag can be omitted, freq defaults to be a calculated value\n",
    "#         that ensures the word can be cut out.\n",
    "#         \"\"\"\n",
    "#         self.check_initialized()\n",
    "#         word = strdecode(word)\n",
    "#         freq = int(freq) if freq is not None else self.suggest_freq(word, False)\n",
    "#         self.FREQ[word] = freq\n",
    "#         self.total += freq\n",
    "#         if tag:\n",
    "#             self.user_word_tag_tab[word] = tag\n",
    "#         for ch in xrange(len(word)):\n",
    "#             wfrag = word[:ch + 1]\n",
    "#             if wfrag not in self.FREQ:\n",
    "#                 self.FREQ[wfrag] = 0\n",
    "#         if freq == 0:\n",
    "#             finalseg.add_force_split(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f82c18",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048933,
     "end_time": "2023-09-25T12:49:21.050502",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.001569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method allows to add a word, frequency, POS into `jieba` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68247cc",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049078,
     "end_time": "2023-09-25T12:49:21.149107",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.100029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def del_word`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bae695e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:21.252314Z",
     "iopub.status.busy": "2023-09-25T12:49:21.251460Z",
     "iopub.status.idle": "2023-09-25T12:49:21.255685Z",
     "shell.execute_reply": "2023-09-25T12:49:21.254810Z"
    },
    "papermill": {
     "duration": 0.058951,
     "end_time": "2023-09-25T12:49:21.257925",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.198974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def del_word(self, word):\n",
    "#         \"\"\"\n",
    "#         Convenient function for deleting a word.\n",
    "#         \"\"\"\n",
    "#         self.add_word(word, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7fafe",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.051132,
     "end_time": "2023-09-25T12:49:21.360679",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.309547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method deletes the word in a dictionary by turning its frequency to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8a004",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049679,
     "end_time": "2023-09-25T12:49:21.466031",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.416352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def suggest_freq`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5592c73",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:21.569215Z",
     "iopub.status.busy": "2023-09-25T12:49:21.568320Z",
     "iopub.status.idle": "2023-09-25T12:49:21.573827Z",
     "shell.execute_reply": "2023-09-25T12:49:21.572909Z"
    },
    "papermill": {
     "duration": 0.060018,
     "end_time": "2023-09-25T12:49:21.576283",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.516265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def suggest_freq(self, segment, tune=False):\n",
    "#         \"\"\"\n",
    "#         Suggest word frequency to force the characters in a word to be\n",
    "#         joined or splitted.\n",
    "\n",
    "#         Parameter:\n",
    "#             - segment : The segments that the word is expected to be cut into,\n",
    "#                         If the word should be treated as a whole, use a str.\n",
    "#             - tune : If True, tune the word frequency.\n",
    "\n",
    "#         Note that HMM may affect the final result. If the result doesn't change,\n",
    "#         set HMM=False.\n",
    "#         \"\"\"\n",
    "#         self.check_initialized()\n",
    "#         ftotal = float(self.total)\n",
    "#         freq = 1\n",
    "#         if isinstance(segment, string_types):\n",
    "#             word = segment\n",
    "#             for seg in self.cut(word, HMM=False):\n",
    "#                 freq *= self.FREQ.get(seg, 1) / ftotal\n",
    "#             freq = max(int(freq * self.total) + 1, self.FREQ.get(word, 1))\n",
    "#         else:\n",
    "#             segment = tuple(map(strdecode, segment))\n",
    "#             word = ''.join(segment)\n",
    "#             for seg in segment:\n",
    "#                 freq *= self.FREQ.get(seg, 1) / ftotal\n",
    "#             freq = min(int(freq * self.total), self.FREQ.get(word, 0))\n",
    "#         if tune:\n",
    "#             self.add_word(word, freq)\n",
    "#         return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174b2eb",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.051529,
     "end_time": "2023-09-25T12:49:21.679397",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.627868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method suggests a word frequency that can force the characters in a word to be joined or split during text segmentation.\n",
    "- This method can affect the behavior of Jieba during text segmentation.<br>It provides a way to customize word segmentations when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df5bf0",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.050199,
     "end_time": "2023-09-25T12:49:21.780397",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.730198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def tokenize`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "686a4080",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:21.883879Z",
     "iopub.status.busy": "2023-09-25T12:49:21.882768Z",
     "iopub.status.idle": "2023-09-25T12:49:21.888710Z",
     "shell.execute_reply": "2023-09-25T12:49:21.887529Z"
    },
    "papermill": {
     "duration": 0.060468,
     "end_time": "2023-09-25T12:49:21.891096",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.830628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def tokenize(self, unicode_sentence, mode=\"default\", HMM=True):\n",
    "#         \"\"\"\n",
    "#         Tokenize a sentence and yields tuples of (word, start, end)\n",
    "\n",
    "#         Parameter:\n",
    "#             - sentence: the str(unicode) to be segmented.\n",
    "#             - mode: \"default\" or \"search\", \"search\" is for finer segmentation.\n",
    "#             - HMM: whether to use the Hidden Markov Model.\n",
    "#         \"\"\"\n",
    "#         if not isinstance(unicode_sentence, text_type):\n",
    "#             raise ValueError(\"jieba: the input parameter should be unicode.\")\n",
    "#         start = 0\n",
    "#         if mode == 'default':\n",
    "#             for w in self.cut(unicode_sentence, HMM=HMM):\n",
    "#                 width = len(w)\n",
    "#                 yield (w, start, start + width)\n",
    "#                 start += width\n",
    "#         else:\n",
    "#             for w in self.cut(unicode_sentence, HMM=HMM):\n",
    "#                 width = len(w)\n",
    "#                 if len(w) > 2:\n",
    "#                     for i in xrange(len(w) - 1):\n",
    "#                         gram2 = w[i:i + 2]\n",
    "#                         if self.FREQ.get(gram2):\n",
    "#                             yield (gram2, start + i, start + i + 2)\n",
    "#                 if len(w) > 3:\n",
    "#                     for i in xrange(len(w) - 2):\n",
    "#                         gram3 = w[i:i + 3]\n",
    "#                         if self.FREQ.get(gram3):\n",
    "#                             yield (gram3, start + i, start + i + 3)\n",
    "#                 yield (w, start, start + width)\n",
    "#                 start += width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0bcea",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.04982,
     "end_time": "2023-09-25T12:49:21.990698",
     "exception": false,
     "start_time": "2023-09-25T12:49:21.940878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method tokenizes a given Unicode sentence into words or n-grams, depending on the mode (default or search).<br>It yields tuples containing each word or n-gram, along with their respective start and end positions within the original sentence.\n",
    "- This method provides flexible tokenization options for text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ad846",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.049406,
     "end_time": "2023-09-25T12:49:22.089771",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.040365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `def set_dictionary`\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57fab1e3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:22.190988Z",
     "iopub.status.busy": "2023-09-25T12:49:22.190536Z",
     "iopub.status.idle": "2023-09-25T12:49:22.195913Z",
     "shell.execute_reply": "2023-09-25T12:49:22.194668Z"
    },
    "papermill": {
     "duration": 0.058629,
     "end_time": "2023-09-25T12:49:22.198112",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.139483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#     def set_dictionary(self, dictionary_path):\n",
    "#         with self.lock:\n",
    "#             abs_path = _get_abs_path(dictionary_path)\n",
    "#             if not os.path.isfile(abs_path):\n",
    "#                 raise Exception(\"jieba: file does not exist: \" + abs_path)\n",
    "#             self.dictionary = abs_path\n",
    "#             self.initialized = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f252dc0",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.052086,
     "end_time": "2023-09-25T12:49:22.302562",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.250476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This method sets a custom dictionary for word segmentation.\n",
    "- It takes the path to a dictionary file as input, validates its existence, and sets it as the dictionary for segmentation.\n",
    "- This method ensures that you can use your custom dictionary with `jieba`, enhancing its flexibility for specific text processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638ac13",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048834,
     "end_time": "2023-09-25T12:49:22.401349",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.352515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "End of Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08655b18",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:22.504676Z",
     "iopub.status.busy": "2023-09-25T12:49:22.503956Z",
     "iopub.status.idle": "2023-09-25T12:49:22.509861Z",
     "shell.execute_reply": "2023-09-25T12:49:22.509139Z"
    },
    "papermill": {
     "duration": 0.060397,
     "end_time": "2023-09-25T12:49:22.511802",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.451405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # default Tokenizer instance\n",
    "\n",
    "# dt = Tokenizer()\n",
    "\n",
    "# # global functions\n",
    "\n",
    "# get_FREQ = lambda k, d=None: dt.FREQ.get(k, d)\n",
    "# add_word = dt.add_word\n",
    "# calc = dt.calc\n",
    "# cut = dt.cut\n",
    "# lcut = dt.lcut\n",
    "# cut_for_search = dt.cut_for_search\n",
    "# lcut_for_search = dt.lcut_for_search\n",
    "# del_word = dt.del_word\n",
    "# get_DAG = dt.get_DAG\n",
    "# get_dict_file = dt.get_dict_file\n",
    "# initialize = dt.initialize\n",
    "# load_userdict = dt.load_userdict\n",
    "# set_dictionary = dt.set_dictionary\n",
    "# suggest_freq = dt.suggest_freq\n",
    "# tokenize = dt.tokenize\n",
    "# user_word_tag_tab = dt.user_word_tag_tab\n",
    "\n",
    "\n",
    "# def _lcut_all(s):\n",
    "#     return dt._lcut_all(s)\n",
    "\n",
    "\n",
    "# def _lcut(s):\n",
    "#     return dt._lcut(s)\n",
    "\n",
    "\n",
    "# def _lcut_no_hmm(s):\n",
    "#     return dt._lcut_no_hmm(s)\n",
    "\n",
    "\n",
    "# def _lcut_all(s):\n",
    "#     return dt._lcut_all(s)\n",
    "\n",
    "\n",
    "# def _lcut_for_search(s):\n",
    "#     return dt._lcut_for_search(s)\n",
    "\n",
    "\n",
    "# def _lcut_for_search_no_hmm(s):\n",
    "#     return dt._lcut_for_search_no_hmm(s)\n",
    "\n",
    "\n",
    "# def _pcut(sentence, cut_all=False, HMM=True):\n",
    "#     parts = strdecode(sentence).splitlines(True)\n",
    "#     if cut_all:\n",
    "#         result = pool.map(_lcut_all, parts)\n",
    "#     elif HMM:\n",
    "#         result = pool.map(_lcut, parts)\n",
    "#     else:\n",
    "#         result = pool.map(_lcut_no_hmm, parts)\n",
    "#     for r in result:\n",
    "#         for w in r:\n",
    "#             yield w\n",
    "\n",
    "\n",
    "# def _pcut_for_search(sentence, HMM=True):\n",
    "#     parts = strdecode(sentence).splitlines(True)\n",
    "#     if HMM:\n",
    "#         result = pool.map(_lcut_for_search, parts)\n",
    "#     else:\n",
    "#         result = pool.map(_lcut_for_search_no_hmm, parts)\n",
    "#     for r in result:\n",
    "#         for w in r:\n",
    "#             yield w\n",
    "\n",
    "\n",
    "# def enable_parallel(processnum=None):\n",
    "#     \"\"\"\n",
    "#     Change the module's `cut` and `cut_for_search` functions to the\n",
    "#     parallel version.\n",
    "\n",
    "#     Note that this only works using dt, custom Tokenizer\n",
    "#     instances are not supported.\n",
    "#     \"\"\"\n",
    "#     global pool, dt, cut, cut_for_search\n",
    "#     from multiprocessing import cpu_count\n",
    "#     if os.name == 'nt':\n",
    "#         raise NotImplementedError(\n",
    "#             \"jieba: parallel mode only supports posix system\")\n",
    "#     else:\n",
    "#         from multiprocessing import Pool\n",
    "#     dt.check_initialized()\n",
    "#     if processnum is None:\n",
    "#         processnum = cpu_count()\n",
    "#     pool = Pool(processnum)\n",
    "#     cut = _pcut\n",
    "#     cut_for_search = _pcut_for_search\n",
    "\n",
    "\n",
    "# def disable_parallel():\n",
    "#     global pool, dt, cut, cut_for_search\n",
    "#     if pool:\n",
    "#         pool.close()\n",
    "#         pool = None\n",
    "#     cut = dt.cut\n",
    "#     cut_for_search = dt.cut_for_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321be09f",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.048677,
     "end_time": "2023-09-25T12:49:22.610499",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.561822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- This code defines a set of global functions and methods for `jieba`.\n",
    "- It creates a default Tokenizer instance (dt) and then defines various global functions and methods that allow users to interact with Jieba's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886589d4",
   "metadata": {
    "papermill": {
     "duration": 0.052318,
     "end_time": "2023-09-25T12:49:22.713758",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.661440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "<div id=\"emphasis\"></div>\n",
    "<strong><a href=\"#top\"> 🔺 Top</a></strong><br>\n",
    "<strong><a href=\"#jieba\"> 🔺 Top of Jieba</a></strong><br>\n",
    "<strong><a href=\"#jieba_read_me\"> 🔺 Jieba Read Me</a></strong><br>\n",
    "<strong><a href=\"#jieba_main_function\"> 🔺 Jieba Main Function </a></strong><br>\n",
    "<strong><a href=\"#jieba_cut\"> 🔺 Jieba Cut Method </a></strong><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1319f9",
   "metadata": {
    "papermill": {
     "duration": 0.049635,
     "end_time": "2023-09-25T12:49:22.813366",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.763731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb43b2ab",
   "metadata": {
    "papermill": {
     "duration": 0.049596,
     "end_time": "2023-09-25T12:49:22.913015",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.863419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# $Below\\ In\\ Progress$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774dc579",
   "metadata": {
    "papermill": {
     "duration": 0.049744,
     "end_time": "2023-09-25T12:49:23.012368",
     "exception": false,
     "start_time": "2023-09-25T12:49:22.962624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f3e0ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:23.115099Z",
     "iopub.status.busy": "2023-09-25T12:49:23.114372Z",
     "iopub.status.idle": "2023-09-25T12:49:23.123671Z",
     "shell.execute_reply": "2023-09-25T12:49:23.122925Z"
    },
    "papermill": {
     "duration": 0.062903,
     "end_time": "2023-09-25T12:49:23.125644",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.062741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cn_new = pd.DataFrame()\n",
    "en_new = pd.DataFrame()\n",
    "cn_new['input'] = \"Headline: \" + cn_example['headline'] + \"; Content: \" + cn_example['content']\n",
    "en_new['input'] = \"Headline: \" + en_example['headline'] + \"; Content: \" + en_example['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6609bbc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:23.228272Z",
     "iopub.status.busy": "2023-09-25T12:49:23.227496Z",
     "iopub.status.idle": "2023-09-25T12:49:23.238504Z",
     "shell.execute_reply": "2023-09-25T12:49:23.237686Z"
    },
    "papermill": {
     "duration": 0.065119,
     "end_time": "2023-09-25T12:49:23.240611",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.175492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [input]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_new[cn_new['input'].isna()==True]\n",
    "cn_new = cn_new.dropna()\n",
    "cn_new[cn_new['input'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf72080f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:23.345879Z",
     "iopub.status.busy": "2023-09-25T12:49:23.344719Z",
     "iopub.status.idle": "2023-09-25T12:49:23.357016Z",
     "shell.execute_reply": "2023-09-25T12:49:23.355926Z"
    },
    "papermill": {
     "duration": 0.067653,
     "end_time": "2023-09-25T12:49:23.359266",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.291613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [input]\n",
       "Index: []"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_new[en_new['input'].isna()==True]\n",
    "en_new = en_new.dropna()\n",
    "en_new[en_new['input'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfd49926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:23.461952Z",
     "iopub.status.busy": "2023-09-25T12:49:23.460903Z",
     "iopub.status.idle": "2023-09-25T12:49:23.473723Z",
     "shell.execute_reply": "2023-09-25T12:49:23.472680Z"
    },
    "papermill": {
     "duration": 0.066372,
     "end_time": "2023-09-25T12:49:23.475965",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.409593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headline: 陆军 领导 机构 火箭 军 战略 支援 部队 成立 大会 在京举行 习近...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input\n",
       "0  Headline: 陆军 领导 机构 火箭 军 战略 支援 部队 成立 大会 在京举行 习近..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headline: As U.S. budget fight looms, Republic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input\n",
       "0  Headline: As U.S. budget fight looms, Republic..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cn_new.head(5))\n",
    "display(en_new.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466c111",
   "metadata": {
    "papermill": {
     "duration": 0.050926,
     "end_time": "2023-09-25T12:49:23.576844",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.525918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenization\n",
    "Tokenization is the process of breaking down a text into smaller units, which are typically words or subwords.<br>These smaller units are called tokens.<br><br>\n",
    "In English, tokenization usually involves splitting text into words based on spaces, punctuation, or other delimiters.<br>\n",
    "For example, the sentence \"I love ice cream\" would be tokenized into the tokens: [\"I\", \"love\", \"ice\", \"cream\"].<br><br>\n",
    "In languages like Chinese, tokenization can be more complex since <br>Tokenization might involve segmenting text into characters or meaningful subword units.\n",
    "<br>\n",
    "\n",
    "### Trying Out SentencePiece\n",
    "Got the [Colab Doc](https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb#scrollTo=SUcAbKnRVAv6), but not sure how to use it yet.<br>\n",
    "As always, [abhishek](https://www.kaggle.com/abhishek)'s [notebook](https://www.kaggle.com/code/abhishek/sentencepiece-tokenizer-with-offsets/notebook) helped me a lot on SentencePiece implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa080c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:23.681862Z",
     "iopub.status.busy": "2023-09-25T12:49:23.681042Z",
     "iopub.status.idle": "2023-09-25T12:49:23.688577Z",
     "shell.execute_reply": "2023-09-25T12:49:23.687161Z"
    },
    "papermill": {
     "duration": 0.064219,
     "end_time": "2023-09-25T12:49:23.691951",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.627732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentencePieceTokenizer:\n",
    "    '''\n",
    "    from Abhishek Thakur's notebook\n",
    "    https://www.kaggle.com/code/abhishek/sentencepiece-tokenizer-with-offsets\n",
    "    '''\n",
    "    def __init__(self, model_path):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(model_path +'.model')\n",
    "        \n",
    "    def encode(self, sentence):\n",
    "        spt = sentencepiece_pb2.SentencePieceText()\n",
    "        spt.ParseFromString(self.sp.encode_as_serialized_proto(sentence))\n",
    "        offsets = []\n",
    "        tokens = []\n",
    "        for piece in spt.pieces:\n",
    "            tokens.append(piece.id)\n",
    "            offsets.append((piece.begin, piece.end))\n",
    "        return tokens, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "023f2b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:23.794658Z",
     "iopub.status.busy": "2023-09-25T12:49:23.794189Z",
     "iopub.status.idle": "2023-09-25T12:49:25.346938Z",
     "shell.execute_reply": "2023-09-25T12:49:25.345852Z"
    },
    "papermill": {
     "duration": 1.606875,
     "end_time": "2023-09-25T12:49:25.349662",
     "exception": false,
     "start_time": "2023-09-25T12:49:23.742787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/deberta_tok/tokenizer_config.json',\n",
       " '/kaggle/working/deberta_tok/special_tokens_map.json',\n",
       " '/kaggle/working/deberta_tok/spm.model',\n",
       " '/kaggle/working/deberta_tok/added_tokens.json',\n",
       " '/kaggle/working/deberta_tok/tokenizer.json')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_tok = AutoTokenizer.from_pretrained('/kaggle/input/debertav3base')\n",
    "deberta_tok.save_pretrained('/kaggle/working/deberta_tok/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6594ed6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:25.456108Z",
     "iopub.status.busy": "2023-09-25T12:49:25.455654Z",
     "iopub.status.idle": "2023-09-25T12:49:25.770981Z",
     "shell.execute_reply": "2023-09-25T12:49:25.770121Z"
    },
    "papermill": {
     "duration": 0.370617,
     "end_time": "2023-09-25T12:49:25.773143",
     "exception": false,
     "start_time": "2023-09-25T12:49:25.402526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spt = SentencePieceTokenizer('/kaggle/input/debertav3base/spm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ebb4b7",
   "metadata": {
    "papermill": {
     "duration": 0.05126,
     "end_time": "2023-09-25T12:49:25.966516",
     "exception": false,
     "start_time": "2023-09-25T12:49:25.915256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoding\n",
    "Here I have tried on encoding different words, languages and tokens.<br>\n",
    "Let's see if it works well!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fb2fe",
   "metadata": {
    "papermill": {
     "duration": 0.050546,
     "end_time": "2023-09-25T12:49:26.067456",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.016910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Tokens\n",
    "It is fun to see how these tokens are treated *similarly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9867609d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:26.171385Z",
     "iopub.status.busy": "2023-09-25T12:49:26.170590Z",
     "iopub.status.idle": "2023-09-25T12:49:26.178261Z",
     "shell.execute_reply": "2023-09-25T12:49:26.177479Z"
    },
    "papermill": {
     "duration": 0.062585,
     "end_time": "2023-09-25T12:49:26.180871",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.118286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MASK] encoded into \t([647, 41197, 1301, 592], [(0, 1), (1, 4), (4, 5), (5, 6)])\n",
      "[CLS] encoded into \t([647, 16312, 430, 592], [(0, 1), (1, 3), (3, 4), (4, 5)])\n",
      "[EOS] encoded into \t([647, 90925, 592], [(0, 1), (1, 4), (4, 5)])\n",
      "[UNK] encoded into \t([647, 63960, 592], [(0, 1), (1, 4), (4, 5)])\n",
      "[SEP] encoded into \t([647, 74606, 592], [(0, 1), (1, 4), (4, 5)])\n",
      "[SPECIAL] encoded into \t([647, 118403, 592], [(0, 1), (1, 8), (8, 9)])\n",
      "\n",
      "MASK encoded into \t([34877, 1301], [(0, 3), (3, 4)])\n",
      "CLS encoded into \t([62456], [(0, 3)])\n",
      "EOS encoded into \t([27479], [(0, 3)])\n",
      "UNK encoded into \t([4647, 1301], [(0, 2), (2, 3)])\n",
      "SEP encoded into \t([43355], [(0, 3)])\n",
      "SPECIAL encoded into \t([26329], [(0, 7)])\n"
     ]
    }
   ],
   "source": [
    "print(f\"[MASK] encoded into \\t{spt.encode('[MASK]')}\")\n",
    "print(f\"[CLS] encoded into \\t{spt.encode('[CLS]')}\")\n",
    "print(f\"[EOS] encoded into \\t{spt.encode('[EOS]')}\")\n",
    "print(f\"[UNK] encoded into \\t{spt.encode('[UNK]')}\")\n",
    "print(f\"[SEP] encoded into \\t{spt.encode('[SEP]')}\")\n",
    "print(f\"[SPECIAL] encoded into \\t{spt.encode('[SPECIAL]')}\")\n",
    "print()\n",
    "print(f\"MASK encoded into \\t{spt.encode('MASK')}\")\n",
    "print(f\"CLS encoded into \\t{spt.encode('CLS')}\")\n",
    "print(f\"EOS encoded into \\t{spt.encode('EOS')}\")\n",
    "print(f\"UNK encoded into \\t{spt.encode('UNK')}\")\n",
    "print(f\"SEP encoded into \\t{spt.encode('SEP')}\")\n",
    "print(f\"SPECIAL encoded into \\t{spt.encode('SPECIAL')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "666f735d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:26.287231Z",
     "iopub.status.busy": "2023-09-25T12:49:26.286721Z",
     "iopub.status.idle": "2023-09-25T12:49:26.299351Z",
     "shell.execute_reply": "2023-09-25T12:49:26.298233Z"
    },
    "papermill": {
     "duration": 0.069429,
     "end_time": "2023-09-25T12:49:26.301694",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.232265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MASK] encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [128000], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "[CLS] encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [1], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "[EOS] encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [647, 90925, 592], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n",
      "\n",
      "[UNK] encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [3], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "[SEP] encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [2], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "[SPECIAL] encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [647, 118403, 592], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n",
      "\n",
      "\n",
      "MASK encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [34877, 1301], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}\n",
      "\n",
      "CLS encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [62456], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "EOS encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [27479], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "UNK encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [4647, 1301], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}\n",
      "\n",
      "SEP encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [43355], 'token_type_ids': [0], 'attention_mask': [1]}\n",
      "\n",
      "SPECIAL encoded into :\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "{'input_ids': [26329], 'token_type_ids': [0], 'attention_mask': [1]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"[MASK] encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('[MASK]', add_special_tokens=False)}\")\n",
    "print(f\"\\n[CLS] encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('[CLS]', add_special_tokens=False)}\")\n",
    "print(f\"\\n[EOS] encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('[EOS]', add_special_tokens=False)}\")\n",
    "print(f\"\\n[UNK] encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('[UNK]', add_special_tokens=False)}\")\n",
    "print(f\"\\n[SEP] encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('[SEP]', add_special_tokens=False)}\")\n",
    "print(f\"\\n[SPECIAL] encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('[SPECIAL]', add_special_tokens=False)}\")\n",
    "print()\n",
    "print(f\"\\nMASK encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('MASK', add_special_tokens=False)}\")\n",
    "print(f\"\\nCLS encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('CLS', add_special_tokens=False)}\")\n",
    "print(f\"\\nEOS encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('EOS', add_special_tokens=False)}\")\n",
    "print(f\"\\nUNK encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('UNK', add_special_tokens=False)}\")\n",
    "print(f\"\\nSEP encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('SEP', add_special_tokens=False)}\")\n",
    "print(f\"\\nSPECIAL encoded into :\\nvvvvvvvvvvvvvvvvvvvvvvvvvv\\n{deberta_tok('SPECIAL', add_special_tokens=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0068c",
   "metadata": {
    "papermill": {
     "duration": 0.051786,
     "end_time": "2023-09-25T12:49:26.405225",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.353439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### English words\n",
    "We can see that these sample English words are encoded properly *(maybe?)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3affeca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:26.514337Z",
     "iopub.status.busy": "2023-09-25T12:49:26.513470Z",
     "iopub.status.idle": "2023-09-25T12:49:26.528084Z",
     "shell.execute_reply": "2023-09-25T12:49:26.526996Z"
    },
    "papermill": {
     "duration": 0.069747,
     "end_time": "2023-09-25T12:49:26.530282",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.460535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([70864, 294], [(0, 8), (8, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([70864, 294, 463, 543, 260], [(0, 8), (8, 9), (9, 12), (12, 14), (14, 15)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([70864, 294, 463, 543, 260, 430, 260, 1753, 1801],\n",
       " [(0, 8),\n",
       "  (8, 9),\n",
       "  (9, 12),\n",
       "  (12, 14),\n",
       "  (14, 15),\n",
       "  (15, 16),\n",
       "  (16, 17),\n",
       "  (17, 24),\n",
       "  (24, 30)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([70864, 294, 463, 543, 260, 430, 260, 1753, 1801, 34405, 261, 4780],\n",
       " [(0, 8),\n",
       "  (8, 9),\n",
       "  (9, 12),\n",
       "  (12, 14),\n",
       "  (14, 15),\n",
       "  (15, 16),\n",
       "  (16, 17),\n",
       "  (17, 24),\n",
       "  (24, 30),\n",
       "  (30, 36),\n",
       "  (36, 37),\n",
       "  (37, 49)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spt.encode(en_new.input[0][:10]))\n",
    "display(spt.encode(en_new.input[0][:15]))\n",
    "display(spt.encode(en_new.input[0][:30]))\n",
    "display(spt.encode(en_new.input[0][:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8ea2347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:26.635497Z",
     "iopub.status.busy": "2023-09-25T12:49:26.635029Z",
     "iopub.status.idle": "2023-09-25T12:49:26.649726Z",
     "shell.execute_reply": "2023-09-25T12:49:26.648554Z"
    },
    "papermill": {
     "duration": 0.069705,
     "end_time": "2023-09-25T12:49:26.651751",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.582046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294, 463, 543, 260], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294, 463, 543, 260, 430, 260, 1753, 1801], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294, 463, 543, 260, 430, 260, 1753, 1801, 34405, 261, 4780], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(deberta_tok(en_new.input[0][:10], add_special_tokens=False))\n",
    "display(deberta_tok(en_new.input[0][:15], add_special_tokens=False))\n",
    "display(deberta_tok(en_new.input[0][:30], add_special_tokens=False))\n",
    "display(deberta_tok(en_new.input[0][:50], add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f6e15",
   "metadata": {
    "papermill": {
     "duration": 0.054082,
     "end_time": "2023-09-25T12:49:26.758944",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.704862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Chinese words\n",
    "Now the problem begins, the last digit of the encoded tensors different.<br> *(which I think is the bytes taken)*<br>\n",
    "Which implies that this doesn't work at all for Chinese words.<br><br>\n",
    "**edit**<br>\n",
    "Wait what...?<br>\n",
    "Last time I checked, there were no differences between 你 and 您.<br>\n",
    "But when I check it now, there is a difference...<br>\n",
    "It seems like deberta is also working well for Chinese characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec5c4193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:26.865052Z",
     "iopub.status.busy": "2023-09-25T12:49:26.864187Z",
     "iopub.status.idle": "2023-09-25T12:49:26.883407Z",
     "shell.execute_reply": "2023-09-25T12:49:26.882578Z"
    },
    "papermill": {
     "duration": 0.07539,
     "end_time": "2023-09-25T12:49:26.885570",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.810180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([70864, 294], [(0, 8), (8, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([70864, 294, 507, 124947, 123535, 507, 123616, 105093],\n",
       " [(0, 8), (8, 9), (9, 10), (10, 13), (13, 16), (16, 17), (17, 20), (20, 23)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([70864,\n",
       "  294,\n",
       "  507,\n",
       "  124947,\n",
       "  123535,\n",
       "  507,\n",
       "  123616,\n",
       "  105093,\n",
       "  507,\n",
       "  67312,\n",
       "  119767,\n",
       "  507,\n",
       "  122496,\n",
       "  126721,\n",
       "  507,\n",
       "  123535,\n",
       "  507,\n",
       "  123495,\n",
       "  122639,\n",
       "  507,\n",
       "  119705,\n",
       "  123863],\n",
       " [(0, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 13),\n",
       "  (13, 16),\n",
       "  (16, 17),\n",
       "  (17, 20),\n",
       "  (20, 23),\n",
       "  (23, 24),\n",
       "  (24, 27),\n",
       "  (27, 30),\n",
       "  (30, 31),\n",
       "  (31, 34),\n",
       "  (34, 37),\n",
       "  (37, 38),\n",
       "  (38, 41),\n",
       "  (41, 42),\n",
       "  (42, 45),\n",
       "  (45, 48),\n",
       "  (48, 49),\n",
       "  (49, 52),\n",
       "  (52, 55)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([70864,\n",
       "  294,\n",
       "  507,\n",
       "  124947,\n",
       "  123535,\n",
       "  507,\n",
       "  123616,\n",
       "  105093,\n",
       "  507,\n",
       "  67312,\n",
       "  119767,\n",
       "  507,\n",
       "  122496,\n",
       "  126721,\n",
       "  507,\n",
       "  123535,\n",
       "  507,\n",
       "  123495,\n",
       "  122639,\n",
       "  507,\n",
       "  119705,\n",
       "  123863,\n",
       "  507,\n",
       "  32349,\n",
       "  124226,\n",
       "  507,\n",
       "  45373,\n",
       "  93826,\n",
       "  110344,\n",
       "  51942,\n",
       "  81061],\n",
       " [(0, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 13),\n",
       "  (13, 16),\n",
       "  (16, 17),\n",
       "  (17, 20),\n",
       "  (20, 23),\n",
       "  (23, 24),\n",
       "  (24, 27),\n",
       "  (27, 30),\n",
       "  (30, 31),\n",
       "  (31, 34),\n",
       "  (34, 37),\n",
       "  (37, 38),\n",
       "  (38, 41),\n",
       "  (41, 42),\n",
       "  (42, 45),\n",
       "  (45, 48),\n",
       "  (48, 49),\n",
       "  (49, 52),\n",
       "  (52, 55),\n",
       "  (55, 56),\n",
       "  (56, 59),\n",
       "  (59, 62),\n",
       "  (62, 63),\n",
       "  (63, 66),\n",
       "  (66, 69),\n",
       "  (69, 73),\n",
       "  (73, 76),\n",
       "  (76, 80)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spt.encode(cn_new.input[0][:10]))\n",
    "display(spt.encode(cn_new.input[0][:15]))\n",
    "display(spt.encode(cn_new.input[0][:30]))\n",
    "display(spt.encode(cn_new.input[0][:40]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "88271c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:26.992200Z",
     "iopub.status.busy": "2023-09-25T12:49:26.991750Z",
     "iopub.status.idle": "2023-09-25T12:49:27.003838Z",
     "shell.execute_reply": "2023-09-25T12:49:27.003130Z"
    },
    "papermill": {
     "duration": 0.067335,
     "end_time": "2023-09-25T12:49:27.005701",
     "exception": false,
     "start_time": "2023-09-25T12:49:26.938366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294, 507, 124947, 123535, 507, 123616, 105093], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294, 507, 124947, 123535, 507, 123616, 105093, 507, 67312, 119767, 507, 122496, 126721, 507, 123535, 507, 123495, 122639, 507, 119705, 123863], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [70864, 294, 507, 124947, 123535, 507, 123616, 105093, 507, 67312, 119767, 507, 122496, 126721, 507, 123535, 507, 123495, 122639, 507, 119705, 123863, 507, 32349, 124226, 507, 45373, 93826, 110344, 51942, 81061], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(deberta_tok(cn_new.input[0][:10], add_special_tokens=False))\n",
    "display(deberta_tok(cn_new.input[0][:15], add_special_tokens=False))\n",
    "display(deberta_tok(cn_new.input[0][:30], add_special_tokens=False))\n",
    "display(deberta_tok(cn_new.input[0][:40], add_special_tokens=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb94c5",
   "metadata": {
    "papermill": {
     "duration": 0.053266,
     "end_time": "2023-09-25T12:49:27.111189",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.057923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So I tried... and this works!!<br>\n",
    "**edit** I will leave below as it is.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1e130002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:27.221726Z",
     "iopub.status.busy": "2023-09-25T12:49:27.220567Z",
     "iopub.status.idle": "2023-09-25T12:49:27.275962Z",
     "shell.execute_reply": "2023-09-25T12:49:27.275114Z"
    },
    "papermill": {
     "duration": 0.112293,
     "end_time": "2023-09-25T12:49:27.278509",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.166216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cn_spt = SentencePieceTokenizer('/kaggle/input/sentencepiece-chinese-bpe/chinese/chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "31bca54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:27.386539Z",
     "iopub.status.busy": "2023-09-25T12:49:27.385816Z",
     "iopub.status.idle": "2023-09-25T12:49:27.403582Z",
     "shell.execute_reply": "2023-09-25T12:49:27.402702Z"
    },
    "papermill": {
     "duration": 0.07393,
     "end_time": "2023-09-25T12:49:27.405698",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.331768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([45440, 0, 47680, 47160, 47717, 47242, 37682, 47680, 45541],\n",
       " [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 7), (7, 8), (8, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([45440,\n",
       "  0,\n",
       "  47680,\n",
       "  47160,\n",
       "  47717,\n",
       "  47242,\n",
       "  37682,\n",
       "  47680,\n",
       "  45541,\n",
       "  45440,\n",
       "  46077,\n",
       "  46385,\n",
       "  45440,\n",
       "  46303,\n",
       "  46235],\n",
       " [(0, 0),\n",
       "  (0, 1),\n",
       "  (1, 2),\n",
       "  (2, 3),\n",
       "  (3, 4),\n",
       "  (4, 5),\n",
       "  (5, 7),\n",
       "  (7, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 13),\n",
       "  (13, 16),\n",
       "  (16, 17),\n",
       "  (17, 20),\n",
       "  (20, 23)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([45440,\n",
       "  0,\n",
       "  47680,\n",
       "  47160,\n",
       "  47717,\n",
       "  47242,\n",
       "  37682,\n",
       "  47680,\n",
       "  45541,\n",
       "  45440,\n",
       "  46077,\n",
       "  46385,\n",
       "  45440,\n",
       "  46303,\n",
       "  46235,\n",
       "  45440,\n",
       "  46035,\n",
       "  47362,\n",
       "  8500,\n",
       "  46892,\n",
       "  45440,\n",
       "  46385,\n",
       "  45440,\n",
       "  45679,\n",
       "  45681,\n",
       "  45440,\n",
       "  12518],\n",
       " [(0, 0),\n",
       "  (0, 1),\n",
       "  (1, 2),\n",
       "  (2, 3),\n",
       "  (3, 4),\n",
       "  (4, 5),\n",
       "  (5, 7),\n",
       "  (7, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 13),\n",
       "  (13, 16),\n",
       "  (16, 17),\n",
       "  (17, 20),\n",
       "  (20, 23),\n",
       "  (23, 24),\n",
       "  (24, 27),\n",
       "  (27, 30),\n",
       "  (30, 34),\n",
       "  (34, 37),\n",
       "  (37, 38),\n",
       "  (38, 41),\n",
       "  (41, 42),\n",
       "  (42, 45),\n",
       "  (45, 48),\n",
       "  (48, 49),\n",
       "  (49, 55)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([45440,\n",
       "  0,\n",
       "  47680,\n",
       "  47160,\n",
       "  47717,\n",
       "  47242,\n",
       "  37682,\n",
       "  47680,\n",
       "  45541,\n",
       "  45440,\n",
       "  46077,\n",
       "  46385,\n",
       "  45440,\n",
       "  46303,\n",
       "  46235,\n",
       "  45440,\n",
       "  46035,\n",
       "  47362,\n",
       "  8500,\n",
       "  46892,\n",
       "  45440,\n",
       "  46385,\n",
       "  45440,\n",
       "  45679,\n",
       "  45681,\n",
       "  45440,\n",
       "  12518,\n",
       "  45440,\n",
       "  4650,\n",
       "  45440,\n",
       "  15389,\n",
       "  45440,\n",
       "  1648,\n",
       "  69],\n",
       " [(0, 0),\n",
       "  (0, 1),\n",
       "  (1, 2),\n",
       "  (2, 3),\n",
       "  (3, 4),\n",
       "  (4, 5),\n",
       "  (5, 7),\n",
       "  (7, 8),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 13),\n",
       "  (13, 16),\n",
       "  (16, 17),\n",
       "  (17, 20),\n",
       "  (20, 23),\n",
       "  (23, 24),\n",
       "  (24, 27),\n",
       "  (27, 30),\n",
       "  (30, 34),\n",
       "  (34, 37),\n",
       "  (37, 38),\n",
       "  (38, 41),\n",
       "  (41, 42),\n",
       "  (42, 45),\n",
       "  (45, 48),\n",
       "  (48, 49),\n",
       "  (49, 55),\n",
       "  (55, 56),\n",
       "  (56, 62),\n",
       "  (62, 63),\n",
       "  (63, 69),\n",
       "  (69, 70),\n",
       "  (70, 76),\n",
       "  (76, 80)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cn_spt.encode(cn_new.input[0][:10]))\n",
    "display(cn_spt.encode(cn_new.input[0][:15]))\n",
    "display(cn_spt.encode(cn_new.input[0][:30]))\n",
    "display(cn_spt.encode(cn_new.input[0][:40]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f54b41",
   "metadata": {
    "papermill": {
     "duration": 0.053103,
     "end_time": "2023-09-25T12:49:27.513378",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.460275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Korean words\n",
    "Same here, I am pretty... no very sure that this doesn't work on foreign languages.<br><br>\n",
    "**edit**<br>\n",
    "Oops.. again, this seems like it works well...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4703e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:27.622104Z",
     "iopub.status.busy": "2023-09-25T12:49:27.621683Z",
     "iopub.status.idle": "2023-09-25T12:49:27.654934Z",
     "shell.execute_reply": "2023-09-25T12:49:27.654146Z"
    },
    "papermill": {
     "duration": 0.090075,
     "end_time": "2023-09-25T12:49:27.656944",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.566869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([68368], [(0, 3)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([40416], [(0, 3)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([92686, 125249], [(0, 3), (3, 6)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([92686, 125249, 46948, 64614, 48255],\n",
       " [(0, 3), (3, 6), (6, 9), (9, 12), (12, 15)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([28507, 121908], [(0, 3), (3, 6)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([28507, 121908, 23493], [(0, 3), (3, 6), (6, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([28507, 123015, 43590], [(0, 3), (3, 6), (6, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([28507, 123015, 43590, 90144], [(0, 3), (3, 6), (6, 9), (9, 18)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([92686, 125249, 46948, 64614, 48255, 40416, 28507, 121908, 23493],\n",
       " [(0, 3),\n",
       "  (3, 6),\n",
       "  (6, 9),\n",
       "  (9, 12),\n",
       "  (12, 15),\n",
       "  (15, 19),\n",
       "  (19, 23),\n",
       "  (23, 26),\n",
       "  (26, 29)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([92686,\n",
       "  125249,\n",
       "  46948,\n",
       "  64614,\n",
       "  48255,\n",
       "  40416,\n",
       "  28507,\n",
       "  121908,\n",
       "  23493,\n",
       "  28507,\n",
       "  123015,\n",
       "  43590,\n",
       "  90144],\n",
       " [(0, 3),\n",
       "  (3, 6),\n",
       "  (6, 9),\n",
       "  (9, 12),\n",
       "  (12, 15),\n",
       "  (15, 19),\n",
       "  (19, 23),\n",
       "  (23, 26),\n",
       "  (26, 29),\n",
       "  (29, 33),\n",
       "  (33, 36),\n",
       "  (36, 39),\n",
       "  (39, 48)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([92686,\n",
       "  125249,\n",
       "  46948,\n",
       "  64614,\n",
       "  48255,\n",
       "  260,\n",
       "  40416,\n",
       "  28507,\n",
       "  121908,\n",
       "  23493,\n",
       "  28507,\n",
       "  123015,\n",
       "  43590,\n",
       "  90144,\n",
       "  260,\n",
       "  507,\n",
       "  123965,\n",
       "  51909,\n",
       "  31753,\n",
       "  70883,\n",
       "  46635,\n",
       "  18454,\n",
       "  507,\n",
       "  52422,\n",
       "  89215,\n",
       "  260],\n",
       " [(0, 3),\n",
       "  (3, 6),\n",
       "  (6, 9),\n",
       "  (9, 12),\n",
       "  (12, 15),\n",
       "  (15, 16),\n",
       "  (16, 20),\n",
       "  (20, 24),\n",
       "  (24, 27),\n",
       "  (27, 30),\n",
       "  (30, 34),\n",
       "  (34, 37),\n",
       "  (37, 40),\n",
       "  (40, 49),\n",
       "  (49, 50),\n",
       "  (50, 51),\n",
       "  (51, 54),\n",
       "  (54, 57),\n",
       "  (57, 63),\n",
       "  (63, 67),\n",
       "  (67, 70),\n",
       "  (70, 73),\n",
       "  (73, 74),\n",
       "  (74, 80),\n",
       "  (80, 93),\n",
       "  (93, 94)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spt.encode('나'))\n",
    "display(spt.encode('제'))\n",
    "print()\n",
    "display(spt.encode('안녕'))\n",
    "display(spt.encode('안녕하세요'))\n",
    "print()\n",
    "display(spt.encode('이름'))\n",
    "display(spt.encode('이름은'))\n",
    "print()\n",
    "display(spt.encode('이희상'))\n",
    "display(spt.encode('이희상입니다'))\n",
    "print()\n",
    "display(spt.encode('안녕하세요 제 이름은'))\n",
    "display(spt.encode('안녕하세요 제 이름은 이희상입니다'))\n",
    "display(spt.encode('안녕하세요. 제 이름은 이희상입니다. 홍대에서 공부를 하고 있습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4113bb31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:27.770310Z",
     "iopub.status.busy": "2023-09-25T12:49:27.769259Z",
     "iopub.status.idle": "2023-09-25T12:49:27.800920Z",
     "shell.execute_reply": "2023-09-25T12:49:27.799900Z"
    },
    "papermill": {
     "duration": 0.090421,
     "end_time": "2023-09-25T12:49:27.803130",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.712709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [68368], 'token_type_ids': [0], 'attention_mask': [1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [40416], 'token_type_ids': [0], 'attention_mask': [1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [92686, 125249], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [92686, 125249, 46948, 64614, 48255], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [28507, 121908], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [28507, 121908, 23493], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [28507, 123015, 43590], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [28507, 123015, 43590, 90144], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [92686, 125249, 46948, 64614, 48255, 40416, 28507, 121908, 23493], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [92686, 125249, 46948, 64614, 48255, 40416, 28507, 121908, 23493, 28507, 123015, 43590, 90144], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [92686, 125249, 46948, 64614, 48255, 260, 40416, 28507, 121908, 23493, 28507, 123015, 43590, 90144, 260, 507, 123965, 51909, 31753, 70883, 46635, 18454, 507, 52422, 89215, 260], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(deberta_tok('나', add_special_tokens=False))\n",
    "display(deberta_tok('제', add_special_tokens=False))\n",
    "print()\n",
    "display(deberta_tok('안녕', add_special_tokens=False))\n",
    "display(deberta_tok('안녕하세요', add_special_tokens=False))\n",
    "print()\n",
    "display(deberta_tok('이름', add_special_tokens=False))\n",
    "display(deberta_tok('이름은', add_special_tokens=False))\n",
    "print()\n",
    "display(deberta_tok('이희상', add_special_tokens=False))\n",
    "display(deberta_tok('이희상입니다', add_special_tokens=False))\n",
    "print()\n",
    "display(deberta_tok('안녕하세요 제 이름은', add_special_tokens=False))\n",
    "display(deberta_tok('안녕하세요 제 이름은 이희상입니다', add_special_tokens=False))\n",
    "display(deberta_tok('안녕하세요. 제 이름은 이희상입니다. 홍대에서 공부를 하고 있습니다.', add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1230dd6",
   "metadata": {
    "papermill": {
     "duration": 0.055086,
     "end_time": "2023-09-25T12:49:27.915644",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.860558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, I tried as below!<br>\n",
    "It seems like it is working properly! :)<br><br>\n",
    "\n",
    "**edit**<br>\n",
    "I will leave below as it is.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "daa9c043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:28.030335Z",
     "iopub.status.busy": "2023-09-25T12:49:28.029573Z",
     "iopub.status.idle": "2023-09-25T12:49:28.147027Z",
     "shell.execute_reply": "2023-09-25T12:49:28.146021Z"
    },
    "papermill": {
     "duration": 0.180529,
     "end_time": "2023-09-25T12:49:28.151996",
     "exception": false,
     "start_time": "2023-09-25T12:49:27.971467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ko_spt = SentencePieceTokenizer('/kaggle/input/airc-keti-ke-t5/vocab/sentencepiece_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cbe1fd38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T12:49:28.271049Z",
     "iopub.status.busy": "2023-09-25T12:49:28.269756Z",
     "iopub.status.idle": "2023-09-25T12:49:28.305590Z",
     "shell.execute_reply": "2023-09-25T12:49:28.304571Z"
    },
    "papermill": {
     "duration": 0.099514,
     "end_time": "2023-09-25T12:49:28.307527",
     "exception": false,
     "start_time": "2023-09-25T12:49:28.208013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([319], [(0, 3)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([37], [(0, 3)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5264], [(0, 6)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([5264, 9, 1520], [(0, 6), (6, 9), (9, 15)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([773], [(0, 6)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([773, 11], [(0, 6), (6, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([26, 4686, 206], [(0, 3), (3, 6), (6, 9)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([26, 4686, 206, 3861, 512, 6],\n",
       " [(0, 3), (3, 6), (6, 9), (9, 12), (12, 15), (15, 18)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5264, 9, 1520, 37, 773, 11],\n",
       " [(0, 6), (6, 9), (9, 15), (15, 19), (19, 26), (26, 29)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([5264, 9, 1520, 37, 773, 11, 26, 4686, 206, 3861, 512, 6],\n",
       " [(0, 6),\n",
       "  (6, 9),\n",
       "  (9, 15),\n",
       "  (15, 19),\n",
       "  (19, 26),\n",
       "  (26, 29),\n",
       "  (29, 33),\n",
       "  (33, 36),\n",
       "  (36, 39),\n",
       "  (39, 42),\n",
       "  (42, 45),\n",
       "  (45, 48)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([5264,\n",
       "  9,\n",
       "  1520,\n",
       "  62690,\n",
       "  37,\n",
       "  773,\n",
       "  11,\n",
       "  26,\n",
       "  4686,\n",
       "  206,\n",
       "  3861,\n",
       "  512,\n",
       "  6,\n",
       "  62690,\n",
       "  1990,\n",
       "  124,\n",
       "  16,\n",
       "  2984,\n",
       "  10,\n",
       "  40,\n",
       "  12,\n",
       "  40011,\n",
       "  51,\n",
       "  62690],\n",
       " [(0, 6),\n",
       "  (6, 9),\n",
       "  (9, 15),\n",
       "  (15, 16),\n",
       "  (16, 20),\n",
       "  (20, 27),\n",
       "  (27, 30),\n",
       "  (30, 34),\n",
       "  (34, 37),\n",
       "  (37, 40),\n",
       "  (40, 43),\n",
       "  (43, 46),\n",
       "  (46, 49),\n",
       "  (49, 50),\n",
       "  (50, 54),\n",
       "  (54, 57),\n",
       "  (57, 63),\n",
       "  (63, 70),\n",
       "  (70, 73),\n",
       "  (73, 74),\n",
       "  (74, 80),\n",
       "  (80, 84),\n",
       "  (84, 93),\n",
       "  (93, 94)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ko_spt.encode('나'))\n",
    "display(ko_spt.encode('제'))\n",
    "print()\n",
    "display(ko_spt.encode('안녕'))\n",
    "display(ko_spt.encode('안녕하세요'))\n",
    "print()\n",
    "display(ko_spt.encode('이름'))\n",
    "display(ko_spt.encode('이름은'))\n",
    "print()\n",
    "display(ko_spt.encode('이희상'))\n",
    "display(ko_spt.encode('이희상입니다'))\n",
    "print()\n",
    "display(ko_spt.encode('안녕하세요 제 이름은'))\n",
    "display(ko_spt.encode('안녕하세요 제 이름은 이희상입니다'))\n",
    "display(ko_spt.encode('안녕하세요. 제 이름은 이희상입니다. 홍대에서 공부를 하고 있습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87fe53",
   "metadata": {
    "papermill": {
     "duration": 0.057593,
     "end_time": "2023-09-25T12:49:28.423143",
     "exception": false,
     "start_time": "2023-09-25T12:49:28.365550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf21178",
   "metadata": {
    "papermill": {
     "duration": 0.057961,
     "end_time": "2023-09-25T12:49:28.538939",
     "exception": false,
     "start_time": "2023-09-25T12:49:28.480978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.879038,
   "end_time": "2023-09-25T12:49:29.723692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-25T12:48:32.844654",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
