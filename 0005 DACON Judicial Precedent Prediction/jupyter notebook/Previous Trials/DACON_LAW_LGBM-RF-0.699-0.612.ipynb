{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc258d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ___________________________\n",
      "|                           |\n",
      "|======== YearDream ========|\n",
      "|===========================|\n",
      "|==== DLC Well Imported ====|\n",
      "|===========================|\n",
      "|========= BYJASON =========|\n",
      "|___________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import dacon_law_class as dlc\n",
    "from dacon_law_class import SimpleOps as so\n",
    "\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "# import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247af21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8011b50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>TEST_1235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>TEST_1236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>TEST_1237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>TEST_1238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>TEST_1239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  first_party_winner\n",
       "0     TEST_0000                   0\n",
       "1     TEST_0001                   0\n",
       "2     TEST_0002                   0\n",
       "3     TEST_0003                   0\n",
       "4     TEST_0004                   0\n",
       "...         ...                 ...\n",
       "1235  TEST_1235                   0\n",
       "1236  TEST_1236                   0\n",
       "1237  TEST_1237                   0\n",
       "1238  TEST_1238                   0\n",
       "1239  TEST_1239                   0\n",
       "\n",
       "[1240 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "# test\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2ef6ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ID                  2478 non-null   object\n",
      " 1   first_party         2478 non-null   object\n",
      " 2   second_party        2478 non-null   object\n",
      " 3   facts               2478 non-null   object\n",
      " 4   first_party_winner  2478 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 96.9+ KB\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "print('\\n\\n\\n')\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b052690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phil amant</td>\n",
       "      <td>herman ompson</td>\n",
       "      <td>phil amant caidate for public office made tele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ephen duncan</td>\n",
       "      <td>lawrence owens</td>\n",
       "      <td>ramon nelson was ridin his bike when he suffer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>billy joe mawood</td>\n",
       "      <td>tony patterson waen et al</td>\n",
       "      <td>an alabama ate court convicted billy joe mawoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkletter</td>\n",
       "      <td>walker</td>\n",
       "      <td>victor linkletter was convicted in ate court o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "      <td>in selma alabama an intruder broke into apartm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>hollyfrontier cheyenne refinin llc et al</td>\n",
       "      <td>renewable fuels association et al</td>\n",
       "      <td>conress ameed clean air act rouh enery policy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>rupo mexicano de desarrollo</td>\n",
       "      <td>alliance bo fu inc</td>\n",
       "      <td>alliance bo fu inc an invement fu purchased ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>peuero</td>\n",
       "      <td>united ates</td>\n",
       "      <td>in dirict court sentenced manuel peuero to mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>iiration naturalization service</td>\n",
       "      <td>cyr</td>\n",
       "      <td>enrico cyr lawful permanent resident pled uilt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>an</td>\n",
       "      <td>weview inruments inc</td>\n",
       "      <td>herbert an owns patent to syem at tracks cloin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   first_party  \\\n",
       "0                                   phil amant   \n",
       "1                                 ephen duncan   \n",
       "2                             billy joe mawood   \n",
       "3                                   linkletter   \n",
       "4                           william earl fikes   \n",
       "...                                        ...   \n",
       "2473  hollyfrontier cheyenne refinin llc et al   \n",
       "2474               rupo mexicano de desarrollo   \n",
       "2475                                    peuero   \n",
       "2476           iiration naturalization service   \n",
       "2477                                        an   \n",
       "\n",
       "                           second_party  \\\n",
       "0                         herman ompson   \n",
       "1                        lawrence owens   \n",
       "2             tony patterson waen et al   \n",
       "3                                walker   \n",
       "4                               alabama   \n",
       "...                                 ...   \n",
       "2473  renewable fuels association et al   \n",
       "2474                 alliance bo fu inc   \n",
       "2475                        united ates   \n",
       "2476                                cyr   \n",
       "2477               weview inruments inc   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     phil amant caidate for public office made tele...                   1  \n",
       "1     ramon nelson was ridin his bike when he suffer...                   0  \n",
       "2     an alabama ate court convicted billy joe mawoo...                   1  \n",
       "3     victor linkletter was convicted in ate court o...                   0  \n",
       "4     in selma alabama an intruder broke into apartm...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  conress ameed clean air act rouh enery policy ...                   1  \n",
       "2474  alliance bo fu inc an invement fu purchased ap...                   1  \n",
       "2475  in dirict court sentenced manuel peuero to mon...                   0  \n",
       "2476  enrico cyr lawful permanent resident pled uilt...                   0  \n",
       "2477  herbert an owns patent to syem at tracks cloin...                   0  \n",
       "\n",
       "[2478 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train['facts'])\n",
    "df = dlc.law_preprocessor(df, 'facts')\n",
    "train['facts'] = df['facts']\n",
    "df = pd.DataFrame(train['first_party'])\n",
    "df = dlc.law_preprocessor(df, 'first_party')\n",
    "train['first_party'] = df['first_party']\n",
    "df = pd.DataFrame(train['second_party'])\n",
    "df = dlc.law_preprocessor(df, 'second_party')\n",
    "train['second_party'] = df['second_party']\n",
    "train_cleansed = train.drop(columns='ID')\n",
    "train_cleansed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42f6a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salerno</td>\n",
       "      <td>united ates</td>\n",
       "      <td>bail reform act allowed federal courts to deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milber weiss bershad hynes lerach</td>\n",
       "      <td>lexecon inc</td>\n",
       "      <td>lexecon inc was defeant in class action lawsui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no title federal counications coission et al</td>\n",
       "      <td>fox television ations inc et al</td>\n",
       "      <td>in fox television ations broadca billboa music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harold kaufman</td>\n",
       "      <td>united ates</td>\n",
       "      <td>durin his trial for armed robbery of federally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berer</td>\n",
       "      <td>hanlon</td>\n",
       "      <td>in mairate jude issued warrant auorizin search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>haitian centers council inc et al</td>\n",
       "      <td>chris sale actin coissioner iiration naturaliz...</td>\n",
       "      <td>accoin to executive oer no sined by president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>whitman</td>\n",
       "      <td>american truckin associations inc</td>\n",
       "      <td>section of clean air act requires environmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>lia matteo john madian</td>\n",
       "      <td>william barr</td>\n",
       "      <td>lia matteo john madian created plan for utiliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>washinton ate apple advertisin coission</td>\n",
       "      <td>hunt</td>\n",
       "      <td>in nor carolina boa of ariculture adopted reul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>eodore ovall</td>\n",
       "      <td>wilfred denno waen</td>\n",
       "      <td>dr paul berheldt was abbed to dea in kitchen o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       first_party  \\\n",
       "0                                          salerno   \n",
       "1                milber weiss bershad hynes lerach   \n",
       "2     no title federal counications coission et al   \n",
       "3                                   harold kaufman   \n",
       "4                                            berer   \n",
       "...                                            ...   \n",
       "1235             haitian centers council inc et al   \n",
       "1236                                       whitman   \n",
       "1237                        lia matteo john madian   \n",
       "1238       washinton ate apple advertisin coission   \n",
       "1239                                  eodore ovall   \n",
       "\n",
       "                                           second_party  \\\n",
       "0                                           united ates   \n",
       "1                                           lexecon inc   \n",
       "2                       fox television ations inc et al   \n",
       "3                                           united ates   \n",
       "4                                                hanlon   \n",
       "...                                                 ...   \n",
       "1235  chris sale actin coissioner iiration naturaliz...   \n",
       "1236                  american truckin associations inc   \n",
       "1237                                       william barr   \n",
       "1238                                               hunt   \n",
       "1239                                 wilfred denno waen   \n",
       "\n",
       "                                                  facts  \n",
       "0     bail reform act allowed federal courts to deta...  \n",
       "1     lexecon inc was defeant in class action lawsui...  \n",
       "2     in fox television ations broadca billboa music...  \n",
       "3     durin his trial for armed robbery of federally...  \n",
       "4     in mairate jude issued warrant auorizin search...  \n",
       "...                                                 ...  \n",
       "1235  accoin to executive oer no sined by president ...  \n",
       "1236  section of clean air act requires environmenta...  \n",
       "1237  lia matteo john madian created plan for utiliz...  \n",
       "1238  in nor carolina boa of ariculture adopted reul...  \n",
       "1239  dr paul berheldt was abbed to dea in kitchen o...  \n",
       "\n",
       "[1240 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test['facts'])\n",
    "df = dlc.law_preprocessor(df, 'facts')\n",
    "test['facts'] = df['facts']\n",
    "df = pd.DataFrame(test['first_party'])\n",
    "df = dlc.law_preprocessor(df, 'first_party')\n",
    "test['first_party'] = df['first_party']\n",
    "df = pd.DataFrame(test['second_party'])\n",
    "df = dlc.law_preprocessor(df, 'second_party')\n",
    "test['second_party'] = df['second_party']\n",
    "test_cleansed = test.drop(columns='ID')\n",
    "test_cleansed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8f896",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "@article{turc2019,\n",
    "  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},\n",
    "  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n",
    "  journal={arXiv preprint arXiv:1908.08962v2 },\n",
    "  year={2019}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_facts = pd.DataFrame(test_cleansed['facts'])\n",
    "train_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fact = pd.DataFrame(test_cleansed['facts'])\n",
    "test_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9d178",
   "metadata": {},
   "source": [
    "model_input_df = dlc.bert_tokenizer(train_facts, 'facts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383af38c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47a66c",
   "metadata": {},
   "source": [
    "df_part_1, df_part_2, df_part_3, df_part_4, df_part_5, df_part_6, df_part_7, df_part_8, df_part_9, df_part_10, df_part_11, df_part_12, df_part_13, df_part_14, df_part_15, df_part_16, df_part_17, df_part_18, df_part_19, df_part_20, df_part_21, df_part_22, df_part_23, df_part_24, df_part_25, df_part_26 = so.df_divider(train_cleansed, 'facts')\n",
    "df_part_1 = pd.DataFrame(df_part_1)\n",
    "df_part_2 = pd.DataFrame(df_part_2)\n",
    "df_part_3 = pd.DataFrame(df_part_3)\n",
    "df_part_4 = pd.DataFrame(df_part_4)\n",
    "df_part_5 = pd.DataFrame(df_part_5)\n",
    "df_part_6 = pd.DataFrame(df_part_6)\n",
    "df_part_7 = pd.DataFrame(df_part_7)\n",
    "df_part_8 = pd.DataFrame(df_part_8)\n",
    "df_part_9 = pd.DataFrame(df_part_9)\n",
    "df_part_10 = pd.DataFrame(df_part_10)\n",
    "df_part_11 = pd.DataFrame(df_part_11)\n",
    "df_part_12 = pd.DataFrame(df_part_12)\n",
    "df_part_13 = pd.DataFrame(df_part_13)\n",
    "df_part_14 = pd.DataFrame(df_part_14)\n",
    "df_part_15 = pd.DataFrame(df_part_15)\n",
    "df_part_16 = pd.DataFrame(df_part_16)\n",
    "df_part_17 = pd.DataFrame(df_part_17)\n",
    "df_part_18 = pd.DataFrame(df_part_18)\n",
    "df_part_19 = pd.DataFrame(df_part_19)\n",
    "df_part_20 = pd.DataFrame(df_part_20)\n",
    "df_part_21 = pd.DataFrame(df_part_21)\n",
    "df_part_22 = pd.DataFrame(df_part_22)\n",
    "df_part_23 = pd.DataFrame(df_part_23)\n",
    "df_part_24 = pd.DataFrame(df_part_24)\n",
    "df_part_25 = pd.DataFrame(df_part_25)\n",
    "df_part_26 = pd.DataFrame(df_part_26)\n",
    "print(df_part_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bf34c",
   "metadata": {},
   "source": [
    "embedded_df_1 = dlc.auto_tokenizer(train_cleansed, 'facts')\n",
    "embedded_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83cfc76",
   "metadata": {},
   "source": [
    "embedded_df_1 = embedded_df_1.rename(columns={0:'facts_berted'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab2385",
   "metadata": {},
   "source": [
    "embedded_df_1.to_csv('./embeddings/facts_embedded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ce9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_berted = dlc.auto_tokenizer(train_cleansed, 'first_party')\n",
    "first_party_berted = first_party_berted.rename(columns={0:'first_party_berted'})\n",
    "first_party_berted.to_csv('./embeddings/first_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_party_berted = dlc.auto_tokenizer(train_cleansed, 'second_party')\n",
    "second_party_berted = second_party_berted.rename(columns={0:'second_party_berted'})\n",
    "second_party_berted.to_csv('./embeddings/second_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_berted = dlc.auto_tokenizer(train_cleansed, 'facts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecee19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_berted = facts_berted.rename(columns={0:'facts_berted'})\n",
    "facts_berted.to_csv('./embeddings/facts_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_berted = pd.read_csv('./embeddings/first_party_berted.csv')\n",
    "second_party_berted = pd.read_csv('./embeddings/second_party_berted.csv')\n",
    "facts_berted = pd.read_csv('./embeddings/facts_berted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715db0c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ready_to_ml = pd.concat([first_party_berted['first_party_berted'], second_party_berted['second_party_berted'], facts_berted['facts_berted'], train_cleansed['first_party_winner']], axis=1)\n",
    "all_ready_to_ml.to_csv('./embeddings/1_train_ready_to_ml.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a083bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first_party_berted = dlc.auto_tokenizer(test_cleansed, 'first_party')\n",
    "test_first_party_berted = test_first_party_berted.rename(columns={0:'first_party_berted'})\n",
    "test_first_party_berted.to_csv('./embeddings/test_first_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_second_party_berted = dlc.auto_tokenizer(test_cleansed, 'second_party')\n",
    "test_second_party_berted = test_second_party_berted.rename(columns={0:'second_party_berted'})\n",
    "test_second_party_berted.to_csv('./embeddings/test_second_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_facts_berted = dlc.auto_tokenizer(test_cleansed, 'facts')\n",
    "test_facts_berted = test_facts_berted.rename(columns={0:'facts_berted'})\n",
    "test_facts_berted.to_csv('./embeddings/test_facts_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a83617",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first_party_berted = pd.read_csv('./embeddings/test_first_party_berted.csv')\n",
    "test_second_party_berted = pd.read_csv('./embeddings/test_second_party_berted.csv')\n",
    "test_facts_berted = pd.read_csv('./embeddings/test_facts_berted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6663ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ready_to_ml = pd.concat([test_first_party_berted['first_party_berted'], test_second_party_berted['second_party_berted'], test_facts_berted['facts_berted']], axis=1)\n",
    "test_ready_to_ml.to_csv('./embeddings/2_test_ready_to_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a7dce",
   "metadata": {},
   "source": [
    "# ì—¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b28ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_ml = pd.read_csv('./embeddings/1_train_ready_to_ml.csv')\n",
    "test_ready_to_ml = pd.read_csv('./embeddings/2_test_ready_to_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78df3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2478/2478 [00:01<00:00, 2194.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2478/2478 [00:01<00:00, 2238.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2478/2478 [00:01<00:00, 2242.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train_to_ml_fp_pr = dlc.tensor_separator(train_to_ml, 'first_party_berted')\n",
    "train_to_ml_sp_pr = dlc.tensor_separator(train_to_ml, 'second_party_berted')\n",
    "train_to_ml_facts_pr = dlc.tensor_separator(train_to_ml, 'facts_berted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2912b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_ml_fp_pr = train_to_ml_fp_pr.astype('float64')\n",
    "train_to_ml_sp_pr = train_to_ml_sp_pr.astype('float64') \n",
    "train_to_ml_facts_pr = train_to_ml_facts_pr.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a99146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Columns: 768 entries, 0 to 767\n",
      "dtypes: float64(768)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_to_ml_fp_pr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e79c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<00:00, 2263.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<00:00, 2265.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<00:00, 2250.22it/s]\n"
     ]
    }
   ],
   "source": [
    "test_to_ml_fp_pr = dlc.tensor_separator(test_ready_to_ml, 'first_party_berted')\n",
    "test_to_ml_sp_pr = dlc.tensor_separator(test_ready_to_ml, 'second_party_berted')\n",
    "test_to_ml_facts_pr = dlc.tensor_separator(test_ready_to_ml, 'facts_berted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728fcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_ml_fp_pr = test_to_ml_fp_pr.astype('float64')\n",
    "test_to_ml_sp_pr = test_to_ml_sp_pr.astype('float64')\n",
    "test_to_ml_facts_pr = test_to_ml_facts_pr.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf161f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_X = pd.concat([train_to_ml_fp_pr, train_to_ml_facts_pr], axis=1)\n",
    "to_be_test_x = pd.concat([test_to_ml_fp_pr, test_to_ml_facts_pr], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e63324c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>-0.012888</td>\n",
       "      <td>-0.007303</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>-0.029552</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018174</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-0.010968</td>\n",
       "      <td>-0.030724</td>\n",
       "      <td>-0.035971</td>\n",
       "      <td>-0.038689</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>-0.010507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003902</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.044628</td>\n",
       "      <td>-0.032344</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>-0.018207</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.016356</td>\n",
       "      <td>-0.039208</td>\n",
       "      <td>-0.031188</td>\n",
       "      <td>-0.014293</td>\n",
       "      <td>-0.026212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>-0.017064</td>\n",
       "      <td>-0.019458</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>-0.030393</td>\n",
       "      <td>-0.020106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011412</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>-0.010546</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.025278</td>\n",
       "      <td>-0.054787</td>\n",
       "      <td>-0.016296</td>\n",
       "      <td>-0.009530</td>\n",
       "      <td>-0.012053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.015234</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>-0.018534</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>-0.030493</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>-0.013273</td>\n",
       "      <td>-0.019490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.005936</td>\n",
       "      <td>-0.003335</td>\n",
       "      <td>-0.026111</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>-0.027738</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011956</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>-0.037784</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>-0.023835</td>\n",
       "      <td>-0.029138</td>\n",
       "      <td>-0.031670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>-0.023639</td>\n",
       "      <td>-0.028438</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>-0.030627</td>\n",
       "      <td>-0.035033</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.024343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>-0.020591</td>\n",
       "      <td>-0.056972</td>\n",
       "      <td>-0.033879</td>\n",
       "      <td>0.031382</td>\n",
       "      <td>0.079985</td>\n",
       "      <td>0.025763</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.060979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027422</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.008214</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.009470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>-0.023678</td>\n",
       "      <td>-0.022937</td>\n",
       "      <td>-0.022214</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.039568</td>\n",
       "      <td>-0.052614</td>\n",
       "      <td>-0.034712</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>-0.004295</td>\n",
       "      <td>-0.029256</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>-0.010641</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>-0.022453</td>\n",
       "      <td>-0.034121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>-0.019696</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.042203</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.023756</td>\n",
       "      <td>-0.004682</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0.021019</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>-0.021894</td>\n",
       "      <td>-0.032928</td>\n",
       "      <td>-0.029230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023799</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>-0.011824</td>\n",
       "      <td>-0.020932</td>\n",
       "      <td>-0.033988</td>\n",
       "      <td>-0.028924</td>\n",
       "      <td>-0.045331</td>\n",
       "      <td>-0.013245</td>\n",
       "      <td>-0.016124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>-0.006356</td>\n",
       "      <td>-0.011619</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>-0.008010</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>-0.016714</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>-0.046451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031149</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>-0.010829</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.037060</td>\n",
       "      <td>-0.035695</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows Ã— 1537 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.005036  0.006439 -0.012888 -0.007303 -0.017571 -0.029552 -0.006318   \n",
       "1    -0.003902  0.026781 -0.044628 -0.032344 -0.001729 -0.018735  0.002111   \n",
       "2     0.003050  0.009259 -0.017064 -0.019458 -0.006200 -0.008553  0.050010   \n",
       "3    -0.015234 -0.000875  0.015897 -0.018534  0.054608 -0.030493  0.041842   \n",
       "4    -0.011956 -0.009987  0.020198  0.009508  0.024592 -0.037784  0.020635   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2473 -0.020591 -0.056972 -0.033879  0.031382  0.079985  0.025763 -0.006569   \n",
       "2474 -0.023678 -0.022937 -0.022214  0.013166  0.054840  0.011287  0.016339   \n",
       "2475 -0.004295 -0.029256 -0.015316 -0.010641  0.007141  0.021234  0.005180   \n",
       "2476  0.021019 -0.003120 -0.007031  0.007962  0.045658  0.014659  0.024269   \n",
       "2477 -0.006356 -0.011619 -0.007439 -0.012634 -0.008010 -0.005947  0.032153   \n",
       "\n",
       "             7         8         9  ...      1527      1528      1529  \\\n",
       "0     0.025047 -0.009394 -0.015124  ... -0.018174  0.001737  0.003518   \n",
       "1    -0.018207 -0.009919 -0.075807  ... -0.010969  0.006232 -0.012417   \n",
       "2     0.035903 -0.030393 -0.020106  ... -0.011412 -0.006155 -0.010546   \n",
       "3     0.057857 -0.013273 -0.019490  ... -0.019637 -0.005936 -0.003335   \n",
       "4    -0.023835 -0.029138 -0.031670  ... -0.033741  0.007560 -0.023639   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2473  0.044251 -0.008797 -0.060979  ... -0.027422  0.000112  0.015122   \n",
       "2474  0.090016  0.000314  0.001474  ... -0.017667  0.015822 -0.002527   \n",
       "2475  0.064935 -0.022453 -0.034121  ... -0.011819  0.019265 -0.019696   \n",
       "2476 -0.021894 -0.032928 -0.029230  ... -0.023799  0.002132 -0.011824   \n",
       "2477 -0.016714  0.039917 -0.046451  ... -0.031149 -0.003120  0.002196   \n",
       "\n",
       "          1530      1531      1532      1533      1534      1535  \\\n",
       "0    -0.010968 -0.030724 -0.035971 -0.038689 -0.006275 -0.010507   \n",
       "1    -0.020754 -0.016356 -0.039208 -0.031188 -0.014293 -0.026212   \n",
       "2    -0.024606 -0.025278 -0.054787 -0.016296 -0.009530 -0.012053   \n",
       "3    -0.026111 -0.015403  0.000960 -0.027738  0.005133 -0.012935   \n",
       "4    -0.028438 -0.010833 -0.030627 -0.035033 -0.000732 -0.024343   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "2473  0.009355 -0.046905 -0.002683 -0.008214 -0.000282 -0.009470   \n",
       "2474  0.004892 -0.039568 -0.052614 -0.034712 -0.004466  0.008349   \n",
       "2475 -0.024496 -0.042203 -0.044682 -0.023756 -0.004682  0.003538   \n",
       "2476 -0.020932 -0.033988 -0.028924 -0.045331 -0.013245 -0.016124   \n",
       "2477 -0.010829 -0.016647 -0.037060 -0.035695 -0.007506  0.002923   \n",
       "\n",
       "      first_party_winner  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "2473                   1  \n",
       "2474                   1  \n",
       "2475                   0  \n",
       "2476                   0  \n",
       "2477                   0  \n",
       "\n",
       "[2478 rows x 1537 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_X.columns = np.arange(len(to_be_X.columns))\n",
    "to_be_X = pd.concat([to_be_X, train_to_ml['first_party_winner']], axis =1)\n",
    "to_be_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e13631f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1526</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.080011</td>\n",
       "      <td>-0.014580</td>\n",
       "      <td>-0.038840</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>-0.040639</td>\n",
       "      <td>0.039663</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.029425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012600</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.034796</td>\n",
       "      <td>-0.020804</td>\n",
       "      <td>-0.006913</td>\n",
       "      <td>-0.038063</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>-0.021999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003053</td>\n",
       "      <td>-0.011769</td>\n",
       "      <td>-0.034803</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-0.026498</td>\n",
       "      <td>-0.014561</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>-0.009658</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018383</td>\n",
       "      <td>-0.027521</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.049594</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025638</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.021478</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>-0.036683</td>\n",
       "      <td>-0.034054</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>-0.017806</td>\n",
       "      <td>-0.045973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023804</td>\n",
       "      <td>-0.017397</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.014011</td>\n",
       "      <td>-0.041264</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>-0.012293</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.010219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028991</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>-0.059128</td>\n",
       "      <td>-0.030722</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.028222</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>-0.009327</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>-0.008745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021711</td>\n",
       "      <td>-0.015069</td>\n",
       "      <td>-0.001111</td>\n",
       "      <td>-0.014473</td>\n",
       "      <td>-0.025876</td>\n",
       "      <td>-0.006428</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.028281</td>\n",
       "      <td>-0.004001</td>\n",
       "      <td>-0.012030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036941</td>\n",
       "      <td>-0.039247</td>\n",
       "      <td>-0.026675</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>-0.016113</td>\n",
       "      <td>0.046348</td>\n",
       "      <td>-0.012971</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>-0.051456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016862</td>\n",
       "      <td>-0.034918</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.037341</td>\n",
       "      <td>-0.040531</td>\n",
       "      <td>-0.014745</td>\n",
       "      <td>-0.042890</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.010147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>-0.017606</td>\n",
       "      <td>-0.026507</td>\n",
       "      <td>-0.038503</td>\n",
       "      <td>-0.013017</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>-0.006750</td>\n",
       "      <td>-0.023582</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.024067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010572</td>\n",
       "      <td>-0.034447</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>-0.046846</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>-0.034175</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>0.006327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-0.001220</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>-0.023937</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>0.076602</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>-0.012813</td>\n",
       "      <td>-0.014318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>-0.030309</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.053392</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.014506</td>\n",
       "      <td>-0.011636</td>\n",
       "      <td>0.024630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>0.063505</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>-0.032935</td>\n",
       "      <td>-0.016052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018592</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.015415</td>\n",
       "      <td>-0.033917</td>\n",
       "      <td>-0.057270</td>\n",
       "      <td>-0.028927</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.001634</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>-0.014695</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>-0.025222</td>\n",
       "      <td>0.065449</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>-0.006307</td>\n",
       "      <td>-0.005089</td>\n",
       "      <td>-0.044533</td>\n",
       "      <td>-0.016824</td>\n",
       "      <td>-0.018459</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.058938</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.051615</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>-0.019234</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027754</td>\n",
       "      <td>-0.020528</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>-0.013797</td>\n",
       "      <td>-0.022734</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>-0.025505</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>-0.011266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0    -0.006672 -0.080011 -0.014580 -0.038840  0.048455 -0.040639  0.039663   \n",
       "1    -0.003053 -0.011769 -0.034803 -0.041324 -0.026498 -0.014561  0.012917   \n",
       "2    -0.025638 -0.016005 -0.021478  0.014413  0.048054 -0.036683 -0.034054   \n",
       "3     0.028991  0.036599 -0.059128 -0.030722 -0.017587 -0.028222  0.052064   \n",
       "4     0.036941 -0.039247 -0.026675 -0.006587 -0.022472 -0.016113  0.046348   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1235 -0.017606 -0.026507 -0.038503 -0.013017  0.036128 -0.006750 -0.023582   \n",
       "1236 -0.001220 -0.002364 -0.025906 -0.023937  0.002847 -0.021732  0.076602   \n",
       "1237  0.001026  0.023440  0.013377  0.016586  0.024960 -0.001395  0.063505   \n",
       "1238  0.001634 -0.000814 -0.014695  0.003300  0.001420  0.028769 -0.025222   \n",
       "1239 -0.058938  0.010668  0.004917 -0.051615  0.033669  0.037903  0.019593   \n",
       "\n",
       "          7         8         9     ...      1526      1527      1528  \\\n",
       "0     0.068547  0.002239 -0.029425  ... -0.012600 -0.023597 -0.003138   \n",
       "1    -0.009658 -0.000563 -0.018914  ... -0.018383 -0.027521  0.004810   \n",
       "2     0.043429 -0.017806 -0.045973  ... -0.023804 -0.017397  0.008190   \n",
       "3    -0.009327  0.006705 -0.008745  ... -0.021711 -0.015069 -0.001111   \n",
       "4    -0.012971  0.029547 -0.051456  ... -0.016862 -0.034918  0.005033   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1235  0.004234 -0.010011 -0.024067  ... -0.010572 -0.034447 -0.002972   \n",
       "1236 -0.014772 -0.012813 -0.014318  ... -0.000953 -0.013990  0.002872   \n",
       "1237 -0.017101 -0.032935 -0.016052  ... -0.018592 -0.016234  0.018842   \n",
       "1238  0.065449 -0.011581 -0.044858  ...  0.004752  0.003640  0.013376   \n",
       "1239  0.016298 -0.019234 -0.045782  ... -0.027754 -0.020528  0.022163   \n",
       "\n",
       "          1529      1530      1531      1532      1533      1534      1535  \n",
       "0    -0.008353 -0.034796 -0.020804 -0.006913 -0.038063  0.008657 -0.021999  \n",
       "1    -0.006279 -0.019910 -0.044318 -0.049594 -0.022413  0.012250  0.003738  \n",
       "2    -0.010989 -0.014011 -0.041264 -0.009615 -0.012293 -0.000732  0.010219  \n",
       "3    -0.014473 -0.025876 -0.006428 -0.018803 -0.028281 -0.004001 -0.012030  \n",
       "4     0.000040 -0.037341 -0.040531 -0.014745 -0.042890 -0.000467 -0.010147  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1235 -0.012302 -0.004949 -0.046846 -0.039191 -0.034175 -0.013973  0.006327  \n",
       "1236 -0.030309 -0.013520 -0.053392 -0.012986 -0.014506 -0.011636  0.024630  \n",
       "1237 -0.002355 -0.015415 -0.033917 -0.057270 -0.028927 -0.005387  0.000249  \n",
       "1238 -0.006307 -0.005089 -0.044533 -0.016824 -0.018459 -0.004400  0.022938  \n",
       "1239 -0.013797 -0.022734 -0.028132 -0.043650 -0.025505 -0.002197 -0.011266  \n",
       "\n",
       "[1240 rows x 1536 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_test_x.columns = np.arange(len(to_be_test_x.columns))\n",
    "to_be_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672d6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = to_be_X.drop(columns='first_party_winner')\n",
    "y = pd.DataFrame(to_be_X['first_party_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e2fcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = to_be_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0114d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Columns: 1536 entries, 0 to 1535\n",
      "dtypes: float64(1536)\n",
      "memory usage: 29.0 MB\n",
      "\n",
      " --------------------------------------- \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 1 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   first_party_winner  2478 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 19.5 KB\n",
      "\n",
      " --------------------------------------- \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1240 entries, 0 to 1239\n",
      "Columns: 1536 entries, 0 to 1535\n",
      "dtypes: float64(1536)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "\n",
    "print('\\n --------------------------------------- \\n')\n",
    "\n",
    "y.info()\n",
    "\n",
    "print('\\n --------------------------------------- \\n')\n",
    "\n",
    "test_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcb14756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1734, 1536) (744, 1536) (1734, 1) (744, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7502f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'error',\n",
    "        'booster': 'gbtree',\n",
    "        'nthread': trial.suggest_int('nthread', 1, 15),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 25, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 0.3),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.7),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 0.2, 200),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 3)\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    xgb_model = xgb(**xgb_params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, xgb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    lgb_params = {\n",
    "        'application': 'binary',\n",
    "        'max_depth': -1,\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt',  'dart']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 2000),\n",
    "        'lambda' : trial.suggest_float('lambda', 0.01, 0.5),\n",
    "        'num_iteration': 500,\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.1),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.7, 0.9),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 0.8),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_preds = lgb_model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, lgb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "    params = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'learning_rate': learning_rate,\n",
    "            'depth': trial.suggest_int('depth', 3, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "\n",
    "    model = cat.CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da54b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selector(trial):\n",
    "    model_type = trial.suggest_categorical('model_type', ['xgb', 'lgbm'])\n",
    "    random_state = 42\n",
    "\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        eval_metric = 'error'\n",
    "        objective = 'binary:logistic'\n",
    "        tree_method = trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\n",
    "\n",
    "        if tree_method == 'exact':\n",
    "            sampling_method = 'uniform'\n",
    "            subsample = 0.5\n",
    "            booster = trial.suggest_categorical('booster', ['dart', 'gbtree'])\n",
    "            if booster == 'gbtree':\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 300)\n",
    "                n_estimators = trial.suggest_int('n_estimators', 1, 1000)\n",
    "                if n_estimators < 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.3, 0.9)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                                1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  500)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 500,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif n_estimators > 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 0.7)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                            1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  500)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 500,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif booster == 'dart':\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 300)\n",
    "                colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.5, 0.9)\n",
    "                learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                            1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                if learning_rate in [1e-4, 5e-4]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.01, 0.5)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        rate_drop=rate_drop,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.3, 0.7)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        rate_drop=rate_drop,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif learning_rate in [5e-2, 1e-1]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.5, 1.0)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        rate_drop=rate_drop,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "            # elif booster == 'gblinear':\n",
    "            #     learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "            #                                                                 1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            #     if learning_rate in [1e-4, 5e-4]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             subsample=subsample,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             subsample=subsample,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [5e-2, 1e-1]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             subsample=subsample,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "\n",
    "        else:\n",
    "            sampling_method = 'uniform'\n",
    "            booster = trial.suggest_categorical('booster', ['dart', 'gbtree'])\n",
    "            if booster == 'gbtree':\n",
    "                subsample = trial.suggest_loguniform('subsample', 0.1, 0.5)\n",
    "                max_depth = 0\n",
    "                n_estimators = trial.suggest_int('n_estimators', 1, 1000)\n",
    "                if n_estimators < 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.3, 0.9)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                                1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  400)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 400,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif n_estimators > 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 0.7)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                                1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  400)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 400,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif booster == 'dart':\n",
    "                subsample = 0.5\n",
    "                max_depth = 0\n",
    "                colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.5, 0.9)\n",
    "                learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                            1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                if learning_rate in [1e-4, 5e-4]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.01, 0.5)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        rate_drop=rate_drop,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "\n",
    "                elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.3, 0.7)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        rate_drop=rate_drop,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif learning_rate in [5e-2, 1e-1]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.5, 1.0)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        rate_drop=rate_drop,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "\n",
    "            # elif booster == 'gblinear':\n",
    "            #     learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "            #                                                                 1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            #     if learning_rate in [1e-4, 5e-4]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [5e-2, 1e-1]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "\n",
    "    elif model_type == 'lgbm':\n",
    "        objective = 'binary'\n",
    "        metric = 'accuracy'\n",
    "        num_threads = 0\n",
    "        max_depth = -1\n",
    "\n",
    "        num_leaves = trial.suggest_int('num_leaves', 1, 1000)\n",
    "        boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'rf', 'goss'])\n",
    "        if boosting_type == 'gbdt':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1, 500)\n",
    "            learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                        1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            if learning_rate in [1e-4, 5e-4]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 20)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.5, 0.999)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.3, 0.7)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.3, 0.7)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [5e-2, 1e-1]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.1, 0.5)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.1, 0.5)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "        elif boosting_type == 'dart':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1, 500)\n",
    "            learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                        1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            if learning_rate in [1e-4, 5e-4]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 20)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.5, 0.999)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                drop_rate = trial.suggest_loguniform('drop_rate', 0.01, 0.5)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    n_estimators=n_estimators,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    drop_rate=drop_rate,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.3, 0.7)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.3, 0.7)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                drop_rate = trial.suggest_loguniform('drop_rate', 0.3, 0.7)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    n_estimators=n_estimators,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    drop_rate=drop_rate,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [5e-2, 1e-1]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.5, 0.999)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                drop_rate = trial.suggest_loguniform('drop_rate', 0.5, 1)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    n_estimators=n_estimators,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    drop_rate=drop_rate,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "        elif boosting_type == 'rf':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1, 500)\n",
    "            feature_fraction_bynode = trial.suggest_loguniform('feature_fraction_bynode', 0.01, 0.999)\n",
    "            if feature_fraction_bynode < 0.33:\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 0, 20)\n",
    "                alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    feature_fraction_bynode=feature_fraction_bynode,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif feature_fraction_bynode > 0.33 and feature_fraction_bynode < 0.66:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    feature_fraction_bynode=feature_fraction_bynode,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif feature_fraction_bynode > 0.66:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "                alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    feature_fraction_bynode=feature_fraction_bynode,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "        elif boosting_type == 'goss':\n",
    "            learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                        1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            if learning_rate in [1e-4, 5e-4]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 0, 20)\n",
    "                top_rate = trial.suggest_loguniform('top_rate', 0.01, 0.5)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    top_rate=top_rate,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                top_rate = trial.suggest_loguniform('top_rate', 0.3, 0.7)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    top_rate=top_rate,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [5e-2, 1e-1]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 2, 40)\n",
    "                top_rate = trial.suggest_loguniform('top_rate', 0.5, 1)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    top_rate=top_rate,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb032a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5616c643",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 00:51:48,492] A new study created in memory with name: no-name-6167e393-844a-477d-9d3a-3005d9e1789d\n",
      "[I 2023-06-11 00:51:56,338] Trial 0 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'dart', 'max_depth': 263, 'colsample_bytree': 0.8059089894710296, 'learning_rate': 0.001, 'rate_drop': 0.4043741811984639, 'min_child_weight': 14}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:51:57,648] Trial 1 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 179, 'n_estimators': 1000, 'colsample_bytree': 0.11164384196813276, 'learning_rate': 0.0001, 'min_split_loss': 0.8563844446909422, 'min_child_weight': 6, 'alpha': 8.37748253772845, 'reg_lambda': 0.22518816570571035}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:52:02,575] Trial 2 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 924, 'boosting_type': 'gbdt', 'n_estimators': 43, 'learning_rate': 0.0001, 'min_data_in_leaf': 1, 'feature_fraction': 0.7149205558471139, 'bagging_fraction': 0.9452491159352443, 'bagging_freq': 19, 'alpha': 3.7028882692116136, 'reg_lambda': 11.082671113504459}. Best is trial 0 with value: 0.6706989247311828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7241678290057527, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7241678290057527\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9727523265295095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9727523265295095\n",
      "[LightGBM] [Warning] bagging_freq is set=124, subsample_freq=0 will be ignored. Current value: bagging_freq=124\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 00:52:19,440] Trial 3 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 471, 'boosting_type': 'gbdt', 'n_estimators': 206, 'learning_rate': 0.0001, 'min_data_in_leaf': 5, 'feature_fraction': 0.9727523265295095, 'bagging_fraction': 0.7241678290057527, 'bagging_freq': 124, 'alpha': 0.32438200179700016, 'reg_lambda': 0.16497626968240706}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:52:20,394] Trial 4 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 100, 'n_estimators': 452, 'colsample_bytree': 0.31088182483935856, 'learning_rate': 0.1, 'min_split_loss': 828.8900189926477, 'min_child_weight': 35, 'alpha': 24.68870410252334, 'reg_lambda': 33.733708694042015}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:52:33,259] Trial 5 finished with value: 0.6720430107526881 and parameters: {'model_type': 'xgb', 'tree_method': 'approx', 'booster': 'dart', 'colsample_bytree': 0.6574186430900815, 'learning_rate': 0.01, 'rate_drop': 0.5304679787112068, 'min_child_weight': 16}. Best is trial 0 with value: 0.6706989247311828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7349302754240067, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7349302754240067\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5873937514297226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5873937514297226\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 00:52:37,884] Trial 6 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 726, 'boosting_type': 'gbdt', 'n_estimators': 233, 'learning_rate': 0.0005, 'min_data_in_leaf': 15, 'feature_fraction': 0.5873937514297226, 'bagging_fraction': 0.7349302754240067, 'bagging_freq': 6, 'alpha': 1.9999245782619597, 'reg_lambda': 9.427412161640394}. Best is trial 0 with value: 0.6706989247311828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 00:52:39,179] Trial 7 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 14, 'boosting_type': 'goss', 'learning_rate': 0.05, 'min_data_in_leaf': 27, 'top_rate': 0.6777033787779705}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:52:43,964] Trial 8 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'approx', 'booster': 'gbtree', 'subsample': 0.17887977468152194, 'n_estimators': 375, 'colsample_bytree': 0.8781597429975883, 'learning_rate': 0.01, 'min_split_loss': 209.17102288024088, 'min_child_weight': 29, 'alpha': 16.42347191521074, 'reg_lambda': 13.773634291715283}. Best is trial 0 with value: 0.6706989247311828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5470395491438352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5470395491438352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.627855643025993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.627855643025993\n",
      "[LightGBM] [Warning] bagging_freq is set=29, subsample_freq=0 will be ignored. Current value: bagging_freq=29\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 00:52:45,528] Trial 9 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 629, 'boosting_type': 'gbdt', 'n_estimators': 49, 'learning_rate': 0.0005, 'min_data_in_leaf': 18, 'feature_fraction': 0.627855643025993, 'bagging_fraction': 0.5470395491438352, 'bagging_freq': 29, 'alpha': 17.19962006606325, 'reg_lambda': 0.061818914818402744}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:53:28,067] Trial 10 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8705478049486228, 'learning_rate': 0.001, 'rate_drop': 0.3271401908529181, 'min_child_weight': 15}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:53:29,140] Trial 11 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 276, 'n_estimators': 929, 'colsample_bytree': 0.10501489195063297, 'learning_rate': 0.005, 'min_split_loss': 200.9189984405461, 'min_child_weight': 10, 'alpha': 25.416289302013976, 'reg_lambda': 16.758654766187917}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:53:36,333] Trial 12 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'dart', 'max_depth': 255, 'colsample_bytree': 0.5194253337957025, 'learning_rate': 0.001, 'rate_drop': 0.40144552634467034, 'min_child_weight': 11}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:53:37,144] Trial 13 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 188, 'n_estimators': 975, 'colsample_bytree': 0.12411770533034559, 'learning_rate': 0.001, 'min_split_loss': 200.91610024207782, 'min_child_weight': 20, 'alpha': 21.078526282585443, 'reg_lambda': 12.356429714893471}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:53:48,627] Trial 14 finished with value: 0.6733870967741935 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'dart', 'max_depth': 13, 'colsample_bytree': 0.5627364416858132, 'learning_rate': 0.0001, 'rate_drop': 0.02154518579982953, 'min_child_weight': 1}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 00:54:11,638] Trial 15 finished with value: 0.6693548387096774 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.5318932472053339, 'learning_rate': 0.005, 'rate_drop': 0.659901114770269, 'min_child_weight': 10}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:54:33,122] Trial 16 finished with value: 0.6720430107526881 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.7948341839734506, 'learning_rate': 0.005, 'rate_drop': 0.6755959268529141, 'min_child_weight': 16}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:54:52,655] Trial 17 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.760867831343503, 'learning_rate': 0.005, 'rate_drop': 0.6990764971939499, 'min_child_weight': 21}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:54:56,554] Trial 18 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.7746271696954766, 'learning_rate': 0.05, 'rate_drop': 0.9672306877826444, 'min_child_weight': 40}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:54:58,833] Trial 19 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.7098408000308463, 'learning_rate': 0.1, 'rate_drop': 0.9986329842191829, 'min_child_weight': 27}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:55:13,201] Trial 20 finished with value: 0.6720430107526881 and parameters: {'model_type': 'xgb', 'tree_method': 'approx', 'booster': 'dart', 'colsample_bytree': 0.8837106042271221, 'learning_rate': 0.005, 'rate_drop': 0.4551372376572802, 'min_child_weight': 13}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:55:15,729] Trial 21 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 166, 'n_estimators': 723, 'colsample_bytree': 0.4495619191023739, 'learning_rate': 0.0001, 'min_split_loss': 0.22057044598357634, 'min_child_weight': 6, 'alpha': 0.10509559035917573, 'reg_lambda': 0.012925088669581477}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:55:16,924] Trial 22 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 213, 'n_estimators': 719, 'colsample_bytree': 0.17157495050104704, 'learning_rate': 0.001, 'min_split_loss': 200.3278259287502, 'min_child_weight': 10, 'alpha': 29.557280325125983, 'reg_lambda': 21.248212187393232}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:55:18,964] Trial 23 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'gbtree', 'max_depth': 110, 'n_estimators': 704, 'colsample_bytree': 0.4068603913230254, 'learning_rate': 0.001, 'min_split_loss': 202.41355932954423, 'min_child_weight': 12, 'alpha': 19.855809216559404, 'reg_lambda': 19.940658433752393}. Best is trial 15 with value: 0.6693548387096774.\n",
      "[I 2023-06-11 00:55:53,430] Trial 24 finished with value: 0.6653225806451613 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8241689071282805, 'learning_rate': 0.005, 'rate_drop': 0.4715292099333671, 'min_child_weight': 10}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:56:28,056] Trial 25 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8282094097472974, 'learning_rate': 0.005, 'rate_drop': 0.44674214250571365, 'min_child_weight': 19}. Best is trial 24 with value: 0.6653225806451613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.975197230075201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.975197230075201\n",
      "[LightGBM] [Warning] bagging_freq is set=138, subsample_freq=0 will be ignored. Current value: bagging_freq=138\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 00:56:38,183] Trial 26 finished with value: 0.6720430107526881 and parameters: {'model_type': 'lgbm', 'num_leaves': 123, 'boosting_type': 'rf', 'n_estimators': 148, 'feature_fraction_bynode': 0.06419754172177068, 'bagging_fraction': 0.975197230075201, 'bagging_freq': 138, 'min_data_in_leaf': 10, 'alpha': 0.6951906269921745, 'reg_lambda': 1.8289784011070733}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:57:09,600] Trial 27 finished with value: 0.6693548387096774 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8268089152294197, 'learning_rate': 0.005, 'rate_drop': 0.5187079244635366, 'min_child_weight': 14}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:57:41,566] Trial 28 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8249006788126586, 'learning_rate': 0.005, 'rate_drop': 0.5321833697900555, 'min_child_weight': 17}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:58:12,774] Trial 29 finished with value: 0.668010752688172 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8927562124428889, 'learning_rate': 0.005, 'rate_drop': 0.5237490308097102, 'min_child_weight': 13}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:58:42,169] Trial 30 finished with value: 0.6666666666666666 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8593378955593176, 'learning_rate': 0.005, 'rate_drop': 0.5631804478373452, 'min_child_weight': 12}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:59:10,163] Trial 31 finished with value: 0.6653225806451613 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8763613555456808, 'learning_rate': 0.005, 'rate_drop': 0.5833701748204957, 'min_child_weight': 12}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 00:59:39,678] Trial 32 finished with value: 0.668010752688172 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8886236660928291, 'learning_rate': 0.005, 'rate_drop': 0.5614318162919388, 'min_child_weight': 12}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 01:00:07,544] Trial 33 finished with value: 0.6693548387096774 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8543190286412277, 'learning_rate': 0.005, 'rate_drop': 0.5814840472920147, 'min_child_weight': 13}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 01:00:40,297] Trial 34 finished with value: 0.6666666666666666 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8618387378832184, 'learning_rate': 0.005, 'rate_drop': 0.5016696167454873, 'min_child_weight': 12}. Best is trial 24 with value: 0.6653225806451613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=78, subsample_freq=0 will be ignored. Current value: bagging_freq=78\n",
      "[LightGBM] [Warning] feature_fraction is set=0.36924235965208957, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.36924235965208957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.31933048561074984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31933048561074984\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:00:41,524] Trial 35 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 313, 'boosting_type': 'dart', 'n_estimators': 111, 'learning_rate': 0.005, 'min_data_in_leaf': 29, 'feature_fraction': 0.36924235965208957, 'bagging_fraction': 0.31933048561074984, 'bagging_freq': 78, 'drop_rate': 0.30898685255137}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 01:00:56,707] Trial 36 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8520531289521815, 'learning_rate': 0.1, 'rate_drop': 0.7789408202354922, 'min_child_weight': 23}. Best is trial 24 with value: 0.6653225806451613.\n",
      "[I 2023-06-11 01:01:29,357] Trial 37 finished with value: 0.6693548387096774 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.8990019740376692, 'learning_rate': 0.01, 'rate_drop': 0.49301568379747057, 'min_child_weight': 15}. Best is trial 24 with value: 0.6653225806451613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8800424410616345, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8800424410616345\n",
      "[LightGBM] [Warning] bagging_freq is set=301, subsample_freq=0 will be ignored. Current value: bagging_freq=301\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:01:34,321] Trial 38 finished with value: 0.6330645161290323 and parameters: {'model_type': 'lgbm', 'num_leaves': 988, 'boosting_type': 'rf', 'n_estimators': 310, 'feature_fraction_bynode': 0.9676796954464125, 'min_data_in_leaf': 39, 'alpha': 39.19935644027287, 'reg_lambda': 36.9924396459861, 'bagging_fraction': 0.8800424410616345, 'bagging_freq': 301}. Best is trial 38 with value: 0.6330645161290323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8743318067286545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8743318067286545\n",
      "[LightGBM] [Warning] bagging_freq is set=309, subsample_freq=0 will be ignored. Current value: bagging_freq=309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:01:38,955] Trial 39 finished with value: 0.668010752688172 and parameters: {'model_type': 'lgbm', 'num_leaves': 993, 'boosting_type': 'rf', 'n_estimators': 310, 'feature_fraction_bynode': 0.8696008537461871, 'min_data_in_leaf': 40, 'alpha': 39.48456896482533, 'reg_lambda': 39.13317855819859, 'bagging_fraction': 0.8743318067286545, 'bagging_freq': 309}. Best is trial 38 with value: 0.6330645161290323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8543219075875358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8543219075875358\n",
      "[LightGBM] [Warning] bagging_freq is set=285, subsample_freq=0 will be ignored. Current value: bagging_freq=285\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:01:43,337] Trial 40 finished with value: 0.6599462365591398 and parameters: {'model_type': 'lgbm', 'num_leaves': 803, 'boosting_type': 'rf', 'n_estimators': 305, 'feature_fraction_bynode': 0.9191058166035451, 'min_data_in_leaf': 40, 'alpha': 39.07157814201049, 'reg_lambda': 38.75233849840901, 'bagging_fraction': 0.8543219075875358, 'bagging_freq': 285}. Best is trial 38 with value: 0.6330645161290323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8328575507351669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8328575507351669\n",
      "[LightGBM] [Warning] bagging_freq is set=290, subsample_freq=0 will be ignored. Current value: bagging_freq=290\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:01:48,215] Trial 41 finished with value: 0.6586021505376344 and parameters: {'model_type': 'lgbm', 'num_leaves': 800, 'boosting_type': 'rf', 'n_estimators': 308, 'feature_fraction_bynode': 0.9953419546011284, 'min_data_in_leaf': 40, 'alpha': 39.61532596294115, 'reg_lambda': 39.50299015097139, 'bagging_fraction': 0.8328575507351669, 'bagging_freq': 290}. Best is trial 38 with value: 0.6330645161290323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8486045427082904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8486045427082904\n",
      "[LightGBM] [Warning] bagging_freq is set=296, subsample_freq=0 will be ignored. Current value: bagging_freq=296\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:01:53,514] Trial 42 finished with value: 0.6693548387096774 and parameters: {'model_type': 'lgbm', 'num_leaves': 769, 'boosting_type': 'rf', 'n_estimators': 305, 'feature_fraction_bynode': 0.8932273247354616, 'min_data_in_leaf': 40, 'alpha': 39.08772417366275, 'reg_lambda': 39.79351296688962, 'bagging_fraction': 0.8486045427082904, 'bagging_freq': 296}. Best is trial 38 with value: 0.6330645161290323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.856294787704204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.856294787704204\n",
      "[LightGBM] [Warning] bagging_freq is set=236, subsample_freq=0 will be ignored. Current value: bagging_freq=236\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:01:58,259] Trial 43 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 855, 'boosting_type': 'rf', 'n_estimators': 309, 'feature_fraction_bynode': 0.8884227975325588, 'min_data_in_leaf': 36, 'alpha': 38.05058053623754, 'reg_lambda': 36.962351623732616, 'bagging_fraction': 0.856294787704204, 'bagging_freq': 236}. Best is trial 38 with value: 0.6330645161290323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8202101827173186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8202101827173186\n",
      "[LightGBM] [Warning] bagging_freq is set=358, subsample_freq=0 will be ignored. Current value: bagging_freq=358\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:03,562] Trial 44 finished with value: 0.6048387096774194 and parameters: {'model_type': 'lgbm', 'num_leaves': 624, 'boosting_type': 'rf', 'n_estimators': 369, 'feature_fraction_bynode': 0.9918816210292678, 'min_data_in_leaf': 36, 'alpha': 36.86553886301719, 'reg_lambda': 36.63410100650133, 'bagging_fraction': 0.8202101827173186, 'bagging_freq': 358}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8222531681000302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8222531681000302\n",
      "[LightGBM] [Warning] bagging_freq is set=354, subsample_freq=0 will be ignored. Current value: bagging_freq=354\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:09,010] Trial 45 finished with value: 0.6048387096774194 and parameters: {'model_type': 'lgbm', 'num_leaves': 626, 'boosting_type': 'rf', 'n_estimators': 355, 'feature_fraction_bynode': 0.9870351154104469, 'min_data_in_leaf': 36, 'alpha': 37.3485310763156, 'reg_lambda': 36.42887521332199, 'bagging_fraction': 0.8222531681000302, 'bagging_freq': 354}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8324862935931895, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8324862935931895\n",
      "[LightGBM] [Warning] bagging_freq is set=368, subsample_freq=0 will be ignored. Current value: bagging_freq=368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:13,962] Trial 46 finished with value: 0.668010752688172 and parameters: {'model_type': 'lgbm', 'num_leaves': 609, 'boosting_type': 'rf', 'n_estimators': 368, 'feature_fraction_bynode': 0.8668934789458763, 'min_data_in_leaf': 37, 'alpha': 37.420048740794094, 'reg_lambda': 36.39250007870722, 'bagging_fraction': 0.8324862935931895, 'bagging_freq': 368}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8141931109307485, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8141931109307485\n",
      "[LightGBM] [Warning] bagging_freq is set=352, subsample_freq=0 will be ignored. Current value: bagging_freq=352\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:19,290] Trial 47 finished with value: 0.6559139784946236 and parameters: {'model_type': 'lgbm', 'num_leaves': 766, 'boosting_type': 'rf', 'n_estimators': 368, 'feature_fraction_bynode': 0.894041614356387, 'min_data_in_leaf': 36, 'alpha': 39.84970077926227, 'reg_lambda': 36.89222032836953, 'bagging_fraction': 0.8141931109307485, 'bagging_freq': 352}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.79875820932899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79875820932899\n",
      "[LightGBM] [Warning] bagging_freq is set=373, subsample_freq=0 will be ignored. Current value: bagging_freq=373\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:25,054] Trial 48 finished with value: 0.6411290322580645 and parameters: {'model_type': 'lgbm', 'num_leaves': 615, 'boosting_type': 'rf', 'n_estimators': 373, 'feature_fraction_bynode': 0.930498338433161, 'min_data_in_leaf': 36, 'alpha': 36.61453666982221, 'reg_lambda': 35.968312850412424, 'bagging_fraction': 0.79875820932899, 'bagging_freq': 373}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7686976684136142, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7686976684136142\n",
      "[LightGBM] [Warning] bagging_freq is set=381, subsample_freq=0 will be ignored. Current value: bagging_freq=381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:35,261] Trial 49 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 547, 'boosting_type': 'rf', 'n_estimators': 390, 'feature_fraction_bynode': 0.300211517113209, 'bagging_fraction': 0.7686976684136142, 'bagging_freq': 381, 'min_data_in_leaf': 19, 'alpha': 11.730726840138958, 'reg_lambda': 6.04149359355762}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7901774703826144, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901774703826144\n",
      "[LightGBM] [Warning] bagging_freq is set=407, subsample_freq=0 will be ignored. Current value: bagging_freq=407\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:46,766] Trial 50 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 659, 'boosting_type': 'rf', 'n_estimators': 417, 'feature_fraction_bynode': 0.019789592556753208, 'bagging_fraction': 0.7901774703826144, 'bagging_freq': 407, 'min_data_in_leaf': 20, 'alpha': 11.187177013520822, 'reg_lambda': 6.218377329124805}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8068734915428245, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8068734915428245\n",
      "[LightGBM] [Warning] bagging_freq is set=318, subsample_freq=0 will be ignored. Current value: bagging_freq=318\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:51,700] Trial 51 finished with value: 0.6612903225806451 and parameters: {'model_type': 'lgbm', 'num_leaves': 465, 'boosting_type': 'rf', 'n_estimators': 344, 'feature_fraction_bynode': 0.9452391210624501, 'min_data_in_leaf': 35, 'alpha': 36.766765883924585, 'reg_lambda': 35.640565461876726, 'bagging_fraction': 0.8068734915428245, 'bagging_freq': 318}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8057321042706761, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8057321042706761\n",
      "[LightGBM] [Warning] bagging_freq is set=320, subsample_freq=0 will be ignored. Current value: bagging_freq=320\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:02:57,049] Trial 52 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 701, 'boosting_type': 'rf', 'n_estimators': 342, 'feature_fraction_bynode': 0.49972439841944405, 'min_data_in_leaf': 29, 'alpha': 28.860714977325944, 'bagging_fraction': 0.8057321042706761, 'bagging_freq': 320, 'reg_lambda': 28.830683027831466}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8770651834233945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770651834233945\n",
      "[LightGBM] [Warning] bagging_freq is set=241, subsample_freq=0 will be ignored. Current value: bagging_freq=241\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:01,877] Trial 53 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 867, 'boosting_type': 'rf', 'n_estimators': 265, 'feature_fraction_bynode': 0.43261255413746713, 'min_data_in_leaf': 29, 'alpha': 29.11715460036847, 'bagging_fraction': 0.8770651834233945, 'bagging_freq': 241, 'reg_lambda': 28.744914735919593}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8098208727400021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8098208727400021\n",
      "[LightGBM] [Warning] bagging_freq is set=356, subsample_freq=0 will be ignored. Current value: bagging_freq=356\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:08,514] Trial 54 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 557, 'boosting_type': 'rf', 'n_estimators': 412, 'feature_fraction_bynode': 0.48670221313039524, 'min_data_in_leaf': 29, 'alpha': 29.11766339975996, 'bagging_fraction': 0.8098208727400021, 'bagging_freq': 356, 'reg_lambda': 28.731670293738656}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=325, subsample_freq=0 will be ignored. Current value: bagging_freq=325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9989226038488688, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9989226038488688\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8854271607698782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8854271607698782\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:24,075] Trial 55 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 756, 'boosting_type': 'dart', 'n_estimators': 351, 'learning_rate': 0.0005, 'min_data_in_leaf': 20, 'feature_fraction': 0.9989226038488688, 'bagging_fraction': 0.8854271607698782, 'bagging_freq': 325, 'drop_rate': 0.010996035809740812}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.782652935515652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.782652935515652\n",
      "[LightGBM] [Warning] bagging_freq is set=250, subsample_freq=0 will be ignored. Current value: bagging_freq=250\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:28,105] Trial 56 finished with value: 0.6612903225806451 and parameters: {'model_type': 'lgbm', 'num_leaves': 969, 'boosting_type': 'rf', 'n_estimators': 272, 'feature_fraction_bynode': 0.9308878862010153, 'min_data_in_leaf': 34, 'alpha': 36.67491006005715, 'reg_lambda': 37.836495009186606, 'bagging_fraction': 0.782652935515652, 'bagging_freq': 250}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:31,920] Trial 57 finished with value: 0.6666666666666666 and parameters: {'model_type': 'lgbm', 'num_leaves': 657, 'boosting_type': 'goss', 'learning_rate': 0.01, 'min_data_in_leaf': 29, 'top_rate': 0.3388966058798169}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.827781506716702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.827781506716702\n",
      "[LightGBM] [Warning] bagging_freq is set=352, subsample_freq=0 will be ignored. Current value: bagging_freq=352\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:38,692] Trial 58 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 849, 'boosting_type': 'rf', 'n_estimators': 411, 'feature_fraction_bynode': 0.5008337928407111, 'min_data_in_leaf': 29, 'alpha': 29.186504328549454, 'bagging_fraction': 0.827781506716702, 'bagging_freq': 352, 'reg_lambda': 28.88915698261457}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8992686798607668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8992686798607668\n",
      "[LightGBM] [Warning] bagging_freq is set=282, subsample_freq=0 will be ignored. Current value: bagging_freq=282\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:43,146] Trial 59 finished with value: 0.6626344086021505 and parameters: {'model_type': 'lgbm', 'num_leaves': 390, 'boosting_type': 'rf', 'n_estimators': 329, 'feature_fraction_bynode': 0.993836782157324, 'min_data_in_leaf': 38, 'alpha': 35.92680738882105, 'reg_lambda': 37.38363097682037, 'bagging_fraction': 0.8992686798607668, 'bagging_freq': 282}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8266067371211966, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8266067371211966\n",
      "[LightGBM] [Warning] bagging_freq is set=341, subsample_freq=0 will be ignored. Current value: bagging_freq=341\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:49,275] Trial 60 finished with value: 0.6693548387096774 and parameters: {'model_type': 'lgbm', 'num_leaves': 587, 'boosting_type': 'rf', 'n_estimators': 384, 'feature_fraction_bynode': 0.5704465342615039, 'min_data_in_leaf': 29, 'alpha': 29.162585537821766, 'bagging_fraction': 0.8266067371211966, 'bagging_freq': 341, 'reg_lambda': 29.076639027861297}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8480598365368747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8480598365368747\n",
      "[LightGBM] [Warning] bagging_freq is set=259, subsample_freq=0 will be ignored. Current value: bagging_freq=259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:53,270] Trial 61 finished with value: 0.6155913978494624 and parameters: {'model_type': 'lgbm', 'num_leaves': 811, 'boosting_type': 'rf', 'n_estimators': 279, 'feature_fraction_bynode': 0.998959348995812, 'min_data_in_leaf': 38, 'alpha': 39.860748498377966, 'reg_lambda': 38.574897615983566, 'bagging_fraction': 0.8480598365368747, 'bagging_freq': 259}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8352127397400297, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8352127397400297\n",
      "[LightGBM] [Warning] bagging_freq is set=258, subsample_freq=0 will be ignored. Current value: bagging_freq=258\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:03:57,905] Trial 62 finished with value: 0.6693548387096774 and parameters: {'model_type': 'lgbm', 'num_leaves': 722, 'boosting_type': 'rf', 'n_estimators': 278, 'feature_fraction_bynode': 0.6284728593413772, 'min_data_in_leaf': 30, 'alpha': 29.37353595371652, 'bagging_fraction': 0.8352127397400297, 'bagging_freq': 258, 'reg_lambda': 29.20293734983912}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9143882104136638, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9143882104136638\n",
      "[LightGBM] [Warning] bagging_freq is set=210, subsample_freq=0 will be ignored. Current value: bagging_freq=210\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:02,177] Trial 63 finished with value: 0.6693548387096774 and parameters: {'model_type': 'lgbm', 'num_leaves': 893, 'boosting_type': 'rf', 'n_estimators': 233, 'feature_fraction_bynode': 0.6313863838692294, 'min_data_in_leaf': 30, 'alpha': 29.39240529806068, 'bagging_fraction': 0.9143882104136638, 'bagging_freq': 210, 'reg_lambda': 29.26970502106371}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7758462863378325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7758462863378325\n",
      "[LightGBM] [Warning] bagging_freq is set=330, subsample_freq=0 will be ignored. Current value: bagging_freq=330\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:06,910] Trial 64 finished with value: 0.6330645161290323 and parameters: {'model_type': 'lgbm', 'num_leaves': 806, 'boosting_type': 'rf', 'n_estimators': 360, 'feature_fraction_bynode': 0.9903962115665084, 'min_data_in_leaf': 38, 'alpha': 39.7804349079718, 'reg_lambda': 39.94437476316894, 'bagging_fraction': 0.7758462863378325, 'bagging_freq': 330}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7674255464591784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7674255464591784\n",
      "[LightGBM] [Warning] bagging_freq is set=413, subsample_freq=0 will be ignored. Current value: bagging_freq=413\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:13,030] Trial 65 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 908, 'boosting_type': 'rf', 'n_estimators': 450, 'feature_fraction_bynode': 0.6625056984854902, 'min_data_in_leaf': 33, 'alpha': 39.90519412336647, 'reg_lambda': 36.10348185420813, 'bagging_fraction': 0.7674255464591784, 'bagging_freq': 413}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=333, subsample_freq=0 will be ignored. Current value: bagging_freq=333\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8688848080225946, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8688848080225946\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.790960489479127, subsample=1.0 will be ignored. Current value: bagging_fraction=0.790960489479127\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:20,944] Trial 66 finished with value: 0.6397849462365591 and parameters: {'model_type': 'lgbm', 'num_leaves': 675, 'boosting_type': 'dart', 'n_estimators': 357, 'learning_rate': 0.05, 'min_data_in_leaf': 38, 'feature_fraction': 0.8688848080225946, 'bagging_fraction': 0.790960489479127, 'bagging_freq': 333, 'drop_rate': 0.9529367673404502}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=323, subsample_freq=0 will be ignored. Current value: bagging_freq=323\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8658422825130387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8658422825130387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7766531546887528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7766531546887528\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:28,085] Trial 67 finished with value: 0.6505376344086021 and parameters: {'model_type': 'lgbm', 'num_leaves': 512, 'boosting_type': 'dart', 'n_estimators': 346, 'learning_rate': 0.05, 'min_data_in_leaf': 38, 'feature_fraction': 0.8658422825130387, 'bagging_fraction': 0.7766531546887528, 'bagging_freq': 323, 'drop_rate': 0.9970192529275451}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=388, subsample_freq=0 will be ignored. Current value: bagging_freq=388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.869353375922925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.869353375922925\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7501275911051014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7501275911051014\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:37,119] Trial 68 finished with value: 0.6478494623655914 and parameters: {'model_type': 'lgbm', 'num_leaves': 669, 'boosting_type': 'dart', 'n_estimators': 436, 'learning_rate': 0.05, 'min_data_in_leaf': 38, 'feature_fraction': 0.869353375922925, 'bagging_fraction': 0.7501275911051014, 'bagging_freq': 388, 'drop_rate': 0.9670387694144298}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.4934332808070528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4934332808070528\n",
      "[LightGBM] [Warning] feature_fraction is set=0.12131795523874522, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.12131795523874522\n",
      "[LightGBM] [Warning] bagging_freq is set=346, subsample_freq=0 will be ignored. Current value: bagging_freq=346\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:04:38,597] Trial 69 finished with value: 0.6586021505376344 and parameters: {'model_type': 'lgbm', 'num_leaves': 609, 'boosting_type': 'gbdt', 'n_estimators': 389, 'learning_rate': 0.05, 'min_data_in_leaf': 37, 'feature_fraction': 0.12131795523874522, 'bagging_fraction': 0.4934332808070528, 'bagging_freq': 346, 'alpha': 34.94163945006681, 'reg_lambda': 35.30538330060417}. Best is trial 44 with value: 0.6048387096774194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n",
      "\n",
      "[W 2023-06-11 01:04:39,202] Trial 70 failed with parameters: {'model_type': 'lgbm', 'num_leaves': 694, 'boosting_type': 'goss', 'learning_rate': 0.05, 'min_data_in_leaf': 33, 'top_rate': 0.9034764045142119} because of the following error: LightGBMError('Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/ipykernel_95655/1136822802.py\", line 981, in model_selector\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n",
      "\n",
      "[W 2023-06-11 01:04:39,202] Trial 70 failed with value None.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_selector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[73], line 981\u001b[0m, in \u001b[0;36mmodel_selector\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    968\u001b[0m top_rate \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    969\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\n\u001b[1;32m    970\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m    971\u001b[0m     boosting_type\u001b[38;5;241m=\u001b[39mboosting_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    978\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state\n\u001b[1;32m    979\u001b[0m )\n\u001b[0;32m--> 981\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_val, preds)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m             valid_sets[i] \u001b[38;5;241m=\u001b[39m (valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y))\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py:2610\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2608\u001b[0m params_str \u001b[38;5;241m=\u001b[39m param_dict_to_str(params)\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m-> 2610\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(model_selector, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de1143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e75ae1b1",
   "metadata": {},
   "source": [
    "print('Number of finished XGB trials: {}'.format(len(xgb_study.trials)))\n",
    "print('XGB Best trial:')\n",
    "xgb_trial = xgb_study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(xgb_trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in xgb_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7203e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished study trials: 71\n",
      "study Best trial:\n",
      "  Value: 0.6048387096774194\n",
      "  Params: \n",
      "    model_type: lgbm\n",
      "    num_leaves: 624\n",
      "    boosting_type: rf\n",
      "    n_estimators: 369\n",
      "    feature_fraction_bynode: 0.9918816210292678\n",
      "    min_data_in_leaf: 36\n",
      "    alpha: 36.86553886301719\n",
      "    reg_lambda: 36.63410100650133\n",
      "    bagging_fraction: 0.8202101827173186\n",
      "    bagging_freq: 358\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished study trials: {}'.format(len(study.trials)))\n",
    "print('study Best trial:')\n",
    "study_trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(study_trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in study_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c757e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(alpha=36.86553886301719, bagging_fraction=0.8202101827173186,\n",
       "               bagging_freq=358, boosting_type=&#x27;rf&#x27;,\n",
       "               feature_fraction_bynode=0.9918816210292678, min_data_in_leaf=36,\n",
       "               n_estimators=369, num_leaves=624, reg_lambda=36.63410100650133)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(alpha=36.86553886301719, bagging_fraction=0.8202101827173186,\n",
       "               bagging_freq=358, boosting_type=&#x27;rf&#x27;,\n",
       "               feature_fraction_bynode=0.9918816210292678, min_data_in_leaf=36,\n",
       "               n_estimators=369, num_leaves=624, reg_lambda=36.63410100650133)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(alpha=36.86553886301719, bagging_fraction=0.8202101827173186,\n",
       "               bagging_freq=358, boosting_type='rf',\n",
       "               feature_fraction_bynode=0.9918816210292678, min_data_in_leaf=36,\n",
       "               n_estimators=369, num_leaves=624, reg_lambda=36.63410100650133)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_best_params = study.best_params\n",
    "study_best_params['random_state'] = 42\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    num_leaves= 624,\n",
    "    boosting_type= 'rf',\n",
    "    n_estimators= 369,\n",
    "    feature_fraction_bynode= 0.9918816210292678,\n",
    "    min_data_in_leaf= 36,\n",
    "    alpha= 36.86553886301719,\n",
    "    reg_lambda= 36.63410100650133,\n",
    "    bagging_fraction= 0.8202101827173186,\n",
    "    bagging_freq= 358)\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "247004aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_preds = lgb_model.predict(X_val)\n",
    "lgb_accuracy = accuracy_score(y_val, lgb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809e172",
   "metadata": {},
   "source": [
    "XGB_pred = XGB.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, XGB_pred)\n",
    "print(\"\\nAccuracy after tuning: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c70e0926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LGB --\n",
      "Train ACC : 0.699\n",
      "Val ACC : 0.612\n"
     ]
    }
   ],
   "source": [
    "print(\"-- LGB --\")\n",
    "print(\"Train ACC : %.3f\" % accuracy_score(y_train, lgb_model.predict(X_train)))\n",
    "print(\"Val ACC : %.3f\" % accuracy_score(y_val, lgb_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236b945",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"\\n-- XGB --\")\n",
    "print(\"Train ACC : %.3f\" % accuracy_score(y_train, XGB.predict(X_train)))\n",
    "print(\"Val ACC : %.3f\" % accuracy_score(y_val, XGB.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "784da023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.11      0.16       245\n",
      "           1       0.66      0.86      0.75       499\n",
      "\n",
      "    accuracy                           0.61       744\n",
      "   macro avg       0.47      0.48      0.45       744\n",
      "weighted avg       0.54      0.61      0.55       744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, lgb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba54e9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6     \\\n",
      "0    -0.006672 -0.080011 -0.014580 -0.038840  0.048455 -0.040639  0.039663   \n",
      "1    -0.003053 -0.011769 -0.034803 -0.041324 -0.026498 -0.014561  0.012917   \n",
      "2    -0.025638 -0.016005 -0.021478  0.014413  0.048054 -0.036683 -0.034054   \n",
      "3     0.028991  0.036599 -0.059128 -0.030722 -0.017587 -0.028222  0.052064   \n",
      "4     0.036941 -0.039247 -0.026675 -0.006587 -0.022472 -0.016113  0.046348   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1235 -0.017606 -0.026507 -0.038503 -0.013017  0.036128 -0.006750 -0.023582   \n",
      "1236 -0.001220 -0.002364 -0.025906 -0.023937  0.002847 -0.021732  0.076602   \n",
      "1237  0.001026  0.023440  0.013377  0.016586  0.024960 -0.001395  0.063505   \n",
      "1238  0.001634 -0.000814 -0.014695  0.003300  0.001420  0.028769 -0.025222   \n",
      "1239 -0.058938  0.010668  0.004917 -0.051615  0.033669  0.037903  0.019593   \n",
      "\n",
      "          7         8         9     ...      1526      1527      1528  \\\n",
      "0     0.068547  0.002239 -0.029425  ... -0.012600 -0.023597 -0.003138   \n",
      "1    -0.009658 -0.000563 -0.018914  ... -0.018383 -0.027521  0.004810   \n",
      "2     0.043429 -0.017806 -0.045973  ... -0.023804 -0.017397  0.008190   \n",
      "3    -0.009327  0.006705 -0.008745  ... -0.021711 -0.015069 -0.001111   \n",
      "4    -0.012971  0.029547 -0.051456  ... -0.016862 -0.034918  0.005033   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1235  0.004234 -0.010011 -0.024067  ... -0.010572 -0.034447 -0.002972   \n",
      "1236 -0.014772 -0.012813 -0.014318  ... -0.000953 -0.013990  0.002872   \n",
      "1237 -0.017101 -0.032935 -0.016052  ... -0.018592 -0.016234  0.018842   \n",
      "1238  0.065449 -0.011581 -0.044858  ...  0.004752  0.003640  0.013376   \n",
      "1239  0.016298 -0.019234 -0.045782  ... -0.027754 -0.020528  0.022163   \n",
      "\n",
      "          1529      1530      1531      1532      1533      1534      1535  \n",
      "0    -0.008353 -0.034796 -0.020804 -0.006913 -0.038063  0.008657 -0.021999  \n",
      "1    -0.006279 -0.019910 -0.044318 -0.049594 -0.022413  0.012250  0.003738  \n",
      "2    -0.010989 -0.014011 -0.041264 -0.009615 -0.012293 -0.000732  0.010219  \n",
      "3    -0.014473 -0.025876 -0.006428 -0.018803 -0.028281 -0.004001 -0.012030  \n",
      "4     0.000040 -0.037341 -0.040531 -0.014745 -0.042890 -0.000467 -0.010147  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1235 -0.012302 -0.004949 -0.046846 -0.039191 -0.034175 -0.013973  0.006327  \n",
      "1236 -0.030309 -0.013520 -0.053392 -0.012986 -0.014506 -0.011636  0.024630  \n",
      "1237 -0.002355 -0.015415 -0.033917 -0.057270 -0.028927 -0.005387  0.000249  \n",
      "1238 -0.006307 -0.005089 -0.044533 -0.016824 -0.018459 -0.004400  0.022938  \n",
      "1239 -0.013797 -0.022734 -0.028132 -0.043650 -0.025505 -0.002197 -0.011266  \n",
      "\n",
      "[1240 rows x 1536 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.get_dummies(data=test_x)\n",
    "print(X_test)\n",
    "lgb_preds = lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28078cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "LGB_pred = pd.DataFrame(lgb_preds.astype(int))\n",
    "LGB_pred = LGB_pred.rename(columns={0:'first_party_winner'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77553934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_party_winner\n",
       "0                      0\n",
       "1                      1\n",
       "2                      1\n",
       "3                      1\n",
       "4                      1\n",
       "...                  ...\n",
       "1235                   0\n",
       "1236                   1\n",
       "1237                   1\n",
       "1238                   0\n",
       "1239                   1\n",
       "\n",
       "[1240 rows x 1 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10c6d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['first_party_winner'] = LGB_pred['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c7ade7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1058\n",
       "0     182\n",
       "Name: first_party_winner, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['first_party_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cf360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "98180da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"./results/LGB_submission_{Train:.03f}_{Val:.03f}.csv\".format(Train=accuracy_score(y_train, lgb_model.predict(X_train)), Val = accuracy_score(y_val, lgb_model.predict(X_val))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55745403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_submission = pd.read_csv('./sample_submission.csv')\n",
    "# XGB_pred = pd.DataFrame(XGB_pred.astype(int))\n",
    "# XGB_submission['first_party_winner'] = XGB_pred\n",
    "# XGB_submission.to_csv(\"./Bert_XGB_submission_{Train:.03f}_{Val:.03f}.csv\".format(Train=accuracy_score(y_train, XGB.predict(X_train)), Val = accuracy_score(y_val, XGB.predict(X_val))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc45434",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2bed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adf1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c0ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fb7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4a940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d2804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b949c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e8e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c88e3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b48fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf448d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f347e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45562744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D to 2D\n",
    "\n",
    "attention_mask_df = dlc.tensor_2_2d(train_bert_tokenized, 0)\n",
    "input_ids_df = dlc.tensor_2_2d(train_bert_tokenized, 1)\n",
    "token_type_ids_df = dlc.tensor_2_2d(train_bert_tokenized, 2)\n",
    "\n",
    "attention_mask_df.info()\n",
    "print('\\n _______________________________ \\n')\n",
    "input_ids_df.info()\n",
    "print('\\n _______________________________ \\n')\n",
    "token_type_ids_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4903d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask_df.info()\n",
    "attention_mask_df\n",
    "# input_ids_df.info()\n",
    "# input_ids_df\n",
    "# token_type_ids_df.info()\n",
    "# token_type_ids_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae125e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([train_cleansed['ID'], attention_mask_df], axis=1)\n",
    "temp = pd.concat([temp, input_ids_df], axis=1)\n",
    "train_BertToken_df = pd.concat([temp, token_type_ids_df], axis=1)\n",
    "train_BertToken_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tBTdf = so.right_merger(train_cleansed, train_BertToken_df, 0)\n",
    "tBTdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cbeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a9613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfb622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f31d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0818f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7ce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145d24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0007f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
