{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc258d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ___________________________\n",
      "|                           |\n",
      "|======== YearDream ========|\n",
      "|===========================|\n",
      "|==== DLC Well Imported ====|\n",
      "|===========================|\n",
      "|========= BYJASON =========|\n",
      "|___________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import dacon_law_class as dlc\n",
    "from dacon_law_class import SimpleOps as so\n",
    "\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "# import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247af21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "test = pd.read_csv('../test.csv')\n",
    "sample_submission = pd.read_csv('../sample_submission.csv')\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8011b50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>TEST_1235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>TEST_1236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>TEST_1237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>TEST_1238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>TEST_1239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  first_party_winner\n",
       "0     TEST_0000                   0\n",
       "1     TEST_0001                   0\n",
       "2     TEST_0002                   0\n",
       "3     TEST_0003                   0\n",
       "4     TEST_0004                   0\n",
       "...         ...                 ...\n",
       "1235  TEST_1235                   0\n",
       "1236  TEST_1236                   0\n",
       "1237  TEST_1237                   0\n",
       "1238  TEST_1238                   0\n",
       "1239  TEST_1239                   0\n",
       "\n",
       "[1240 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "# test\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2ef6ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ID                  2478 non-null   object\n",
      " 1   first_party         2478 non-null   object\n",
      " 2   second_party        2478 non-null   object\n",
      " 3   facts               2478 non-null   object\n",
      " 4   first_party_winner  2478 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 96.9+ KB\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "print('\\n\\n\\n')\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b052690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phil amant</td>\n",
       "      <td>herman ompson</td>\n",
       "      <td>phil amant caidate for public office made tele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ephen duncan</td>\n",
       "      <td>lawrence owens</td>\n",
       "      <td>ramon nelson was ridin his bike when he suffer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>billy joe mawood</td>\n",
       "      <td>tony patterson waen et al</td>\n",
       "      <td>an alabama ate court convicted billy joe mawoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkletter</td>\n",
       "      <td>walker</td>\n",
       "      <td>victor linkletter was convicted in ate court o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "      <td>in selma alabama an intruder broke into apartm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>hollyfrontier cheyenne refinin llc et al</td>\n",
       "      <td>renewable fuels association et al</td>\n",
       "      <td>conress ameed clean air act rouh enery policy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>rupo mexicano de desarrollo</td>\n",
       "      <td>alliance bo fu inc</td>\n",
       "      <td>alliance bo fu inc an invement fu purchased ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>peuero</td>\n",
       "      <td>united ates</td>\n",
       "      <td>in dirict court sentenced manuel peuero to mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>iiration naturalization service</td>\n",
       "      <td>cyr</td>\n",
       "      <td>enrico cyr lawful permanent resident pled uilt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>an</td>\n",
       "      <td>weview inruments inc</td>\n",
       "      <td>herbert an owns patent to syem at tracks cloin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   first_party  \\\n",
       "0                                   phil amant   \n",
       "1                                 ephen duncan   \n",
       "2                             billy joe mawood   \n",
       "3                                   linkletter   \n",
       "4                           william earl fikes   \n",
       "...                                        ...   \n",
       "2473  hollyfrontier cheyenne refinin llc et al   \n",
       "2474               rupo mexicano de desarrollo   \n",
       "2475                                    peuero   \n",
       "2476           iiration naturalization service   \n",
       "2477                                        an   \n",
       "\n",
       "                           second_party  \\\n",
       "0                         herman ompson   \n",
       "1                        lawrence owens   \n",
       "2             tony patterson waen et al   \n",
       "3                                walker   \n",
       "4                               alabama   \n",
       "...                                 ...   \n",
       "2473  renewable fuels association et al   \n",
       "2474                 alliance bo fu inc   \n",
       "2475                        united ates   \n",
       "2476                                cyr   \n",
       "2477               weview inruments inc   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     phil amant caidate for public office made tele...                   1  \n",
       "1     ramon nelson was ridin his bike when he suffer...                   0  \n",
       "2     an alabama ate court convicted billy joe mawoo...                   1  \n",
       "3     victor linkletter was convicted in ate court o...                   0  \n",
       "4     in selma alabama an intruder broke into apartm...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  conress ameed clean air act rouh enery policy ...                   1  \n",
       "2474  alliance bo fu inc an invement fu purchased ap...                   1  \n",
       "2475  in dirict court sentenced manuel peuero to mon...                   0  \n",
       "2476  enrico cyr lawful permanent resident pled uilt...                   0  \n",
       "2477  herbert an owns patent to syem at tracks cloin...                   0  \n",
       "\n",
       "[2478 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train['facts'])\n",
    "df = dlc.law_preprocessor(df, 'facts')\n",
    "train['facts'] = df['facts']\n",
    "df = pd.DataFrame(train['first_party'])\n",
    "df = dlc.law_preprocessor(df, 'first_party')\n",
    "train['first_party'] = df['first_party']\n",
    "df = pd.DataFrame(train['second_party'])\n",
    "df = dlc.law_preprocessor(df, 'second_party')\n",
    "train['second_party'] = df['second_party']\n",
    "train_cleansed = train.drop(columns='ID')\n",
    "train_cleansed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42f6a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salerno</td>\n",
       "      <td>united ates</td>\n",
       "      <td>bail reform act allowed federal courts to deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milber weiss bershad hynes lerach</td>\n",
       "      <td>lexecon inc</td>\n",
       "      <td>lexecon inc was defeant in class action lawsui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no title federal counications coission et al</td>\n",
       "      <td>fox television ations inc et al</td>\n",
       "      <td>in fox television ations broadca billboa music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harold kaufman</td>\n",
       "      <td>united ates</td>\n",
       "      <td>durin his trial for armed robbery of federally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berer</td>\n",
       "      <td>hanlon</td>\n",
       "      <td>in mairate jude issued warrant auorizin search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>haitian centers council inc et al</td>\n",
       "      <td>chris sale actin coissioner iiration naturaliz...</td>\n",
       "      <td>accoin to executive oer no sined by president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>whitman</td>\n",
       "      <td>american truckin associations inc</td>\n",
       "      <td>section of clean air act requires environmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>lia matteo john madian</td>\n",
       "      <td>william barr</td>\n",
       "      <td>lia matteo john madian created plan for utiliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>washinton ate apple advertisin coission</td>\n",
       "      <td>hunt</td>\n",
       "      <td>in nor carolina boa of ariculture adopted reul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>eodore ovall</td>\n",
       "      <td>wilfred denno waen</td>\n",
       "      <td>dr paul berheldt was abbed to dea in kitchen o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       first_party  \\\n",
       "0                                          salerno   \n",
       "1                milber weiss bershad hynes lerach   \n",
       "2     no title federal counications coission et al   \n",
       "3                                   harold kaufman   \n",
       "4                                            berer   \n",
       "...                                            ...   \n",
       "1235             haitian centers council inc et al   \n",
       "1236                                       whitman   \n",
       "1237                        lia matteo john madian   \n",
       "1238       washinton ate apple advertisin coission   \n",
       "1239                                  eodore ovall   \n",
       "\n",
       "                                           second_party  \\\n",
       "0                                           united ates   \n",
       "1                                           lexecon inc   \n",
       "2                       fox television ations inc et al   \n",
       "3                                           united ates   \n",
       "4                                                hanlon   \n",
       "...                                                 ...   \n",
       "1235  chris sale actin coissioner iiration naturaliz...   \n",
       "1236                  american truckin associations inc   \n",
       "1237                                       william barr   \n",
       "1238                                               hunt   \n",
       "1239                                 wilfred denno waen   \n",
       "\n",
       "                                                  facts  \n",
       "0     bail reform act allowed federal courts to deta...  \n",
       "1     lexecon inc was defeant in class action lawsui...  \n",
       "2     in fox television ations broadca billboa music...  \n",
       "3     durin his trial for armed robbery of federally...  \n",
       "4     in mairate jude issued warrant auorizin search...  \n",
       "...                                                 ...  \n",
       "1235  accoin to executive oer no sined by president ...  \n",
       "1236  section of clean air act requires environmenta...  \n",
       "1237  lia matteo john madian created plan for utiliz...  \n",
       "1238  in nor carolina boa of ariculture adopted reul...  \n",
       "1239  dr paul berheldt was abbed to dea in kitchen o...  \n",
       "\n",
       "[1240 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test['facts'])\n",
    "df = dlc.law_preprocessor(df, 'facts')\n",
    "test['facts'] = df['facts']\n",
    "df = pd.DataFrame(test['first_party'])\n",
    "df = dlc.law_preprocessor(df, 'first_party')\n",
    "test['first_party'] = df['first_party']\n",
    "df = pd.DataFrame(test['second_party'])\n",
    "df = dlc.law_preprocessor(df, 'second_party')\n",
    "test['second_party'] = df['second_party']\n",
    "test_cleansed = test.drop(columns='ID')\n",
    "test_cleansed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8f896",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "@article{turc2019,\n",
    "  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},\n",
    "  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n",
    "  journal={arXiv preprint arXiv:1908.08962v2 },\n",
    "  year={2019}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_facts = pd.DataFrame(test_cleansed['facts'])\n",
    "train_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fact = pd.DataFrame(test_cleansed['facts'])\n",
    "test_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9d178",
   "metadata": {},
   "source": [
    "model_input_df = dlc.bert_tokenizer(train_facts, 'facts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383af38c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47a66c",
   "metadata": {},
   "source": [
    "df_part_1, df_part_2, df_part_3, df_part_4, df_part_5, df_part_6, df_part_7, df_part_8, df_part_9, df_part_10, df_part_11, df_part_12, df_part_13, df_part_14, df_part_15, df_part_16, df_part_17, df_part_18, df_part_19, df_part_20, df_part_21, df_part_22, df_part_23, df_part_24, df_part_25, df_part_26 = so.df_divider(train_cleansed, 'facts')\n",
    "df_part_1 = pd.DataFrame(df_part_1)\n",
    "df_part_2 = pd.DataFrame(df_part_2)\n",
    "df_part_3 = pd.DataFrame(df_part_3)\n",
    "df_part_4 = pd.DataFrame(df_part_4)\n",
    "df_part_5 = pd.DataFrame(df_part_5)\n",
    "df_part_6 = pd.DataFrame(df_part_6)\n",
    "df_part_7 = pd.DataFrame(df_part_7)\n",
    "df_part_8 = pd.DataFrame(df_part_8)\n",
    "df_part_9 = pd.DataFrame(df_part_9)\n",
    "df_part_10 = pd.DataFrame(df_part_10)\n",
    "df_part_11 = pd.DataFrame(df_part_11)\n",
    "df_part_12 = pd.DataFrame(df_part_12)\n",
    "df_part_13 = pd.DataFrame(df_part_13)\n",
    "df_part_14 = pd.DataFrame(df_part_14)\n",
    "df_part_15 = pd.DataFrame(df_part_15)\n",
    "df_part_16 = pd.DataFrame(df_part_16)\n",
    "df_part_17 = pd.DataFrame(df_part_17)\n",
    "df_part_18 = pd.DataFrame(df_part_18)\n",
    "df_part_19 = pd.DataFrame(df_part_19)\n",
    "df_part_20 = pd.DataFrame(df_part_20)\n",
    "df_part_21 = pd.DataFrame(df_part_21)\n",
    "df_part_22 = pd.DataFrame(df_part_22)\n",
    "df_part_23 = pd.DataFrame(df_part_23)\n",
    "df_part_24 = pd.DataFrame(df_part_24)\n",
    "df_part_25 = pd.DataFrame(df_part_25)\n",
    "df_part_26 = pd.DataFrame(df_part_26)\n",
    "print(df_part_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bf34c",
   "metadata": {},
   "source": [
    "embedded_df_1 = dlc.auto_tokenizer(train_cleansed, 'facts')\n",
    "embedded_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83cfc76",
   "metadata": {},
   "source": [
    "embedded_df_1 = embedded_df_1.rename(columns={0:'facts_berted'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab2385",
   "metadata": {},
   "source": [
    "embedded_df_1.to_csv('./embeddings/facts_embedded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ce9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_berted = dlc.auto_tokenizer(train_cleansed, 'first_party')\n",
    "first_party_berted = first_party_berted.rename(columns={0:'first_party_berted'})\n",
    "first_party_berted.to_csv('./embeddings/first_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_party_berted = dlc.auto_tokenizer(train_cleansed, 'second_party')\n",
    "second_party_berted = second_party_berted.rename(columns={0:'second_party_berted'})\n",
    "second_party_berted.to_csv('./embeddings/second_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ba3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_berted = dlc.auto_tokenizer(train_cleansed, 'facts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecee19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_berted = facts_berted.rename(columns={0:'facts_berted'})\n",
    "facts_berted.to_csv('./embeddings/facts_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_berted = pd.read_csv('./embeddings/first_party_berted.csv')\n",
    "second_party_berted = pd.read_csv('./embeddings/second_party_berted.csv')\n",
    "facts_berted = pd.read_csv('./embeddings/facts_berted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715db0c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ready_to_ml = pd.concat([first_party_berted['first_party_berted'], second_party_berted['second_party_berted'], facts_berted['facts_berted'], train_cleansed['first_party_winner']], axis=1)\n",
    "all_ready_to_ml.to_csv('./embeddings/1_train_ready_to_ml.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a083bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first_party_berted = dlc.auto_tokenizer(test_cleansed, 'first_party')\n",
    "test_first_party_berted = test_first_party_berted.rename(columns={0:'first_party_berted'})\n",
    "test_first_party_berted.to_csv('./embeddings/test_first_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_second_party_berted = dlc.auto_tokenizer(test_cleansed, 'second_party')\n",
    "test_second_party_berted = test_second_party_berted.rename(columns={0:'second_party_berted'})\n",
    "test_second_party_berted.to_csv('./embeddings/test_second_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_facts_berted = dlc.auto_tokenizer(test_cleansed, 'facts')\n",
    "test_facts_berted = test_facts_berted.rename(columns={0:'facts_berted'})\n",
    "test_facts_berted.to_csv('./embeddings/test_facts_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a83617",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first_party_berted = pd.read_csv('./embeddings/test_first_party_berted.csv')\n",
    "test_second_party_berted = pd.read_csv('./embeddings/test_second_party_berted.csv')\n",
    "test_facts_berted = pd.read_csv('./embeddings/test_facts_berted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ready_to_ml = pd.concat([test_first_party_berted['first_party_berted'], test_second_party_berted['second_party_berted'], test_facts_berted['facts_berted']], axis=1)\n",
    "test_ready_to_ml.to_csv('./embeddings/2_test_ready_to_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e3c0a",
   "metadata": {},
   "source": [
    "# ì—¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34b1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_ml = pd.read_csv('../embeddings/1_train_ready_to_ml.csv')\n",
    "test_ready_to_ml = pd.read_csv('../embeddings/2_test_ready_to_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78df3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2478/2478 [00:01<00:00, 2227.22it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2478/2478 [00:01<00:00, 2243.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2478/2478 [00:01<00:00, 2259.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_to_ml_fp_pr = dlc.tensor_separator(train_to_ml, 'first_party_berted')\n",
    "train_to_ml_sp_pr = dlc.tensor_separator(train_to_ml, 'second_party_berted')\n",
    "train_to_ml_facts_pr = dlc.tensor_separator(train_to_ml, 'facts_berted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b09c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_ml_fp_pr = train_to_ml_fp_pr.astype('float64')\n",
    "train_to_ml_sp_pr = train_to_ml_sp_pr.astype('float64') \n",
    "train_to_ml_facts_pr = train_to_ml_facts_pr.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a61f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Columns: 768 entries, 0 to 767\n",
      "dtypes: float64(768)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_to_ml_fp_pr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88eddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<00:00, 2276.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<00:00, 2291.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<00:00, 2254.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_to_ml_fp_pr = dlc.tensor_separator(test_ready_to_ml, 'first_party_berted')\n",
    "test_to_ml_sp_pr = dlc.tensor_separator(test_ready_to_ml, 'second_party_berted')\n",
    "test_to_ml_facts_pr = dlc.tensor_separator(test_ready_to_ml, 'facts_berted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824f88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_ml_fp_pr = test_to_ml_fp_pr.astype('float64')\n",
    "test_to_ml_sp_pr = test_to_ml_sp_pr.astype('float64')\n",
    "test_to_ml_facts_pr = test_to_ml_facts_pr.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee9c4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_X = pd.concat([train_to_ml_fp_pr, train_to_ml_facts_pr], axis=1)\n",
    "to_be_test_x = pd.concat([test_to_ml_fp_pr, test_to_ml_facts_pr], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72a15692",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>-0.012888</td>\n",
       "      <td>-0.007303</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>-0.029552</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018174</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-0.010968</td>\n",
       "      <td>-0.030724</td>\n",
       "      <td>-0.035971</td>\n",
       "      <td>-0.038689</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>-0.010507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003902</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.044628</td>\n",
       "      <td>-0.032344</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>-0.018207</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.016356</td>\n",
       "      <td>-0.039208</td>\n",
       "      <td>-0.031188</td>\n",
       "      <td>-0.014293</td>\n",
       "      <td>-0.026212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>-0.017064</td>\n",
       "      <td>-0.019458</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>-0.030393</td>\n",
       "      <td>-0.020106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011412</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>-0.010546</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.025278</td>\n",
       "      <td>-0.054787</td>\n",
       "      <td>-0.016296</td>\n",
       "      <td>-0.009530</td>\n",
       "      <td>-0.012053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.015234</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>-0.018534</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>-0.030493</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>-0.013273</td>\n",
       "      <td>-0.019490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.005936</td>\n",
       "      <td>-0.003335</td>\n",
       "      <td>-0.026111</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>-0.027738</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011956</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>-0.037784</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>-0.023835</td>\n",
       "      <td>-0.029138</td>\n",
       "      <td>-0.031670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>-0.023639</td>\n",
       "      <td>-0.028438</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>-0.030627</td>\n",
       "      <td>-0.035033</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.024343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>-0.020591</td>\n",
       "      <td>-0.056972</td>\n",
       "      <td>-0.033879</td>\n",
       "      <td>0.031382</td>\n",
       "      <td>0.079985</td>\n",
       "      <td>0.025763</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.060979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027422</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.008214</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.009470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>-0.023678</td>\n",
       "      <td>-0.022937</td>\n",
       "      <td>-0.022214</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.039568</td>\n",
       "      <td>-0.052614</td>\n",
       "      <td>-0.034712</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>-0.004295</td>\n",
       "      <td>-0.029256</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>-0.010641</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>-0.022453</td>\n",
       "      <td>-0.034121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>-0.019696</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.042203</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.023756</td>\n",
       "      <td>-0.004682</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0.021019</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>-0.021894</td>\n",
       "      <td>-0.032928</td>\n",
       "      <td>-0.029230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023799</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>-0.011824</td>\n",
       "      <td>-0.020932</td>\n",
       "      <td>-0.033988</td>\n",
       "      <td>-0.028924</td>\n",
       "      <td>-0.045331</td>\n",
       "      <td>-0.013245</td>\n",
       "      <td>-0.016124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>-0.006356</td>\n",
       "      <td>-0.011619</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>-0.008010</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>-0.016714</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>-0.046451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031149</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>-0.010829</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.037060</td>\n",
       "      <td>-0.035695</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows Ã— 1537 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.005036  0.006439 -0.012888 -0.007303 -0.017571 -0.029552 -0.006318   \n",
       "1    -0.003902  0.026781 -0.044628 -0.032344 -0.001729 -0.018735  0.002111   \n",
       "2     0.003050  0.009259 -0.017064 -0.019458 -0.006200 -0.008553  0.050010   \n",
       "3    -0.015234 -0.000875  0.015897 -0.018534  0.054608 -0.030493  0.041842   \n",
       "4    -0.011956 -0.009987  0.020198  0.009508  0.024592 -0.037784  0.020635   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2473 -0.020591 -0.056972 -0.033879  0.031382  0.079985  0.025763 -0.006569   \n",
       "2474 -0.023678 -0.022937 -0.022214  0.013166  0.054840  0.011287  0.016339   \n",
       "2475 -0.004295 -0.029256 -0.015316 -0.010641  0.007141  0.021234  0.005180   \n",
       "2476  0.021019 -0.003120 -0.007031  0.007962  0.045658  0.014659  0.024269   \n",
       "2477 -0.006356 -0.011619 -0.007439 -0.012634 -0.008010 -0.005947  0.032153   \n",
       "\n",
       "             7         8         9  ...      1527      1528      1529  \\\n",
       "0     0.025047 -0.009394 -0.015124  ... -0.018174  0.001737  0.003518   \n",
       "1    -0.018207 -0.009919 -0.075807  ... -0.010969  0.006232 -0.012417   \n",
       "2     0.035903 -0.030393 -0.020106  ... -0.011412 -0.006155 -0.010546   \n",
       "3     0.057857 -0.013273 -0.019490  ... -0.019637 -0.005936 -0.003335   \n",
       "4    -0.023835 -0.029138 -0.031670  ... -0.033741  0.007560 -0.023639   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2473  0.044251 -0.008797 -0.060979  ... -0.027422  0.000112  0.015122   \n",
       "2474  0.090016  0.000314  0.001474  ... -0.017667  0.015822 -0.002527   \n",
       "2475  0.064935 -0.022453 -0.034121  ... -0.011819  0.019265 -0.019696   \n",
       "2476 -0.021894 -0.032928 -0.029230  ... -0.023799  0.002132 -0.011824   \n",
       "2477 -0.016714  0.039917 -0.046451  ... -0.031149 -0.003120  0.002196   \n",
       "\n",
       "          1530      1531      1532      1533      1534      1535  \\\n",
       "0    -0.010968 -0.030724 -0.035971 -0.038689 -0.006275 -0.010507   \n",
       "1    -0.020754 -0.016356 -0.039208 -0.031188 -0.014293 -0.026212   \n",
       "2    -0.024606 -0.025278 -0.054787 -0.016296 -0.009530 -0.012053   \n",
       "3    -0.026111 -0.015403  0.000960 -0.027738  0.005133 -0.012935   \n",
       "4    -0.028438 -0.010833 -0.030627 -0.035033 -0.000732 -0.024343   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "2473  0.009355 -0.046905 -0.002683 -0.008214 -0.000282 -0.009470   \n",
       "2474  0.004892 -0.039568 -0.052614 -0.034712 -0.004466  0.008349   \n",
       "2475 -0.024496 -0.042203 -0.044682 -0.023756 -0.004682  0.003538   \n",
       "2476 -0.020932 -0.033988 -0.028924 -0.045331 -0.013245 -0.016124   \n",
       "2477 -0.010829 -0.016647 -0.037060 -0.035695 -0.007506  0.002923   \n",
       "\n",
       "      first_party_winner  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "2473                   1  \n",
       "2474                   1  \n",
       "2475                   0  \n",
       "2476                   0  \n",
       "2477                   0  \n",
       "\n",
       "[2478 rows x 1537 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_X.columns = np.arange(len(to_be_X.columns))\n",
    "to_be_X = pd.concat([to_be_X, train_to_ml['first_party_winner']], axis =1)\n",
    "to_be_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821816c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1526</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.080011</td>\n",
       "      <td>-0.014580</td>\n",
       "      <td>-0.038840</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>-0.040639</td>\n",
       "      <td>0.039663</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.029425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012600</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.034796</td>\n",
       "      <td>-0.020804</td>\n",
       "      <td>-0.006913</td>\n",
       "      <td>-0.038063</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>-0.021999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003053</td>\n",
       "      <td>-0.011769</td>\n",
       "      <td>-0.034803</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-0.026498</td>\n",
       "      <td>-0.014561</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>-0.009658</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018383</td>\n",
       "      <td>-0.027521</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.049594</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025638</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.021478</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>-0.036683</td>\n",
       "      <td>-0.034054</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>-0.017806</td>\n",
       "      <td>-0.045973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023804</td>\n",
       "      <td>-0.017397</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.014011</td>\n",
       "      <td>-0.041264</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>-0.012293</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.010219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028991</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>-0.059128</td>\n",
       "      <td>-0.030722</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.028222</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>-0.009327</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>-0.008745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021711</td>\n",
       "      <td>-0.015069</td>\n",
       "      <td>-0.001111</td>\n",
       "      <td>-0.014473</td>\n",
       "      <td>-0.025876</td>\n",
       "      <td>-0.006428</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.028281</td>\n",
       "      <td>-0.004001</td>\n",
       "      <td>-0.012030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036941</td>\n",
       "      <td>-0.039247</td>\n",
       "      <td>-0.026675</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>-0.016113</td>\n",
       "      <td>0.046348</td>\n",
       "      <td>-0.012971</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>-0.051456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016862</td>\n",
       "      <td>-0.034918</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.037341</td>\n",
       "      <td>-0.040531</td>\n",
       "      <td>-0.014745</td>\n",
       "      <td>-0.042890</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.010147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>-0.017606</td>\n",
       "      <td>-0.026507</td>\n",
       "      <td>-0.038503</td>\n",
       "      <td>-0.013017</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>-0.006750</td>\n",
       "      <td>-0.023582</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.024067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010572</td>\n",
       "      <td>-0.034447</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>-0.046846</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>-0.034175</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>0.006327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-0.001220</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>-0.023937</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>0.076602</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>-0.012813</td>\n",
       "      <td>-0.014318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>-0.030309</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.053392</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.014506</td>\n",
       "      <td>-0.011636</td>\n",
       "      <td>0.024630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>0.063505</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>-0.032935</td>\n",
       "      <td>-0.016052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018592</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.015415</td>\n",
       "      <td>-0.033917</td>\n",
       "      <td>-0.057270</td>\n",
       "      <td>-0.028927</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.001634</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>-0.014695</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>-0.025222</td>\n",
       "      <td>0.065449</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>-0.006307</td>\n",
       "      <td>-0.005089</td>\n",
       "      <td>-0.044533</td>\n",
       "      <td>-0.016824</td>\n",
       "      <td>-0.018459</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.058938</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.051615</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>-0.019234</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027754</td>\n",
       "      <td>-0.020528</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>-0.013797</td>\n",
       "      <td>-0.022734</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>-0.025505</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>-0.011266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0    -0.006672 -0.080011 -0.014580 -0.038840  0.048455 -0.040639  0.039663   \n",
       "1    -0.003053 -0.011769 -0.034803 -0.041324 -0.026498 -0.014561  0.012917   \n",
       "2    -0.025638 -0.016005 -0.021478  0.014413  0.048054 -0.036683 -0.034054   \n",
       "3     0.028991  0.036599 -0.059128 -0.030722 -0.017587 -0.028222  0.052064   \n",
       "4     0.036941 -0.039247 -0.026675 -0.006587 -0.022472 -0.016113  0.046348   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1235 -0.017606 -0.026507 -0.038503 -0.013017  0.036128 -0.006750 -0.023582   \n",
       "1236 -0.001220 -0.002364 -0.025906 -0.023937  0.002847 -0.021732  0.076602   \n",
       "1237  0.001026  0.023440  0.013377  0.016586  0.024960 -0.001395  0.063505   \n",
       "1238  0.001634 -0.000814 -0.014695  0.003300  0.001420  0.028769 -0.025222   \n",
       "1239 -0.058938  0.010668  0.004917 -0.051615  0.033669  0.037903  0.019593   \n",
       "\n",
       "          7         8         9     ...      1526      1527      1528  \\\n",
       "0     0.068547  0.002239 -0.029425  ... -0.012600 -0.023597 -0.003138   \n",
       "1    -0.009658 -0.000563 -0.018914  ... -0.018383 -0.027521  0.004810   \n",
       "2     0.043429 -0.017806 -0.045973  ... -0.023804 -0.017397  0.008190   \n",
       "3    -0.009327  0.006705 -0.008745  ... -0.021711 -0.015069 -0.001111   \n",
       "4    -0.012971  0.029547 -0.051456  ... -0.016862 -0.034918  0.005033   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1235  0.004234 -0.010011 -0.024067  ... -0.010572 -0.034447 -0.002972   \n",
       "1236 -0.014772 -0.012813 -0.014318  ... -0.000953 -0.013990  0.002872   \n",
       "1237 -0.017101 -0.032935 -0.016052  ... -0.018592 -0.016234  0.018842   \n",
       "1238  0.065449 -0.011581 -0.044858  ...  0.004752  0.003640  0.013376   \n",
       "1239  0.016298 -0.019234 -0.045782  ... -0.027754 -0.020528  0.022163   \n",
       "\n",
       "          1529      1530      1531      1532      1533      1534      1535  \n",
       "0    -0.008353 -0.034796 -0.020804 -0.006913 -0.038063  0.008657 -0.021999  \n",
       "1    -0.006279 -0.019910 -0.044318 -0.049594 -0.022413  0.012250  0.003738  \n",
       "2    -0.010989 -0.014011 -0.041264 -0.009615 -0.012293 -0.000732  0.010219  \n",
       "3    -0.014473 -0.025876 -0.006428 -0.018803 -0.028281 -0.004001 -0.012030  \n",
       "4     0.000040 -0.037341 -0.040531 -0.014745 -0.042890 -0.000467 -0.010147  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1235 -0.012302 -0.004949 -0.046846 -0.039191 -0.034175 -0.013973  0.006327  \n",
       "1236 -0.030309 -0.013520 -0.053392 -0.012986 -0.014506 -0.011636  0.024630  \n",
       "1237 -0.002355 -0.015415 -0.033917 -0.057270 -0.028927 -0.005387  0.000249  \n",
       "1238 -0.006307 -0.005089 -0.044533 -0.016824 -0.018459 -0.004400  0.022938  \n",
       "1239 -0.013797 -0.022734 -0.028132 -0.043650 -0.025505 -0.002197 -0.011266  \n",
       "\n",
       "[1240 rows x 1536 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_test_x.columns = np.arange(len(to_be_test_x.columns))\n",
    "to_be_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "672d6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = to_be_X.drop(columns='first_party_winner')\n",
    "y = pd.DataFrame(to_be_X['first_party_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ba05847",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = to_be_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef21a57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Columns: 1536 entries, 0 to 1535\n",
      "dtypes: float64(1536)\n",
      "memory usage: 29.0 MB\n",
      "\n",
      " --------------------------------------- \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 1 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   first_party_winner  2478 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 19.5 KB\n",
      "\n",
      " --------------------------------------- \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1240 entries, 0 to 1239\n",
      "Columns: 1536 entries, 0 to 1535\n",
      "dtypes: float64(1536)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "\n",
    "print('\\n --------------------------------------- \\n')\n",
    "\n",
    "y.info()\n",
    "\n",
    "print('\\n --------------------------------------- \\n')\n",
    "\n",
    "test_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410b0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb14756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1734, 1536) (744, 1536) (1734, 1) (744, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4970a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'error',\n",
    "        'booster': 'gbtree',\n",
    "        'nthread': trial.suggest_int('nthread', 1, 15),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 25, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 0.3),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.7),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 0.2, 200),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 3)\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    xgb_model = xgb(**xgb_params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, xgb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eec7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    lgb_params = {\n",
    "        'application': 'binary',\n",
    "        'max_depth': -1,\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt',  'dart']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 2000),\n",
    "        'lambda' : trial.suggest_float('lambda', 0.01, 0.5),\n",
    "        'num_iteration': 500,\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.1),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.7, 0.9),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 0.8),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_preds = lgb_model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, lgb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e874243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "    params = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'learning_rate': learning_rate,\n",
    "            'depth': trial.suggest_int('depth', 3, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "\n",
    "    model = cat.CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizes = dlc.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ae759f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-10 15:52:33,476] A new study created in memory with name: no-name-5499f085-f560-452d-b436-ad41805ba3f3\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2901b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db102d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 13:37:13,432] A new study created in memory with name: no-name-3f64f5dd-cf6d-41d0-a6f5-b7de1f5fe317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b9f2fcbbc94622b705b0549c4a31c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.07911695061300714. Current value: lambda_l2=0.07911695061300714\n",
      "[LightGBM] [Warning] num_iterations is set=500, num_iteration=500 will be ignored. Current value: num_iterations=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8318072994354647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8318072994354647\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6772159567546318, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6772159567546318\n",
      "[I 2023-06-11 13:37:38,521] Trial 0 finished with value: 0.6599462365591398 and parameters: {'boosting_type': 'dart', 'num_leaves': 1921, 'lambda': 0.07911695061300714, 'learning_rate': 0.07521150631221399, 'feature_fraction': 0.8318072994354647, 'bagging_fraction': 0.6772159567546318}. Best is trial 0 with value: 0.6599462365591398.\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.42650231341601624. Current value: lambda_l2=0.42650231341601624\n",
      "[LightGBM] [Warning] num_iterations is set=500, num_iteration=500 will be ignored. Current value: num_iterations=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7566869887319803, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7566869887319803\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.29399629244015874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.29399629244015874\n",
      "[I 2023-06-11 13:37:58,335] Trial 1 finished with value: 0.6586021505376344 and parameters: {'boosting_type': 'dart', 'num_leaves': 1591, 'lambda': 0.42650231341601624, 'learning_rate': 0.09826674429601488, 'feature_fraction': 0.7566869887319803, 'bagging_fraction': 0.29399629244015874}. Best is trial 1 with value: 0.6586021505376344.\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.20566187247806228. Current value: lambda_l2=0.20566187247806228\n",
      "[LightGBM] [Warning] num_iterations is set=500, num_iteration=500 will be ignored. Current value: num_iterations=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7615781012562591, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7615781012562591\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7076620046750038, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7076620046750038\n",
      "[I 2023-06-11 13:38:11,986] Trial 2 finished with value: 0.6666666666666666 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 1465, 'lambda': 0.20566187247806228, 'learning_rate': 0.07547868302464363, 'feature_fraction': 0.7615781012562591, 'bagging_fraction': 0.7076620046750038}. Best is trial 1 with value: 0.6586021505376344.\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.2880977195813002. Current value: lambda_l2=0.2880977195813002\n",
      "[LightGBM] [Warning] num_iterations is set=500, num_iteration=500 will be ignored. Current value: num_iterations=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.800656842574689, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.800656842574689\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2892466042741572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2892466042741572\n",
      "[I 2023-06-11 13:38:26,601] Trial 3 finished with value: 0.6653225806451613 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 1480, 'lambda': 0.2880977195813002, 'learning_rate': 0.05399118462512646, 'feature_fraction': 0.800656842574689, 'bagging_fraction': 0.2892466042741572}. Best is trial 1 with value: 0.6586021505376344.\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.29749127298451106. Current value: lambda_l2=0.29749127298451106\n",
      "[LightGBM] [Warning] num_iterations is set=500, num_iteration=500 will be ignored. Current value: num_iterations=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7542207041219193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7542207041219193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7099047625020872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099047625020872\n",
      "[I 2023-06-11 13:38:40,578] Trial 4 finished with value: 0.6559139784946236 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 1611, 'lambda': 0.29749127298451106, 'learning_rate': 0.06593896755655602, 'feature_fraction': 0.7542207041219193, 'bagging_fraction': 0.7099047625020872}. Best is trial 4 with value: 0.6559139784946236.\n"
     ]
    }
   ],
   "source": [
    "lgb_study = optuna.create_study(direction='minimize')\n",
    "lgb_study.optimize(lgb_objective, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc165c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7873372d",
   "metadata": {},
   "source": [
    "print('Number of finished XGB trials: {}'.format(len(xgb_study.trials)))\n",
    "print('XGB Best trial:')\n",
    "xgb_trial = xgb_study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(xgb_trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in xgb_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb2e584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished LGB trials: 5\n",
      "LGB Best trial:\n",
      "  Value: 0.6559139784946236\n",
      "  Params: \n",
      "    boosting_type: gbdt\n",
      "    num_leaves: 1611\n",
      "    lambda: 0.29749127298451106\n",
      "    learning_rate: 0.06593896755655602\n",
      "    feature_fraction: 0.7542207041219193\n",
      "    bagging_fraction: 0.7099047625020872\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished LGB trials: {}'.format(len(lgb_study.trials)))\n",
    "print('LGB Best trial:')\n",
    "lgb_trial = lgb_study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(lgb_trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in lgb_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a6bad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=0.29749127298451106. Current value: lambda_l2=0.29749127298451106\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7542207041219193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7542207041219193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7099047625020872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099047625020872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.7099047625020872,\n",
       "               feature_fraction=0.7542207041219193, lambda=0.29749127298451106,\n",
       "               learning_rate=0.06593896755655602, num_leaves=1611,\n",
       "               random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.7099047625020872,\n",
       "               feature_fraction=0.7542207041219193, lambda=0.29749127298451106,\n",
       "               learning_rate=0.06593896755655602, num_leaves=1611,\n",
       "               random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.7099047625020872,\n",
       "               feature_fraction=0.7542207041219193, lambda=0.29749127298451106,\n",
       "               learning_rate=0.06593896755655602, num_leaves=1611,\n",
       "               random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_best_params = lgb_study.best_params\n",
    "lgb_best_params['random_state'] = 42\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8a0633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_preds = lgb_model.predict(X_val)\n",
    "lgb_accuracy = accuracy_score(y_val, lgb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7d6e1",
   "metadata": {},
   "source": [
    "XGB_pred = XGB.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, XGB_pred)\n",
    "print(\"\\nAccuracy after tuning: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23f9a634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LGB --\n",
      "Train ACC : 1.000\n",
      "Val ACC : 0.656\n"
     ]
    }
   ],
   "source": [
    "print(\"-- LGB --\")\n",
    "print(\"Train ACC : %.3f\" % accuracy_score(y_train, lgb_model.predict(X_train)))\n",
    "print(\"Val ACC : %.3f\" % accuracy_score(y_val, lgb_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c7b9f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"\\n-- XGB --\")\n",
    "print(\"Train ACC : %.3f\" % accuracy_score(y_train, XGB.predict(X_train)))\n",
    "print(\"Val ACC : %.3f\" % accuracy_score(y_val, XGB.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdb42882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12       245\n",
      "           1       0.67      0.94      0.79       499\n",
      "\n",
      "    accuracy                           0.66       744\n",
      "   macro avg       0.53      0.51      0.45       744\n",
      "weighted avg       0.58      0.66      0.57       744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, lgb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b189476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6     \\\n",
      "0    -0.006672 -0.080011 -0.014580 -0.038840  0.048455 -0.040639  0.039663   \n",
      "1    -0.003053 -0.011769 -0.034803 -0.041324 -0.026498 -0.014561  0.012917   \n",
      "2    -0.025638 -0.016005 -0.021478  0.014413  0.048054 -0.036683 -0.034054   \n",
      "3     0.028991  0.036599 -0.059128 -0.030722 -0.017587 -0.028222  0.052064   \n",
      "4     0.036941 -0.039247 -0.026675 -0.006587 -0.022472 -0.016113  0.046348   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1235 -0.017606 -0.026507 -0.038503 -0.013017  0.036128 -0.006750 -0.023582   \n",
      "1236 -0.001220 -0.002364 -0.025906 -0.023937  0.002847 -0.021732  0.076602   \n",
      "1237  0.001026  0.023440  0.013377  0.016586  0.024960 -0.001395  0.063505   \n",
      "1238  0.001634 -0.000814 -0.014695  0.003300  0.001420  0.028769 -0.025222   \n",
      "1239 -0.058938  0.010668  0.004917 -0.051615  0.033669  0.037903  0.019593   \n",
      "\n",
      "          7         8         9     ...      1526      1527      1528  \\\n",
      "0     0.068547  0.002239 -0.029425  ... -0.012600 -0.023597 -0.003138   \n",
      "1    -0.009658 -0.000563 -0.018914  ... -0.018383 -0.027521  0.004810   \n",
      "2     0.043429 -0.017806 -0.045973  ... -0.023804 -0.017397  0.008190   \n",
      "3    -0.009327  0.006705 -0.008745  ... -0.021711 -0.015069 -0.001111   \n",
      "4    -0.012971  0.029547 -0.051456  ... -0.016862 -0.034918  0.005033   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1235  0.004234 -0.010011 -0.024067  ... -0.010572 -0.034447 -0.002972   \n",
      "1236 -0.014772 -0.012813 -0.014318  ... -0.000953 -0.013990  0.002872   \n",
      "1237 -0.017101 -0.032935 -0.016052  ... -0.018592 -0.016234  0.018842   \n",
      "1238  0.065449 -0.011581 -0.044858  ...  0.004752  0.003640  0.013376   \n",
      "1239  0.016298 -0.019234 -0.045782  ... -0.027754 -0.020528  0.022163   \n",
      "\n",
      "          1529      1530      1531      1532      1533      1534      1535  \n",
      "0    -0.008353 -0.034796 -0.020804 -0.006913 -0.038063  0.008657 -0.021999  \n",
      "1    -0.006279 -0.019910 -0.044318 -0.049594 -0.022413  0.012250  0.003738  \n",
      "2    -0.010989 -0.014011 -0.041264 -0.009615 -0.012293 -0.000732  0.010219  \n",
      "3    -0.014473 -0.025876 -0.006428 -0.018803 -0.028281 -0.004001 -0.012030  \n",
      "4     0.000040 -0.037341 -0.040531 -0.014745 -0.042890 -0.000467 -0.010147  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1235 -0.012302 -0.004949 -0.046846 -0.039191 -0.034175 -0.013973  0.006327  \n",
      "1236 -0.030309 -0.013520 -0.053392 -0.012986 -0.014506 -0.011636  0.024630  \n",
      "1237 -0.002355 -0.015415 -0.033917 -0.057270 -0.028927 -0.005387  0.000249  \n",
      "1238 -0.006307 -0.005089 -0.044533 -0.016824 -0.018459 -0.004400  0.022938  \n",
      "1239 -0.013797 -0.022734 -0.028132 -0.043650 -0.025505 -0.002197 -0.011266  \n",
      "\n",
      "[1240 rows x 1536 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.get_dummies(data=test_x)\n",
    "print(X_test)\n",
    "lgb_preds = lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a39f8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../sample_submission.csv')\n",
    "LGB_pred = pd.DataFrame(lgb_preds.astype(int))\n",
    "LGB_pred = LGB_pred.rename(columns={0:'first_party_winner'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66c9acf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_party_winner\n",
       "0                     1\n",
       "1                     1\n",
       "2                     1\n",
       "3                     1\n",
       "4                     1\n",
       "..                  ...\n",
       "739                   1\n",
       "740                   1\n",
       "741                   1\n",
       "742                   1\n",
       "743                   1\n",
       "\n",
       "[744 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e298bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['first_party_winner'] = LGB_pred['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e479851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    697\n",
      "0.0     47\n",
      "Name: first_party_winner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sample_submission['first_party_winner'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93ece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66f06f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"./results/LGB_submission_{Train:.03f}_{Val:.03f}.csv\".format(Train=accuracy_score(y_train, lgb_model.predict(X_train)), Val = accuracy_score(y_val, lgb_model.predict(X_val))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55745403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_submission = pd.read_csv('./sample_submission.csv')\n",
    "# XGB_pred = pd.DataFrame(XGB_pred.astype(int))\n",
    "# XGB_submission['first_party_winner'] = XGB_pred\n",
    "# XGB_submission.to_csv(\"./Bert_XGB_submission_{Train:.03f}_{Val:.03f}.csv\".format(Train=accuracy_score(y_train, XGB.predict(X_train)), Val = accuracy_score(y_val, XGB.predict(X_val))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc45434",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2bed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adf1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03158f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98ce1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa9de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6656db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ff303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d54a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4431c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480fea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e553a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aed924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D to 2D\n",
    "\n",
    "attention_mask_df = dlc.tensor_2_2d(train_bert_tokenized, 0)\n",
    "input_ids_df = dlc.tensor_2_2d(train_bert_tokenized, 1)\n",
    "token_type_ids_df = dlc.tensor_2_2d(train_bert_tokenized, 2)\n",
    "\n",
    "attention_mask_df.info()\n",
    "print('\\n _______________________________ \\n')\n",
    "input_ids_df.info()\n",
    "print('\\n _______________________________ \\n')\n",
    "token_type_ids_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4903d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask_df.info()\n",
    "attention_mask_df\n",
    "# input_ids_df.info()\n",
    "# input_ids_df\n",
    "# token_type_ids_df.info()\n",
    "# token_type_ids_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae125e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([train_cleansed['ID'], attention_mask_df], axis=1)\n",
    "temp = pd.concat([temp, input_ids_df], axis=1)\n",
    "train_BertToken_df = pd.concat([temp, token_type_ids_df], axis=1)\n",
    "train_BertToken_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tBTdf = so.right_merger(train_cleansed, train_BertToken_df, 0)\n",
    "tBTdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cbeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a9613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfb622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f31d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0818f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7ce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145d24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0007f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
