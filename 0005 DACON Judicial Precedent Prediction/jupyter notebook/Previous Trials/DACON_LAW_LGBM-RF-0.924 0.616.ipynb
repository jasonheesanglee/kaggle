{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc258d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ___________________________\n",
      "|                           |\n",
      "|======== YearDream ========|\n",
      "|===========================|\n",
      "|==== DLC Well Imported ====|\n",
      "|===========================|\n",
      "|========= BYJASON =========|\n",
      "|___________________________|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import dacon_law_class as dlc\n",
    "from dacon_law_class import SimpleOps as so\n",
    "\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from xgboost.sklearn import XGBClassifier as xgb\n",
    "# import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247af21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m sample_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./sample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8011b50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>TEST_1235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>TEST_1236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>TEST_1237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>TEST_1238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>TEST_1239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  first_party_winner\n",
       "0     TEST_0000                   0\n",
       "1     TEST_0001                   0\n",
       "2     TEST_0002                   0\n",
       "3     TEST_0003                   0\n",
       "4     TEST_0004                   0\n",
       "...         ...                 ...\n",
       "1235  TEST_1235                   0\n",
       "1236  TEST_1236                   0\n",
       "1237  TEST_1237                   0\n",
       "1238  TEST_1238                   0\n",
       "1239  TEST_1239                   0\n",
       "\n",
       "[1240 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "# test\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2ef6ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ID                  2478 non-null   object\n",
      " 1   first_party         2478 non-null   object\n",
      " 2   second_party        2478 non-null   object\n",
      " 3   facts               2478 non-null   object\n",
      " 4   first_party_winner  2478 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 96.9+ KB\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "print('\\n\\n\\n')\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b052690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phil amant</td>\n",
       "      <td>herman ompson</td>\n",
       "      <td>phil amant caidate for public office made tele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ephen duncan</td>\n",
       "      <td>lawrence owens</td>\n",
       "      <td>ramon nelson was ridin his bike when he suffer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>billy joe mawood</td>\n",
       "      <td>tony patterson waen et al</td>\n",
       "      <td>an alabama ate court convicted billy joe mawoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkletter</td>\n",
       "      <td>walker</td>\n",
       "      <td>victor linkletter was convicted in ate court o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "      <td>in selma alabama an intruder broke into apartm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>hollyfrontier cheyenne refinin llc et al</td>\n",
       "      <td>renewable fuels association et al</td>\n",
       "      <td>conress ameed clean air act rouh enery policy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>rupo mexicano de desarrollo</td>\n",
       "      <td>alliance bo fu inc</td>\n",
       "      <td>alliance bo fu inc an invement fu purchased ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>peuero</td>\n",
       "      <td>united ates</td>\n",
       "      <td>in dirict court sentenced manuel peuero to mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>iiration naturalization service</td>\n",
       "      <td>cyr</td>\n",
       "      <td>enrico cyr lawful permanent resident pled uilt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>an</td>\n",
       "      <td>weview inruments inc</td>\n",
       "      <td>herbert an owns patent to syem at tracks cloin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   first_party  \\\n",
       "0                                   phil amant   \n",
       "1                                 ephen duncan   \n",
       "2                             billy joe mawood   \n",
       "3                                   linkletter   \n",
       "4                           william earl fikes   \n",
       "...                                        ...   \n",
       "2473  hollyfrontier cheyenne refinin llc et al   \n",
       "2474               rupo mexicano de desarrollo   \n",
       "2475                                    peuero   \n",
       "2476           iiration naturalization service   \n",
       "2477                                        an   \n",
       "\n",
       "                           second_party  \\\n",
       "0                         herman ompson   \n",
       "1                        lawrence owens   \n",
       "2             tony patterson waen et al   \n",
       "3                                walker   \n",
       "4                               alabama   \n",
       "...                                 ...   \n",
       "2473  renewable fuels association et al   \n",
       "2474                 alliance bo fu inc   \n",
       "2475                        united ates   \n",
       "2476                                cyr   \n",
       "2477               weview inruments inc   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     phil amant caidate for public office made tele...                   1  \n",
       "1     ramon nelson was ridin his bike when he suffer...                   0  \n",
       "2     an alabama ate court convicted billy joe mawoo...                   1  \n",
       "3     victor linkletter was convicted in ate court o...                   0  \n",
       "4     in selma alabama an intruder broke into apartm...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  conress ameed clean air act rouh enery policy ...                   1  \n",
       "2474  alliance bo fu inc an invement fu purchased ap...                   1  \n",
       "2475  in dirict court sentenced manuel peuero to mon...                   0  \n",
       "2476  enrico cyr lawful permanent resident pled uilt...                   0  \n",
       "2477  herbert an owns patent to syem at tracks cloin...                   0  \n",
       "\n",
       "[2478 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train['facts'])\n",
    "df = dlc.law_preprocessor(df, 'facts')\n",
    "train['facts'] = df['facts']\n",
    "df = pd.DataFrame(train['first_party'])\n",
    "df = dlc.law_preprocessor(df, 'first_party')\n",
    "train['first_party'] = df['first_party']\n",
    "df = pd.DataFrame(train['second_party'])\n",
    "df = dlc.law_preprocessor(df, 'second_party')\n",
    "train['second_party'] = df['second_party']\n",
    "train_cleansed = train.drop(columns='ID')\n",
    "train_cleansed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42f6a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salerno</td>\n",
       "      <td>united ates</td>\n",
       "      <td>bail reform act allowed federal courts to deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milber weiss bershad hynes lerach</td>\n",
       "      <td>lexecon inc</td>\n",
       "      <td>lexecon inc was defeant in class action lawsui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no title federal counications coission et al</td>\n",
       "      <td>fox television ations inc et al</td>\n",
       "      <td>in fox television ations broadca billboa music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harold kaufman</td>\n",
       "      <td>united ates</td>\n",
       "      <td>durin his trial for armed robbery of federally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berer</td>\n",
       "      <td>hanlon</td>\n",
       "      <td>in mairate jude issued warrant auorizin search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>haitian centers council inc et al</td>\n",
       "      <td>chris sale actin coissioner iiration naturaliz...</td>\n",
       "      <td>accoin to executive oer no sined by president ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>whitman</td>\n",
       "      <td>american truckin associations inc</td>\n",
       "      <td>section of clean air act requires environmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>lia matteo john madian</td>\n",
       "      <td>william barr</td>\n",
       "      <td>lia matteo john madian created plan for utiliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>washinton ate apple advertisin coission</td>\n",
       "      <td>hunt</td>\n",
       "      <td>in nor carolina boa of ariculture adopted reul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>eodore ovall</td>\n",
       "      <td>wilfred denno waen</td>\n",
       "      <td>dr paul berheldt was abbed to dea in kitchen o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       first_party  \\\n",
       "0                                          salerno   \n",
       "1                milber weiss bershad hynes lerach   \n",
       "2     no title federal counications coission et al   \n",
       "3                                   harold kaufman   \n",
       "4                                            berer   \n",
       "...                                            ...   \n",
       "1235             haitian centers council inc et al   \n",
       "1236                                       whitman   \n",
       "1237                        lia matteo john madian   \n",
       "1238       washinton ate apple advertisin coission   \n",
       "1239                                  eodore ovall   \n",
       "\n",
       "                                           second_party  \\\n",
       "0                                           united ates   \n",
       "1                                           lexecon inc   \n",
       "2                       fox television ations inc et al   \n",
       "3                                           united ates   \n",
       "4                                                hanlon   \n",
       "...                                                 ...   \n",
       "1235  chris sale actin coissioner iiration naturaliz...   \n",
       "1236                  american truckin associations inc   \n",
       "1237                                       william barr   \n",
       "1238                                               hunt   \n",
       "1239                                 wilfred denno waen   \n",
       "\n",
       "                                                  facts  \n",
       "0     bail reform act allowed federal courts to deta...  \n",
       "1     lexecon inc was defeant in class action lawsui...  \n",
       "2     in fox television ations broadca billboa music...  \n",
       "3     durin his trial for armed robbery of federally...  \n",
       "4     in mairate jude issued warrant auorizin search...  \n",
       "...                                                 ...  \n",
       "1235  accoin to executive oer no sined by president ...  \n",
       "1236  section of clean air act requires environmenta...  \n",
       "1237  lia matteo john madian created plan for utiliz...  \n",
       "1238  in nor carolina boa of ariculture adopted reul...  \n",
       "1239  dr paul berheldt was abbed to dea in kitchen o...  \n",
       "\n",
       "[1240 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test['facts'])\n",
    "df = dlc.law_preprocessor(df, 'facts')\n",
    "test['facts'] = df['facts']\n",
    "df = pd.DataFrame(test['first_party'])\n",
    "df = dlc.law_preprocessor(df, 'first_party')\n",
    "test['first_party'] = df['first_party']\n",
    "df = pd.DataFrame(test['second_party'])\n",
    "df = dlc.law_preprocessor(df, 'second_party')\n",
    "test['second_party'] = df['second_party']\n",
    "test_cleansed = test.drop(columns='ID')\n",
    "test_cleansed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8f896",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "@article{turc2019,\n",
    "  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},\n",
    "  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n",
    "  journal={arXiv preprint arXiv:1908.08962v2 },\n",
    "  year={2019}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_facts = pd.DataFrame(test_cleansed['facts'])\n",
    "train_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fact = pd.DataFrame(test_cleansed['facts'])\n",
    "test_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9d178",
   "metadata": {},
   "source": [
    "model_input_df = dlc.bert_tokenizer(train_facts, 'facts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383af38c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47a66c",
   "metadata": {},
   "source": [
    "df_part_1, df_part_2, df_part_3, df_part_4, df_part_5, df_part_6, df_part_7, df_part_8, df_part_9, df_part_10, df_part_11, df_part_12, df_part_13, df_part_14, df_part_15, df_part_16, df_part_17, df_part_18, df_part_19, df_part_20, df_part_21, df_part_22, df_part_23, df_part_24, df_part_25, df_part_26 = so.df_divider(train_cleansed, 'facts')\n",
    "df_part_1 = pd.DataFrame(df_part_1)\n",
    "df_part_2 = pd.DataFrame(df_part_2)\n",
    "df_part_3 = pd.DataFrame(df_part_3)\n",
    "df_part_4 = pd.DataFrame(df_part_4)\n",
    "df_part_5 = pd.DataFrame(df_part_5)\n",
    "df_part_6 = pd.DataFrame(df_part_6)\n",
    "df_part_7 = pd.DataFrame(df_part_7)\n",
    "df_part_8 = pd.DataFrame(df_part_8)\n",
    "df_part_9 = pd.DataFrame(df_part_9)\n",
    "df_part_10 = pd.DataFrame(df_part_10)\n",
    "df_part_11 = pd.DataFrame(df_part_11)\n",
    "df_part_12 = pd.DataFrame(df_part_12)\n",
    "df_part_13 = pd.DataFrame(df_part_13)\n",
    "df_part_14 = pd.DataFrame(df_part_14)\n",
    "df_part_15 = pd.DataFrame(df_part_15)\n",
    "df_part_16 = pd.DataFrame(df_part_16)\n",
    "df_part_17 = pd.DataFrame(df_part_17)\n",
    "df_part_18 = pd.DataFrame(df_part_18)\n",
    "df_part_19 = pd.DataFrame(df_part_19)\n",
    "df_part_20 = pd.DataFrame(df_part_20)\n",
    "df_part_21 = pd.DataFrame(df_part_21)\n",
    "df_part_22 = pd.DataFrame(df_part_22)\n",
    "df_part_23 = pd.DataFrame(df_part_23)\n",
    "df_part_24 = pd.DataFrame(df_part_24)\n",
    "df_part_25 = pd.DataFrame(df_part_25)\n",
    "df_part_26 = pd.DataFrame(df_part_26)\n",
    "print(df_part_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370bf34c",
   "metadata": {},
   "source": [
    "embedded_df_1 = dlc.auto_tokenizer(train_cleansed, 'facts')\n",
    "embedded_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83cfc76",
   "metadata": {},
   "source": [
    "embedded_df_1 = embedded_df_1.rename(columns={0:'facts_berted'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab2385",
   "metadata": {},
   "source": [
    "embedded_df_1.to_csv('./embeddings/facts_embedded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ce9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_berted = dlc.auto_tokenizer(train_cleansed, 'first_party')\n",
    "first_party_berted = first_party_berted.rename(columns={0:'first_party_berted'})\n",
    "first_party_berted.to_csv('./embeddings/first_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_party_berted = dlc.auto_tokenizer(train_cleansed, 'second_party')\n",
    "second_party_berted = second_party_berted.rename(columns={0:'second_party_berted'})\n",
    "second_party_berted.to_csv('./embeddings/second_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ddfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_berted = dlc.auto_tokenizer(train_cleansed, 'facts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecee19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_berted = facts_berted.rename(columns={0:'facts_berted'})\n",
    "facts_berted.to_csv('./embeddings/facts_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_berted = pd.read_csv('./embeddings/first_party_berted.csv')\n",
    "second_party_berted = pd.read_csv('./embeddings/second_party_berted.csv')\n",
    "facts_berted = pd.read_csv('./embeddings/facts_berted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715db0c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ready_to_ml = pd.concat([first_party_berted['first_party_berted'], second_party_berted['second_party_berted'], facts_berted['facts_berted'], train_cleansed['first_party_winner']], axis=1)\n",
    "all_ready_to_ml.to_csv('./embeddings/1_train_ready_to_ml.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a083bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first_party_berted = dlc.auto_tokenizer(test_cleansed, 'first_party')\n",
    "test_first_party_berted = test_first_party_berted.rename(columns={0:'first_party_berted'})\n",
    "test_first_party_berted.to_csv('./embeddings/test_first_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_second_party_berted = dlc.auto_tokenizer(test_cleansed, 'second_party')\n",
    "test_second_party_berted = test_second_party_berted.rename(columns={0:'second_party_berted'})\n",
    "test_second_party_berted.to_csv('./embeddings/test_second_party_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_facts_berted = dlc.auto_tokenizer(test_cleansed, 'facts')\n",
    "test_facts_berted = test_facts_berted.rename(columns={0:'facts_berted'})\n",
    "test_facts_berted.to_csv('./embeddings/test_facts_berted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a83617",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first_party_berted = pd.read_csv('./embeddings/test_first_party_berted.csv')\n",
    "test_second_party_berted = pd.read_csv('./embeddings/test_second_party_berted.csv')\n",
    "test_facts_berted = pd.read_csv('./embeddings/test_facts_berted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ready_to_ml = pd.concat([test_first_party_berted['first_party_berted'], test_second_party_berted['second_party_berted'], test_facts_berted['facts_berted']], axis=1)\n",
    "test_ready_to_ml.to_csv('./embeddings/2_test_ready_to_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9f846",
   "metadata": {},
   "source": [
    "# 여기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ca9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_ml = pd.read_csv('./embeddings/1_train_ready_to_ml.csv')\n",
    "test_ready_to_ml = pd.read_csv('./embeddings/2_test_ready_to_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78df3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 2478/2478 [00:01<00:00, 2194.51it/s]\n",
      "100%|██████████████████████| 2478/2478 [00:01<00:00, 2238.00it/s]\n",
      "100%|██████████████████████| 2478/2478 [00:01<00:00, 2242.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train_to_ml_fp_pr = dlc.tensor_separator(train_to_ml, 'first_party_berted')\n",
    "train_to_ml_sp_pr = dlc.tensor_separator(train_to_ml, 'second_party_berted')\n",
    "train_to_ml_facts_pr = dlc.tensor_separator(train_to_ml, 'facts_berted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f496c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_ml_fp_pr = train_to_ml_fp_pr.astype('float64')\n",
    "train_to_ml_sp_pr = train_to_ml_sp_pr.astype('float64') \n",
    "train_to_ml_facts_pr = train_to_ml_facts_pr.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce3c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Columns: 768 entries, 0 to 767\n",
      "dtypes: float64(768)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_to_ml_fp_pr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fe8f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 1240/1240 [00:00<00:00, 2263.22it/s]\n",
      "100%|██████████████████████| 1240/1240 [00:00<00:00, 2265.55it/s]\n",
      "100%|██████████████████████| 1240/1240 [00:00<00:00, 2250.22it/s]\n"
     ]
    }
   ],
   "source": [
    "test_to_ml_fp_pr = dlc.tensor_separator(test_ready_to_ml, 'first_party_berted')\n",
    "test_to_ml_sp_pr = dlc.tensor_separator(test_ready_to_ml, 'second_party_berted')\n",
    "test_to_ml_facts_pr = dlc.tensor_separator(test_ready_to_ml, 'facts_berted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1772e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_ml_fp_pr = test_to_ml_fp_pr.astype('float64')\n",
    "test_to_ml_sp_pr = test_to_ml_sp_pr.astype('float64')\n",
    "test_to_ml_facts_pr = test_to_ml_facts_pr.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c15d9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_X = pd.concat([train_to_ml_fp_pr, train_to_ml_facts_pr], axis=1)\n",
    "to_be_test_x = pd.concat([test_to_ml_fp_pr, test_to_ml_facts_pr], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9313a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>-0.012888</td>\n",
       "      <td>-0.007303</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>-0.029552</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018174</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-0.010968</td>\n",
       "      <td>-0.030724</td>\n",
       "      <td>-0.035971</td>\n",
       "      <td>-0.038689</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>-0.010507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003902</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.044628</td>\n",
       "      <td>-0.032344</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>-0.018207</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.016356</td>\n",
       "      <td>-0.039208</td>\n",
       "      <td>-0.031188</td>\n",
       "      <td>-0.014293</td>\n",
       "      <td>-0.026212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>-0.017064</td>\n",
       "      <td>-0.019458</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>-0.030393</td>\n",
       "      <td>-0.020106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011412</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>-0.010546</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.025278</td>\n",
       "      <td>-0.054787</td>\n",
       "      <td>-0.016296</td>\n",
       "      <td>-0.009530</td>\n",
       "      <td>-0.012053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.015234</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>-0.018534</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>-0.030493</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>-0.013273</td>\n",
       "      <td>-0.019490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.005936</td>\n",
       "      <td>-0.003335</td>\n",
       "      <td>-0.026111</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>-0.027738</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011956</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>-0.037784</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>-0.023835</td>\n",
       "      <td>-0.029138</td>\n",
       "      <td>-0.031670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>-0.023639</td>\n",
       "      <td>-0.028438</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>-0.030627</td>\n",
       "      <td>-0.035033</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.024343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>-0.020591</td>\n",
       "      <td>-0.056972</td>\n",
       "      <td>-0.033879</td>\n",
       "      <td>0.031382</td>\n",
       "      <td>0.079985</td>\n",
       "      <td>0.025763</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.060979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027422</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.008214</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.009470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>-0.023678</td>\n",
       "      <td>-0.022937</td>\n",
       "      <td>-0.022214</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.039568</td>\n",
       "      <td>-0.052614</td>\n",
       "      <td>-0.034712</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>-0.004295</td>\n",
       "      <td>-0.029256</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>-0.010641</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>-0.022453</td>\n",
       "      <td>-0.034121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011819</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>-0.019696</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.042203</td>\n",
       "      <td>-0.044682</td>\n",
       "      <td>-0.023756</td>\n",
       "      <td>-0.004682</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0.021019</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>-0.021894</td>\n",
       "      <td>-0.032928</td>\n",
       "      <td>-0.029230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023799</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>-0.011824</td>\n",
       "      <td>-0.020932</td>\n",
       "      <td>-0.033988</td>\n",
       "      <td>-0.028924</td>\n",
       "      <td>-0.045331</td>\n",
       "      <td>-0.013245</td>\n",
       "      <td>-0.016124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>-0.006356</td>\n",
       "      <td>-0.011619</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>-0.008010</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>-0.016714</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>-0.046451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031149</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>-0.010829</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.037060</td>\n",
       "      <td>-0.035695</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 1537 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.005036  0.006439 -0.012888 -0.007303 -0.017571 -0.029552 -0.006318   \n",
       "1    -0.003902  0.026781 -0.044628 -0.032344 -0.001729 -0.018735  0.002111   \n",
       "2     0.003050  0.009259 -0.017064 -0.019458 -0.006200 -0.008553  0.050010   \n",
       "3    -0.015234 -0.000875  0.015897 -0.018534  0.054608 -0.030493  0.041842   \n",
       "4    -0.011956 -0.009987  0.020198  0.009508  0.024592 -0.037784  0.020635   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2473 -0.020591 -0.056972 -0.033879  0.031382  0.079985  0.025763 -0.006569   \n",
       "2474 -0.023678 -0.022937 -0.022214  0.013166  0.054840  0.011287  0.016339   \n",
       "2475 -0.004295 -0.029256 -0.015316 -0.010641  0.007141  0.021234  0.005180   \n",
       "2476  0.021019 -0.003120 -0.007031  0.007962  0.045658  0.014659  0.024269   \n",
       "2477 -0.006356 -0.011619 -0.007439 -0.012634 -0.008010 -0.005947  0.032153   \n",
       "\n",
       "             7         8         9  ...      1527      1528      1529  \\\n",
       "0     0.025047 -0.009394 -0.015124  ... -0.018174  0.001737  0.003518   \n",
       "1    -0.018207 -0.009919 -0.075807  ... -0.010969  0.006232 -0.012417   \n",
       "2     0.035903 -0.030393 -0.020106  ... -0.011412 -0.006155 -0.010546   \n",
       "3     0.057857 -0.013273 -0.019490  ... -0.019637 -0.005936 -0.003335   \n",
       "4    -0.023835 -0.029138 -0.031670  ... -0.033741  0.007560 -0.023639   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2473  0.044251 -0.008797 -0.060979  ... -0.027422  0.000112  0.015122   \n",
       "2474  0.090016  0.000314  0.001474  ... -0.017667  0.015822 -0.002527   \n",
       "2475  0.064935 -0.022453 -0.034121  ... -0.011819  0.019265 -0.019696   \n",
       "2476 -0.021894 -0.032928 -0.029230  ... -0.023799  0.002132 -0.011824   \n",
       "2477 -0.016714  0.039917 -0.046451  ... -0.031149 -0.003120  0.002196   \n",
       "\n",
       "          1530      1531      1532      1533      1534      1535  \\\n",
       "0    -0.010968 -0.030724 -0.035971 -0.038689 -0.006275 -0.010507   \n",
       "1    -0.020754 -0.016356 -0.039208 -0.031188 -0.014293 -0.026212   \n",
       "2    -0.024606 -0.025278 -0.054787 -0.016296 -0.009530 -0.012053   \n",
       "3    -0.026111 -0.015403  0.000960 -0.027738  0.005133 -0.012935   \n",
       "4    -0.028438 -0.010833 -0.030627 -0.035033 -0.000732 -0.024343   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "2473  0.009355 -0.046905 -0.002683 -0.008214 -0.000282 -0.009470   \n",
       "2474  0.004892 -0.039568 -0.052614 -0.034712 -0.004466  0.008349   \n",
       "2475 -0.024496 -0.042203 -0.044682 -0.023756 -0.004682  0.003538   \n",
       "2476 -0.020932 -0.033988 -0.028924 -0.045331 -0.013245 -0.016124   \n",
       "2477 -0.010829 -0.016647 -0.037060 -0.035695 -0.007506  0.002923   \n",
       "\n",
       "      first_party_winner  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "2473                   1  \n",
       "2474                   1  \n",
       "2475                   0  \n",
       "2476                   0  \n",
       "2477                   0  \n",
       "\n",
       "[2478 rows x 1537 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_X.columns = np.arange(len(to_be_X.columns))\n",
    "to_be_X = pd.concat([to_be_X, train_to_ml['first_party_winner']], axis =1)\n",
    "to_be_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f84a232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1526</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.080011</td>\n",
       "      <td>-0.014580</td>\n",
       "      <td>-0.038840</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>-0.040639</td>\n",
       "      <td>0.039663</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.029425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012600</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.034796</td>\n",
       "      <td>-0.020804</td>\n",
       "      <td>-0.006913</td>\n",
       "      <td>-0.038063</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>-0.021999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003053</td>\n",
       "      <td>-0.011769</td>\n",
       "      <td>-0.034803</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-0.026498</td>\n",
       "      <td>-0.014561</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>-0.009658</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018383</td>\n",
       "      <td>-0.027521</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.049594</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025638</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.021478</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>-0.036683</td>\n",
       "      <td>-0.034054</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>-0.017806</td>\n",
       "      <td>-0.045973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023804</td>\n",
       "      <td>-0.017397</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.014011</td>\n",
       "      <td>-0.041264</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>-0.012293</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.010219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028991</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>-0.059128</td>\n",
       "      <td>-0.030722</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.028222</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>-0.009327</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>-0.008745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021711</td>\n",
       "      <td>-0.015069</td>\n",
       "      <td>-0.001111</td>\n",
       "      <td>-0.014473</td>\n",
       "      <td>-0.025876</td>\n",
       "      <td>-0.006428</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.028281</td>\n",
       "      <td>-0.004001</td>\n",
       "      <td>-0.012030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036941</td>\n",
       "      <td>-0.039247</td>\n",
       "      <td>-0.026675</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>-0.016113</td>\n",
       "      <td>0.046348</td>\n",
       "      <td>-0.012971</td>\n",
       "      <td>0.029547</td>\n",
       "      <td>-0.051456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016862</td>\n",
       "      <td>-0.034918</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.037341</td>\n",
       "      <td>-0.040531</td>\n",
       "      <td>-0.014745</td>\n",
       "      <td>-0.042890</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.010147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>-0.017606</td>\n",
       "      <td>-0.026507</td>\n",
       "      <td>-0.038503</td>\n",
       "      <td>-0.013017</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>-0.006750</td>\n",
       "      <td>-0.023582</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.024067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010572</td>\n",
       "      <td>-0.034447</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>-0.046846</td>\n",
       "      <td>-0.039191</td>\n",
       "      <td>-0.034175</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>0.006327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-0.001220</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>-0.023937</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>0.076602</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>-0.012813</td>\n",
       "      <td>-0.014318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>-0.030309</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.053392</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.014506</td>\n",
       "      <td>-0.011636</td>\n",
       "      <td>0.024630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>0.063505</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>-0.032935</td>\n",
       "      <td>-0.016052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018592</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.015415</td>\n",
       "      <td>-0.033917</td>\n",
       "      <td>-0.057270</td>\n",
       "      <td>-0.028927</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.001634</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>-0.014695</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>-0.025222</td>\n",
       "      <td>0.065449</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>-0.006307</td>\n",
       "      <td>-0.005089</td>\n",
       "      <td>-0.044533</td>\n",
       "      <td>-0.016824</td>\n",
       "      <td>-0.018459</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>-0.058938</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>-0.051615</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>-0.019234</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027754</td>\n",
       "      <td>-0.020528</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>-0.013797</td>\n",
       "      <td>-0.022734</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>-0.025505</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>-0.011266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0    -0.006672 -0.080011 -0.014580 -0.038840  0.048455 -0.040639  0.039663   \n",
       "1    -0.003053 -0.011769 -0.034803 -0.041324 -0.026498 -0.014561  0.012917   \n",
       "2    -0.025638 -0.016005 -0.021478  0.014413  0.048054 -0.036683 -0.034054   \n",
       "3     0.028991  0.036599 -0.059128 -0.030722 -0.017587 -0.028222  0.052064   \n",
       "4     0.036941 -0.039247 -0.026675 -0.006587 -0.022472 -0.016113  0.046348   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1235 -0.017606 -0.026507 -0.038503 -0.013017  0.036128 -0.006750 -0.023582   \n",
       "1236 -0.001220 -0.002364 -0.025906 -0.023937  0.002847 -0.021732  0.076602   \n",
       "1237  0.001026  0.023440  0.013377  0.016586  0.024960 -0.001395  0.063505   \n",
       "1238  0.001634 -0.000814 -0.014695  0.003300  0.001420  0.028769 -0.025222   \n",
       "1239 -0.058938  0.010668  0.004917 -0.051615  0.033669  0.037903  0.019593   \n",
       "\n",
       "          7         8         9     ...      1526      1527      1528  \\\n",
       "0     0.068547  0.002239 -0.029425  ... -0.012600 -0.023597 -0.003138   \n",
       "1    -0.009658 -0.000563 -0.018914  ... -0.018383 -0.027521  0.004810   \n",
       "2     0.043429 -0.017806 -0.045973  ... -0.023804 -0.017397  0.008190   \n",
       "3    -0.009327  0.006705 -0.008745  ... -0.021711 -0.015069 -0.001111   \n",
       "4    -0.012971  0.029547 -0.051456  ... -0.016862 -0.034918  0.005033   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1235  0.004234 -0.010011 -0.024067  ... -0.010572 -0.034447 -0.002972   \n",
       "1236 -0.014772 -0.012813 -0.014318  ... -0.000953 -0.013990  0.002872   \n",
       "1237 -0.017101 -0.032935 -0.016052  ... -0.018592 -0.016234  0.018842   \n",
       "1238  0.065449 -0.011581 -0.044858  ...  0.004752  0.003640  0.013376   \n",
       "1239  0.016298 -0.019234 -0.045782  ... -0.027754 -0.020528  0.022163   \n",
       "\n",
       "          1529      1530      1531      1532      1533      1534      1535  \n",
       "0    -0.008353 -0.034796 -0.020804 -0.006913 -0.038063  0.008657 -0.021999  \n",
       "1    -0.006279 -0.019910 -0.044318 -0.049594 -0.022413  0.012250  0.003738  \n",
       "2    -0.010989 -0.014011 -0.041264 -0.009615 -0.012293 -0.000732  0.010219  \n",
       "3    -0.014473 -0.025876 -0.006428 -0.018803 -0.028281 -0.004001 -0.012030  \n",
       "4     0.000040 -0.037341 -0.040531 -0.014745 -0.042890 -0.000467 -0.010147  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1235 -0.012302 -0.004949 -0.046846 -0.039191 -0.034175 -0.013973  0.006327  \n",
       "1236 -0.030309 -0.013520 -0.053392 -0.012986 -0.014506 -0.011636  0.024630  \n",
       "1237 -0.002355 -0.015415 -0.033917 -0.057270 -0.028927 -0.005387  0.000249  \n",
       "1238 -0.006307 -0.005089 -0.044533 -0.016824 -0.018459 -0.004400  0.022938  \n",
       "1239 -0.013797 -0.022734 -0.028132 -0.043650 -0.025505 -0.002197 -0.011266  \n",
       "\n",
       "[1240 rows x 1536 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_test_x.columns = np.arange(len(to_be_test_x.columns))\n",
    "to_be_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672d6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = to_be_X.drop(columns='first_party_winner')\n",
    "y = pd.DataFrame(to_be_X['first_party_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "956e9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = to_be_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a0efe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Columns: 1536 entries, 0 to 1535\n",
      "dtypes: float64(1536)\n",
      "memory usage: 29.0 MB\n",
      "\n",
      " --------------------------------------- \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 1 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   first_party_winner  2478 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 19.5 KB\n",
      "\n",
      " --------------------------------------- \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1240 entries, 0 to 1239\n",
      "Columns: 1536 entries, 0 to 1535\n",
      "dtypes: float64(1536)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "\n",
    "print('\\n --------------------------------------- \\n')\n",
    "\n",
    "y.info()\n",
    "\n",
    "print('\\n --------------------------------------- \\n')\n",
    "\n",
    "test_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcb14756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1734, 1536) (744, 1536) (1734, 1) (744, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'error',\n",
    "        'booster': 'gbtree',\n",
    "        'nthread': trial.suggest_int('nthread', 1, 15),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 25, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 15),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 0.3),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.7),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 0.2, 200),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 3)\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    xgb_model = xgb(**xgb_params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, xgb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f35946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    lgb_params = {\n",
    "        'application': 'binary',\n",
    "        'max_depth': -1,\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt',  'dart']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 2000),\n",
    "        'lambda' : trial.suggest_float('lambda', 0.01, 0.5),\n",
    "        'num_iteration': 500,\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.1),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.7, 0.9),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 0.8),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_preds = lgb_model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, lgb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "    params = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'learning_rate': learning_rate,\n",
    "            'depth': trial.suggest_int('depth', 3, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "\n",
    "\n",
    "    model = cat.CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    \n",
    "    return accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74eaeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selector(trial):\n",
    "    model_type = trial.suggest_categorical('model_type', ['xgb', 'lgbm'])\n",
    "    random_state = 42\n",
    "\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        eval_metric = 'error'\n",
    "        objective = 'binary:logistic'\n",
    "        tree_method = trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\n",
    "\n",
    "        if tree_method == 'exact':\n",
    "            sampling_method = 'uniform'\n",
    "            subsample = 0.5\n",
    "            booster = trial.suggest_categorical('booster', ['dart', 'gbtree'])\n",
    "            if booster == 'gbtree':\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 300)\n",
    "                n_estimators = trial.suggest_int('n_estimators', 1, 1000)\n",
    "                if n_estimators < 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.3, 0.9)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                                1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  500)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 500,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif n_estimators > 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 0.7)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                            1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  500)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 500,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif booster == 'dart':\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 300)\n",
    "                colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.5, 0.9)\n",
    "                learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                            1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                if learning_rate in [1e-4, 5e-4]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.01, 0.5)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        rate_drop=rate_drop,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.3, 0.7)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        rate_drop=rate_drop,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif learning_rate in [5e-2, 1e-1]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.5, 1.0)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        rate_drop=rate_drop,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "            # elif booster == 'gblinear':\n",
    "            #     learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "            #                                                                 1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            #     if learning_rate in [1e-4, 5e-4]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             subsample=subsample,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             subsample=subsample,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [5e-2, 1e-1]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             subsample=subsample,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "\n",
    "        else:\n",
    "            sampling_method = 'uniform'\n",
    "            booster = trial.suggest_categorical('booster', ['dart', 'gbtree'])\n",
    "            if booster == 'gbtree':\n",
    "                subsample = trial.suggest_loguniform('subsample', 0.1, 0.5)\n",
    "                max_depth = 0\n",
    "                n_estimators = trial.suggest_int('n_estimators', 1, 1000)\n",
    "                if n_estimators < 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.3, 0.9)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                                1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  400)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 400,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif n_estimators > 500:\n",
    "                    colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.1, 0.7)\n",
    "                    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                                1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                    if learning_rate in [1e-4, 5e-4]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 0.1,\n",
    "                                                                  400)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 200,\n",
    "                                                                  700)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "                    elif learning_rate in [5e-2, 1e-1]:\n",
    "                        min_split_loss = trial.suggest_loguniform('min_split_loss', 400,\n",
    "                                                                  1000)  # aka gamma, from 0 to 1, loguniform\n",
    "                        min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                        alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                        model = xgb(\n",
    "                            eval_metric=eval_metric,\n",
    "                            objective=objective,\n",
    "                            learning_rate=learning_rate,\n",
    "                            sampling_method=sampling_method,\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            max_depth=max_depth,\n",
    "                            tree_method=tree_method,\n",
    "                            booster=booster,\n",
    "                            min_split_loss=min_split_loss,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            alpha=alpha,\n",
    "                            reg_lambda=reg_lambda,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        preds = model.predict(X_val)\n",
    "\n",
    "                        return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif booster == 'dart':\n",
    "                subsample = 0.5\n",
    "                max_depth = 0\n",
    "                colsample_bytree = trial.suggest_loguniform('colsample_bytree', 0.5, 0.9)\n",
    "                learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                            1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "                if learning_rate in [1e-4, 5e-4]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.01, 0.5)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 1, 20)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        rate_drop=rate_drop,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "\n",
    "                elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.3, 0.7)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 10, 30)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        rate_drop=rate_drop,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "                elif learning_rate in [5e-2, 1e-1]:\n",
    "                    rate_drop = trial.suggest_loguniform('rate_drop', 0.5, 1.0)\n",
    "                    min_child_weight = trial.suggest_int('min_child_weight', 20, 40)  # from 0 to infinite, int\n",
    "                    model = xgb(\n",
    "                        eval_metric=eval_metric,\n",
    "                        objective=objective,\n",
    "                        learning_rate=learning_rate,\n",
    "                        sampling_method=sampling_method,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree,\n",
    "                        max_depth=max_depth,\n",
    "                        tree_method=tree_method,\n",
    "                        booster=booster,\n",
    "                        rate_drop=rate_drop,\n",
    "                        min_child_weight=min_child_weight,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_val)\n",
    "\n",
    "                    return accuracy_score(y_val, preds)\n",
    "\n",
    "\n",
    "            # elif booster == 'gblinear':\n",
    "            #     learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "            #                                                                 1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            #     if learning_rate in [1e-4, 5e-4]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "            #\n",
    "            #     elif learning_rate in [5e-2, 1e-1]:\n",
    "            #         alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "            #         model = xgb(\n",
    "            #             eval_metric=eval_metric,\n",
    "            #             objective=objective,\n",
    "            #             learning_rate=learning_rate,\n",
    "            #             sampling_method=sampling_method,\n",
    "            #             tree_method=tree_method,\n",
    "            #             booster=booster,\n",
    "            #             alpha=alpha,\n",
    "            #             reg_lambda=reg_lambda,\n",
    "            #             random_state=random_state\n",
    "            #         )\n",
    "            #         model.fit(X_train, y_train)\n",
    "            #         preds = model.predict(X_val)\n",
    "            #\n",
    "            #         return accuracy_score(y_val, preds)\n",
    "\n",
    "    elif model_type == 'lgbm':\n",
    "        objective = 'binary'\n",
    "        metric = 'accuracy'\n",
    "        num_threads = 0\n",
    "        max_depth = -1\n",
    "\n",
    "        num_leaves = trial.suggest_int('num_leaves', 1, 1000)\n",
    "        boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'rf', 'goss'])\n",
    "        if boosting_type == 'gbdt':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1, 500)\n",
    "            learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                        1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            if learning_rate in [1e-4, 5e-4]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 20)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.5, 0.999)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.3, 0.7)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.3, 0.7)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [5e-2, 1e-1]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.1, 0.5)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.1, 0.5)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "        elif boosting_type == 'dart':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1, 500)\n",
    "            learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                        1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            if learning_rate in [1e-4, 5e-4]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 20)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.5, 0.999)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                drop_rate = trial.suggest_loguniform('drop_rate', 0.01, 0.5)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    n_estimators=n_estimators,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    drop_rate=drop_rate,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.3, 0.7)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.3, 0.7)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                drop_rate = trial.suggest_loguniform('drop_rate', 0.3, 0.7)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    n_estimators=n_estimators,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    drop_rate=drop_rate,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [5e-2, 1e-1]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "                feature_fraction = trial.suggest_uniform('feature_fraction', 0.5, 0.999)\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                drop_rate = trial.suggest_loguniform('drop_rate', 0.5, 1)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    n_estimators=n_estimators,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    feature_fraction=feature_fraction,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    max_depth=max_depth,\n",
    "                    drop_rate=drop_rate,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "        elif boosting_type == 'rf':\n",
    "            n_estimators = trial.suggest_int('n_estimators', 1, 500)\n",
    "            feature_fraction_bynode = trial.suggest_loguniform('feature_fraction_bynode', 0.01, 0.999)\n",
    "            if feature_fraction_bynode < 0.33:\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 0, 20)\n",
    "                alpha = trial.suggest_loguniform('alpha', 0.1, 20)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 0.01, 20)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    feature_fraction_bynode=feature_fraction_bynode,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif feature_fraction_bynode > 0.33 and feature_fraction_bynode < 0.66:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                alpha = trial.suggest_loguniform('alpha', 10, 30)  # from 0 to infinite, loguniform\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 10, 30)  # from 0 to infinite, loguniform\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    feature_fraction_bynode=feature_fraction_bynode,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif feature_fraction_bynode > 0.66:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 40)\n",
    "                alpha = trial.suggest_loguniform('alpha', 20, 40)  # from 0 to infinite, loguniform\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', 20, 40)  # from 0 to infinite, loguniform\n",
    "                bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.5, 0.999)\n",
    "                bagging_freq = trial.suggest_int('bagging_freq', 1, n_estimators)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    feature_fraction_bynode=feature_fraction_bynode,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    bagging_freq=bagging_freq,\n",
    "                    bagging_fraction=bagging_fraction,\n",
    "                    n_estimators=n_estimators,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    alpha=alpha,\n",
    "                    reg_lambda=reg_lambda,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "        elif boosting_type == 'goss':\n",
    "            learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2,\n",
    "                                                                        1e-1])  # aka eta, from 0 to 1, loguniform\n",
    "            if learning_rate in [1e-4, 5e-4]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 0, 20)\n",
    "                top_rate = trial.suggest_loguniform('top_rate', 0.1, 0.5)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    top_rate=top_rate,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [1e-3, 5e-3, 1e-2]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 30)\n",
    "                top_rate = trial.suggest_loguniform('top_rate', 0.3, 0.7)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    metric=metric,\n",
    "                    top_rate=top_rate,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)\n",
    "\n",
    "            elif learning_rate in [5e-2, 1e-1]:\n",
    "                min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 2, 40)\n",
    "                top_rate = trial.suggest_loguniform('top_rate', 0.5, 0.9)\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    boosting_type=boosting_type,\n",
    "                    num_leaves=num_leaves,\n",
    "                    num_threads=num_threads,\n",
    "                    objective=objective,\n",
    "                    top_rate=top_rate,\n",
    "                    min_data_in_leaf=min_data_in_leaf,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=random_state\n",
    "                )\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_val)\n",
    "\n",
    "                return accuracy_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f7999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "edc076e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:16:17,326] A new study created in memory with name: no-name-153a2c30-dfcf-4ddf-ba00-c5fb7c9ae476\n",
      "[I 2023-06-11 01:17:13,442] Trial 0 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'hist', 'booster': 'dart', 'colsample_bytree': 0.7305749527599955, 'learning_rate': 0.0001, 'rate_drop': 0.02256162736229715, 'min_child_weight': 20}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 01:17:18,238] Trial 1 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'approx', 'booster': 'gbtree', 'subsample': 0.1247214377306586, 'n_estimators': 741, 'colsample_bytree': 0.2437680436994102, 'learning_rate': 0.05, 'min_split_loss': 468.4541623105902, 'min_child_weight': 22, 'alpha': 36.898939485122376, 'reg_lambda': 31.05853762195564}. Best is trial 0 with value: 0.6706989247311828.\n",
      "[I 2023-06-11 01:17:27,572] Trial 2 finished with value: 0.6706989247311828 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'dart', 'max_depth': 204, 'colsample_bytree': 0.7537213190642513, 'learning_rate': 0.0001, 'rate_drop': 0.07448840162937954, 'min_child_weight': 17}. Best is trial 0 with value: 0.6706989247311828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9537075237001793, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9537075237001793\n",
      "[LightGBM] [Warning] bagging_freq is set=48, subsample_freq=0 will be ignored. Current value: bagging_freq=48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:17:53,301] Trial 3 finished with value: 0.6626344086021505 and parameters: {'model_type': 'lgbm', 'num_leaves': 420, 'boosting_type': 'rf', 'n_estimators': 195, 'feature_fraction_bynode': 0.08682816992453662, 'bagging_fraction': 0.9537075237001793, 'bagging_freq': 48, 'min_data_in_leaf': 4, 'alpha': 0.2965588998672286, 'reg_lambda': 0.13920392274270993}. Best is trial 3 with value: 0.6626344086021505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=346, subsample_freq=0 will be ignored. Current value: bagging_freq=346\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4876195613812056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4876195613812056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5136078557691223, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5136078557691223\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:18:00,583] Trial 4 finished with value: 0.6666666666666666 and parameters: {'model_type': 'lgbm', 'num_leaves': 483, 'boosting_type': 'dart', 'n_estimators': 394, 'learning_rate': 0.005, 'min_data_in_leaf': 22, 'feature_fraction': 0.4876195613812056, 'bagging_fraction': 0.5136078557691223, 'bagging_freq': 346, 'drop_rate': 0.39069218976171155}. Best is trial 3 with value: 0.6626344086021505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.3193251854919902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3193251854919902\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3536638154033356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3536638154033356\n",
      "[LightGBM] [Warning] bagging_freq is set=190, subsample_freq=0 will be ignored. Current value: bagging_freq=190\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=29, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=29\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:18:02,321] Trial 5 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 750, 'boosting_type': 'gbdt', 'n_estimators': 340, 'learning_rate': 0.01, 'min_data_in_leaf': 29, 'feature_fraction': 0.3536638154033356, 'bagging_fraction': 0.3193251854919902, 'bagging_freq': 190, 'alpha': 21.57133228334681, 'reg_lambda': 27.638939089303282}. Best is trial 3 with value: 0.6626344086021505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9858438538458153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9858438538458153\n",
      "[LightGBM] [Warning] bagging_freq is set=97, subsample_freq=0 will be ignored. Current value: bagging_freq=97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:18:13,395] Trial 6 finished with value: 0.6693548387096774 and parameters: {'model_type': 'lgbm', 'num_leaves': 789, 'boosting_type': 'rf', 'n_estimators': 400, 'feature_fraction_bynode': 0.5369347498460978, 'min_data_in_leaf': 15, 'alpha': 23.04712572620713, 'bagging_fraction': 0.9858438538458153, 'bagging_freq': 97, 'reg_lambda': 27.7233595626765}. Best is trial 3 with value: 0.6626344086021505.\n",
      "[I 2023-06-11 01:18:19,720] Trial 7 finished with value: 0.6693548387096774 and parameters: {'model_type': 'xgb', 'tree_method': 'exact', 'booster': 'dart', 'max_depth': 92, 'colsample_bytree': 0.5771750328325298, 'learning_rate': 0.001, 'rate_drop': 0.4679102251724578, 'min_child_weight': 13}. Best is trial 3 with value: 0.6626344086021505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=37, subsample_freq=0 will be ignored. Current value: bagging_freq=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4950345142824165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4950345142824165\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4697883931091244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4697883931091244\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:18:22,254] Trial 8 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 972, 'boosting_type': 'dart', 'n_estimators': 96, 'learning_rate': 0.005, 'min_data_in_leaf': 18, 'feature_fraction': 0.4950345142824165, 'bagging_fraction': 0.4697883931091244, 'bagging_freq': 37, 'drop_rate': 0.36546304475915337}. Best is trial 3 with value: 0.6626344086021505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.67397887459008, subsample=1.0 will be ignored. Current value: bagging_fraction=0.67397887459008\n",
      "[LightGBM] [Warning] bagging_freq is set=118, subsample_freq=0 will be ignored. Current value: bagging_freq=118\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:18:36,650] Trial 9 finished with value: 0.6599462365591398 and parameters: {'model_type': 'lgbm', 'num_leaves': 148, 'boosting_type': 'rf', 'n_estimators': 198, 'feature_fraction_bynode': 0.0987543250262737, 'bagging_fraction': 0.67397887459008, 'bagging_freq': 118, 'min_data_in_leaf': 7, 'alpha': 14.437074204090923, 'reg_lambda': 0.01384194991025955}. Best is trial 9 with value: 0.6599462365591398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:18:38,162] Trial 10 finished with value: 0.6706989247311828 and parameters: {'model_type': 'lgbm', 'num_leaves': 13, 'boosting_type': 'goss', 'learning_rate': 0.0005, 'min_data_in_leaf': 3, 'top_rate': 0.452700921407744}. Best is trial 9 with value: 0.6599462365591398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9397610834464499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9397610834464499\n",
      "[LightGBM] [Warning] bagging_freq is set=95, subsample_freq=0 will be ignored. Current value: bagging_freq=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:19:00,716] Trial 11 finished with value: 0.6747311827956989 and parameters: {'model_type': 'lgbm', 'num_leaves': 202, 'boosting_type': 'rf', 'n_estimators': 160, 'feature_fraction_bynode': 0.06011086120406012, 'bagging_fraction': 0.9397610834464499, 'bagging_freq': 95, 'min_data_in_leaf': 4, 'alpha': 0.1894556519987326, 'reg_lambda': 0.010229789191220211}. Best is trial 9 with value: 0.6599462365591398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8106354367412077, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8106354367412077\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:19:18,887] Trial 12 finished with value: 0.6720430107526881 and parameters: {'model_type': 'lgbm', 'num_leaves': 323, 'boosting_type': 'rf', 'n_estimators': 220, 'feature_fraction_bynode': 0.05713605958375755, 'bagging_fraction': 0.8106354367412077, 'bagging_freq': 14, 'min_data_in_leaf': 8, 'alpha': 0.896373682061737, 'reg_lambda': 0.02756542685965072}. Best is trial 9 with value: 0.6599462365591398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8094408757678654, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8094408757678654\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=0, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=0\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:19:23,818] Trial 13 finished with value: 0.6505376344086021 and parameters: {'model_type': 'lgbm', 'num_leaves': 219, 'boosting_type': 'rf', 'n_estimators': 28, 'feature_fraction_bynode': 0.1493510376507823, 'bagging_fraction': 0.8094408757678654, 'bagging_freq': 2, 'min_data_in_leaf': 0, 'alpha': 2.72733882999385, 'reg_lambda': 0.09245029259515498}. Best is trial 13 with value: 0.6505376344086021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7754379577879577, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7754379577879577\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=0, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=0\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-11 01:19:24,605] Trial 14 finished with value: 0.6155913978494624 and parameters: {'model_type': 'lgbm', 'num_leaves': 88, 'boosting_type': 'rf', 'n_estimators': 6, 'feature_fraction_bynode': 0.010143208983493432, 'bagging_fraction': 0.7754379577879577, 'bagging_freq': 1, 'min_data_in_leaf': 0, 'alpha': 4.236899902301447, 'reg_lambda': 0.06904552459730254}. Best is trial 14 with value: 0.6155913978494624.\n",
      "[LightGBM] [Fatal] Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n",
      "\n",
      "[W 2023-06-11 01:19:24,740] Trial 15 failed with parameters: {'model_type': 'lgbm', 'num_leaves': 13, 'boosting_type': 'goss', 'learning_rate': 0.1, 'min_data_in_leaf': 12, 'top_rate': 0.9552940215382816} because of the following error: LightGBMError('Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/ipykernel_95655/1003415067.py\", line 981, in model_selector\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n",
      "\n",
      "[W 2023-06-11 01:19:24,741] Trial 15 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] num_threads is set=0, n_jobs=-1 will be ignored. Current value: num_threads=0\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_selector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[91], line 981\u001b[0m, in \u001b[0;36mmodel_selector\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    968\u001b[0m top_rate \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.999\u001b[39m)\n\u001b[1;32m    969\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\n\u001b[1;32m    970\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m    971\u001b[0m     boosting_type\u001b[38;5;241m=\u001b[39mboosting_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    978\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state\n\u001b[1;32m    979\u001b[0m )\n\u001b[0;32m--> 981\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_val, preds)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m             valid_sets[i] \u001b[38;5;241m=\u001b[39m (valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y))\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py:2610\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2608\u001b[0m params_str \u001b[38;5;241m=\u001b[39m param_dict_to_str(params)\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m-> 2610\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (config_->top_rate + config_->other_rate) <= (1.0f) at /private/var/folders/0t/816d84452dn7h591gjkg32_m0000gn/T/pip-install-r7of8ftg/lightgbm_a925e0ed4219424bac647af665e90126/compile/src/boosting/goss.hpp, line 77 .\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(model_selector, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80fce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7031937",
   "metadata": {},
   "source": [
    "print('Number of finished XGB trials: {}'.format(len(xgb_study.trials)))\n",
    "print('XGB Best trial:')\n",
    "xgb_trial = xgb_study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(xgb_trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in xgb_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "42d1690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished study trials: 16\n",
      "study Best trial:\n",
      "  Value: 0.6155913978494624\n",
      "  Params: \n",
      "    model_type: lgbm\n",
      "    num_leaves: 88\n",
      "    boosting_type: rf\n",
      "    n_estimators: 6\n",
      "    feature_fraction_bynode: 0.010143208983493432\n",
      "    bagging_fraction: 0.7754379577879577\n",
      "    bagging_freq: 1\n",
      "    min_data_in_leaf: 0\n",
      "    alpha: 4.236899902301447\n",
      "    reg_lambda: 0.06904552459730254\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished study trials: {}'.format(len(study.trials)))\n",
    "print('study Best trial:')\n",
    "study_trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(study_trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in study_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b282d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(alpha=4.236899902301447, bagging_fraction=0.7754379577879577,\n",
       "               bagging_freq=1, boosting_type=&#x27;rf&#x27;,\n",
       "               feature_fraction_bynode=0.010143208983493432, min_data_in_leaf=0,\n",
       "               model_type=&#x27;lgbm&#x27;, n_estimators=6, num_leaves=88,\n",
       "               random_state=42, reg_lambda=0.06904552459730254)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(alpha=4.236899902301447, bagging_fraction=0.7754379577879577,\n",
       "               bagging_freq=1, boosting_type=&#x27;rf&#x27;,\n",
       "               feature_fraction_bynode=0.010143208983493432, min_data_in_leaf=0,\n",
       "               model_type=&#x27;lgbm&#x27;, n_estimators=6, num_leaves=88,\n",
       "               random_state=42, reg_lambda=0.06904552459730254)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(alpha=4.236899902301447, bagging_fraction=0.7754379577879577,\n",
       "               bagging_freq=1, boosting_type='rf',\n",
       "               feature_fraction_bynode=0.010143208983493432, min_data_in_leaf=0,\n",
       "               model_type='lgbm', n_estimators=6, num_leaves=88,\n",
       "               random_state=42, reg_lambda=0.06904552459730254)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_best_params = study.best_params\n",
    "study_best_params['random_state'] = 42\n",
    "if study_best_params['model_type'] == 'lgbm':\n",
    "    model = lgb.LGBMClassifier(**study_best_params)\n",
    "elif study_best_params['model_type'] == 'xgb':\n",
    "    model = xgb(**study_best_params)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af80e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_preds = lgb_model.predict(X_val)\n",
    "lgb_accuracy = accuracy_score(y_val, lgb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf243d26",
   "metadata": {},
   "source": [
    "XGB_pred = XGB.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, XGB_pred)\n",
    "print(\"\\nAccuracy after tuning: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fb6ce9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LGB --\n",
      "Train ACC : 0.924\n",
      "Val ACC : 0.616\n"
     ]
    }
   ],
   "source": [
    "print(\"-- LGB --\")\n",
    "print(\"Train ACC : %.3f\" % accuracy_score(y_train, lgb_model.predict(X_train)))\n",
    "print(\"Val ACC : %.3f\" % accuracy_score(y_val, lgb_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab56df",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"\\n-- XGB --\")\n",
    "print(\"Train ACC : %.3f\" % accuracy_score(y_train, XGB.predict(X_train)))\n",
    "print(\"Val ACC : %.3f\" % accuracy_score(y_val, XGB.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be4beb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.16      0.21       245\n",
      "           1       0.67      0.84      0.75       499\n",
      "\n",
      "    accuracy                           0.62       744\n",
      "   macro avg       0.50      0.50      0.48       744\n",
      "weighted avg       0.56      0.62      0.57       744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, lgb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd1b361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6     \\\n",
      "0    -0.006672 -0.080011 -0.014580 -0.038840  0.048455 -0.040639  0.039663   \n",
      "1    -0.003053 -0.011769 -0.034803 -0.041324 -0.026498 -0.014561  0.012917   \n",
      "2    -0.025638 -0.016005 -0.021478  0.014413  0.048054 -0.036683 -0.034054   \n",
      "3     0.028991  0.036599 -0.059128 -0.030722 -0.017587 -0.028222  0.052064   \n",
      "4     0.036941 -0.039247 -0.026675 -0.006587 -0.022472 -0.016113  0.046348   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1235 -0.017606 -0.026507 -0.038503 -0.013017  0.036128 -0.006750 -0.023582   \n",
      "1236 -0.001220 -0.002364 -0.025906 -0.023937  0.002847 -0.021732  0.076602   \n",
      "1237  0.001026  0.023440  0.013377  0.016586  0.024960 -0.001395  0.063505   \n",
      "1238  0.001634 -0.000814 -0.014695  0.003300  0.001420  0.028769 -0.025222   \n",
      "1239 -0.058938  0.010668  0.004917 -0.051615  0.033669  0.037903  0.019593   \n",
      "\n",
      "          7         8         9     ...      1526      1527      1528  \\\n",
      "0     0.068547  0.002239 -0.029425  ... -0.012600 -0.023597 -0.003138   \n",
      "1    -0.009658 -0.000563 -0.018914  ... -0.018383 -0.027521  0.004810   \n",
      "2     0.043429 -0.017806 -0.045973  ... -0.023804 -0.017397  0.008190   \n",
      "3    -0.009327  0.006705 -0.008745  ... -0.021711 -0.015069 -0.001111   \n",
      "4    -0.012971  0.029547 -0.051456  ... -0.016862 -0.034918  0.005033   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1235  0.004234 -0.010011 -0.024067  ... -0.010572 -0.034447 -0.002972   \n",
      "1236 -0.014772 -0.012813 -0.014318  ... -0.000953 -0.013990  0.002872   \n",
      "1237 -0.017101 -0.032935 -0.016052  ... -0.018592 -0.016234  0.018842   \n",
      "1238  0.065449 -0.011581 -0.044858  ...  0.004752  0.003640  0.013376   \n",
      "1239  0.016298 -0.019234 -0.045782  ... -0.027754 -0.020528  0.022163   \n",
      "\n",
      "          1529      1530      1531      1532      1533      1534      1535  \n",
      "0    -0.008353 -0.034796 -0.020804 -0.006913 -0.038063  0.008657 -0.021999  \n",
      "1    -0.006279 -0.019910 -0.044318 -0.049594 -0.022413  0.012250  0.003738  \n",
      "2    -0.010989 -0.014011 -0.041264 -0.009615 -0.012293 -0.000732  0.010219  \n",
      "3    -0.014473 -0.025876 -0.006428 -0.018803 -0.028281 -0.004001 -0.012030  \n",
      "4     0.000040 -0.037341 -0.040531 -0.014745 -0.042890 -0.000467 -0.010147  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1235 -0.012302 -0.004949 -0.046846 -0.039191 -0.034175 -0.013973  0.006327  \n",
      "1236 -0.030309 -0.013520 -0.053392 -0.012986 -0.014506 -0.011636  0.024630  \n",
      "1237 -0.002355 -0.015415 -0.033917 -0.057270 -0.028927 -0.005387  0.000249  \n",
      "1238 -0.006307 -0.005089 -0.044533 -0.016824 -0.018459 -0.004400  0.022938  \n",
      "1239 -0.013797 -0.022734 -0.028132 -0.043650 -0.025505 -0.002197 -0.011266  \n",
      "\n",
      "[1240 rows x 1536 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.get_dummies(data=test_x)\n",
    "print(X_test)\n",
    "lgb_preds = lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8cf0e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./sample_submission.csv')\n",
    "LGB_pred = pd.DataFrame(lgb_preds.astype(int))\n",
    "LGB_pred = LGB_pred.rename(columns={0:'first_party_winner'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "505f6aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_party_winner\n",
       "0                      0\n",
       "1                      1\n",
       "2                      1\n",
       "3                      1\n",
       "4                      1\n",
       "...                  ...\n",
       "1235                   0\n",
       "1236                   1\n",
       "1237                   1\n",
       "1238                   0\n",
       "1239                   1\n",
       "\n",
       "[1240 rows x 1 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e53a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['first_party_winner'] = LGB_pred['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fda5e1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1058\n",
       "0     182\n",
       "Name: first_party_winner, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['first_party_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e1bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4bc9e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"./results/LGB_submission_{Train:.03f}_{Val:.03f}.csv\".format(Train=accuracy_score(y_train, lgb_model.predict(X_train)), Val = accuracy_score(y_val, lgb_model.predict(X_val))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55745403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_submission = pd.read_csv('./sample_submission.csv')\n",
    "# XGB_pred = pd.DataFrame(XGB_pred.astype(int))\n",
    "# XGB_submission['first_party_winner'] = XGB_pred\n",
    "# XGB_submission.to_csv(\"./Bert_XGB_submission_{Train:.03f}_{Val:.03f}.csv\".format(Train=accuracy_score(y_train, XGB.predict(X_train)), Val = accuracy_score(y_val, XGB.predict(X_val))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc45434",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2bed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adf1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17efdcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2aa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cc7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80fba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873a673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20b16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f81b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05028c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cbe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f11548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60f28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D to 2D\n",
    "\n",
    "attention_mask_df = dlc.tensor_2_2d(train_bert_tokenized, 0)\n",
    "input_ids_df = dlc.tensor_2_2d(train_bert_tokenized, 1)\n",
    "token_type_ids_df = dlc.tensor_2_2d(train_bert_tokenized, 2)\n",
    "\n",
    "attention_mask_df.info()\n",
    "print('\\n _______________________________ \\n')\n",
    "input_ids_df.info()\n",
    "print('\\n _______________________________ \\n')\n",
    "token_type_ids_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4903d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask_df.info()\n",
    "attention_mask_df\n",
    "# input_ids_df.info()\n",
    "# input_ids_df\n",
    "# token_type_ids_df.info()\n",
    "# token_type_ids_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae125e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([train_cleansed['ID'], attention_mask_df], axis=1)\n",
    "temp = pd.concat([temp, input_ids_df], axis=1)\n",
    "train_BertToken_df = pd.concat([temp, token_type_ids_df], axis=1)\n",
    "train_BertToken_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tBTdf = so.right_merger(train_cleansed, train_BertToken_df, 0)\n",
    "tBTdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cbeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a9613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfb622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f31d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0818f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7ce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145d24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0007f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
